{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEPGcd3cYcpI"
      },
      "source": [
        "## 1.Download Video and Extract Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU3dfcu3flE5"
      },
      "source": [
        "Required Installs and Imports\n",
        "\n",
        "pytube: Pytube is a Python library for downloading YouTube videos.\n",
        "\n",
        "importing YouTube class from the pytube module.\n",
        "\n",
        "importing os for file handling\n",
        "\n",
        "Installing and importing ffmpeg:  Ffmpeg is a multimedia framework for handling audio, video, and other multimedia files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYvU4-EqfkeN",
        "outputId": "0535bedd-4b3c-4540-f820-1ea3638f0490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=183ef13e39c3609d055a4e7df7e5dd94a93073a30239f840bf85400ff1bb8b50\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube\n",
        "from pytube import YouTube\n",
        "import os\n",
        "!pip install ffmpeg\n",
        "import ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K9X4Tk4MA8DM",
        "outputId": "705f7dcd-5a96-499d-a74f-49de29e209e5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sarvam AI Wants To Leverage AI In Health & Education Says Co Founder Vivek Raghavan With OpenHathi'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vid_url = \"https://www.youtube.com/watch?v=Sby1uJ_NFIY\"  #url of the youtube video\n",
        "yt = YouTube(vid_url)\n",
        "yt.title  # Accessing the title of the YouTube video using the title attribute of the YouTube object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpIU8cUGBsVD",
        "outputId": "1351f199-c08a-48a4-a3c9-d2bcd3edd62f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-c8cb32afb0e1>:1: DeprecationWarning: Call to deprecated function all (This object can be treated as a list, all() is useless).\n",
            "  yt.streams.all()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">,\n",
              " <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">,\n",
              " <Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"248\" mime_type=\"video/webm\" res=\"1080p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001f\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"247\" mime_type=\"video/webm\" res=\"720p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"244\" mime_type=\"video/webm\" res=\"480p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"243\" mime_type=\"video/webm\" res=\"360p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"242\" mime_type=\"video/webm\" res=\"240p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"278\" mime_type=\"video/webm\" res=\"144p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">,\n",
              " <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">,\n",
              " <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">,\n",
              " <Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">,\n",
              " <Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">,\n",
              " <Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yt.streams.all()\n",
        "#Fetching all available streams for the video using the streams.all() method.\n",
        "#This returns a list of Stream objects representing different available\n",
        "#streams for the video, such as different resolutions and formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-D5-t7eB6s1",
        "outputId": "fce9daf8-457e-4698-cac4-b52e3f243ae9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stream = yt.streams.first()  # selecting the first stream\n",
        "stream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9X4ZFbkiU97"
      },
      "source": [
        "The video by default would be downloaded as \"Sarvam AI Wants To Leverage AI In Health & Education Says Co Founder Vivek Raghavan With OpenHathi.mp4\" , We rename it to \"video.mp4\" for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "T329HuxFCKMm",
        "outputId": "861943b0-89ce-40fd-ea5e-769c21870f93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/video'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stream.download(filename = \"video\")  #downloading the stream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js2ruJoYi2hi"
      },
      "source": [
        "Using the ffprobe command to analyze the video file (video.mp4) and display information about its streams, and other metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErSH6TRgFQRj",
        "outputId": "ac1b9503-6b74-414c-ebe6-c6066158a7d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Google\n",
            "  Duration: 00:26:15.06, start: 0.000000, bitrate: 453 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 354 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n"
          ]
        }
      ],
      "source": [
        "!ffprobe video.mp4 # display information about its streams, and other metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNYi4zDXjJ-2"
      },
      "source": [
        "Extracting audio from the video: Using ffmpeg to extract the audio from the video file (video.mp4) and save it as an MP3 file (audio.mp3). This command converts the audio stream from the video file to MP3 format using the libmp3lame audio codec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxJKLmVTG4U-",
        "outputId": "3bdbd40e-1bcc-412b-f376-6d451134794c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Google\n",
            "  Duration: 00:26:15.06, start: 0.000000, bitrate: 453 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 354 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to 'audio.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    TSSE            : Lavf58.76.100\n",
            "  Stream #0:0(eng): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libmp3lame\n",
            "size=   24611kB time=00:26:15.05 bitrate= 128.0kbits/s speed=44.8x    \n",
            "video:0kB audio:24611kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.001373%\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -i video.mp4 -map 0:a -acodec libmp3lame audio.mp3   #Extracting audio from the video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4vP98-5ZsY4"
      },
      "source": [
        "## 2.Transcription of Audio and 3.Time Alignment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl7Ja7TOjZCw"
      },
      "source": [
        "Here we first installed the open source speech-to-text model whisper.ai by OpenAI. I chose whisper.ai because it is one of the best speech-to-text models available and it is also open source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5W0G3MQHXEH",
        "outputId": "047fb441-7563-44c5-da19-07da890fc057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-dofxcn45\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-dofxcn45\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=07a60b9b0729b7d59d9b1ab52c3a6c2ff410b1dc370afa06a0597d3ba71e4e42\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hnxiuiyn/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [830 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,798 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,374 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,445 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,110 kB]\n",
            "Fetched 10.0 MB in 2s (4,063 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsH8_LQBkCVD"
      },
      "source": [
        "Now we run whisper on the audio.mp3 file, here I have used the medium model. There are various other models available like tiny, base, small, medium or large.Where tiny is the fastest, smallest and with the least accuracy and large takes longer, is a larger file and with highest quality model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqRnLx2NK6uR",
        "outputId": "a76d00a9-de10-4e9f-c39d-18247c61a574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:22<00:00, 67.4MiB/s]\n",
            "[00:00.000 --> 00:04.500]  Congratulations to you, Mr. Raghavan, for that. Thank you so much for joining us. Over to you.\n",
            "[00:08.500 --> 00:10.500]  Hi, everybody. How are you?\n",
            "[00:11.500 --> 00:17.500]  Okay, I am not hearing this at all. Is this like a post-lunch energy downer or something?\n",
            "[00:18.000 --> 00:20.500]  Let's hear it. Are you guys awake?\n",
            "[00:21.500 --> 00:27.000]  Alright. You better be because we have a superstar guest here.\n",
            "[00:27.500 --> 00:31.500]  You heard the $41 million and I didn't hear honestly anything she said after that.\n",
            "[00:32.500 --> 00:38.500]  So, we're going to ask for about $40 million from him by the end of this conversation, okay?\n",
            "[00:39.500 --> 00:45.500]  But let's get started. I want to introduce Vivek and Pratyush, his co-founder who is not here.\n",
            "[00:46.000 --> 00:50.500]  We wanted to start with playing a video of what OpenHati does.\n",
            "[00:51.000 --> 00:55.500]  I encourage all of you to go to the website servom.ai and check it out.\n",
            "[00:56.500 --> 01:04.000]  But let me start by introducing Vivek. Vivek is a dear friend and he is very, very modest, one of the most modest guys that I know.\n",
            "[01:04.500 --> 01:12.000]  But his personal journey, Vivek, you got a PhD from Carnegie Mellon. You started and sold a company to Magma.\n",
            "[01:12.500 --> 01:17.000]  And Vivek and I moved back to India. We were both in the valley on the same day, actually.\n",
            "[01:17.500 --> 01:25.000]  And you've been in India for the last 16 years. And what most people don't know is your journey at Aadhaar.\n",
            "[01:25.500 --> 01:38.000]  Vivek spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today.\n",
            "[01:38.500 --> 01:47.000]  So, please give it up. Honestly, when I think of selfless service, truly selfless service, I always think of Vivek.\n",
            "[01:48.000 --> 01:54.500]  And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush, his other co-founder.\n",
            "[01:55.000 --> 02:05.500]  Pratyush had a PhD from ETH at Zurich. He was at IBM Research. He was at Microsoft Research, playing a key role, and a faculty at IIT Madras, and at AI for Bharat.\n",
            "[02:06.000 --> 02:13.500]  So, that's a little brief introduction about them. These guys are modest, modest engineers, so they don't toot their own horn.\n",
            "[02:13.500 --> 02:17.000]  So, forgive me for tooting their horn in this case.\n",
            "[02:17.500 --> 02:25.000]  But let's jump right in about the money. Funding. 41 million bucks, man. That's a lot of money, right?\n",
            "[02:25.500 --> 02:32.000]  Every entrepreneur here is saying, what the hell did these guys do? What did the investors see to write such a big cheque?\n",
            "[02:32.500 --> 02:40.000]  No, I think it's a new trend of what's going on in India. I think that for the very first time,\n",
            "[02:40.000 --> 02:45.500]  I think the investors have looked at, you know, let's try and build something deep tech out of the country,\n",
            "[02:46.000 --> 02:50.500]  and let's try to figure out how to build something as a foundational technology out of the country.\n",
            "[02:51.000 --> 02:59.500]  And that's really what's really exciting, you know? And I think that about, you know, as Balazs was mentioning,\n",
            "[03:00.000 --> 03:06.500]  for the past 15 years, I've been kind of working in kind of, you know, both digital public infrastructure\n",
            "[03:06.500 --> 03:13.000]  and kind of non-profit kind of things. But when this whole thing of generative AI came about,\n",
            "[03:13.500 --> 03:19.000]  I, you know, we said, okay, how can I actually make a difference in this space?\n",
            "[03:19.500 --> 03:25.000]  And I said, maybe this is the opportunity to actually come out and really build something,\n",
            "[03:25.500 --> 03:32.000]  you know, and the only way that we realize that you can do it is actually in the private sector.\n",
            "[03:32.000 --> 03:37.500]  And I think that's, and then we went out there and we said we want to build something which is a continuation, right?\n",
            "[03:38.000 --> 03:42.500]  I mean, and fundamentally, the question is, the reason of what we want to do at ServamAI\n",
            "[03:43.000 --> 03:49.500]  is we want to basically make generative AI available and accessible to the people in the country.\n",
            "[03:50.000 --> 03:55.500]  And that's the intent. And when we said that we want to do this, there was a resonance in the investment community.\n",
            "[03:56.500 --> 04:03.000]  And I think it's a responsibility to really to show that something like this can be built out of India.\n",
            "[04:03.500 --> 04:09.000]  So we see that as confidence and a responsibility. And I also hope it's a trend that, you know,\n",
            "[04:09.500 --> 04:14.000]  that there are many more people like us who are backed, because if you look at it,\n",
            "[04:14.500 --> 04:19.000]  maybe it's a large number in, you know, in the Indian context, but in the global context,\n",
            "[04:19.500 --> 04:25.000]  I think there is just, there should be many, many more entrepreneurs who are backed to do things in India.\n",
            "[04:25.500 --> 04:31.000]  I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Krutim.\n",
            "[04:31.500 --> 04:36.000]  So we're going to come back to that question. But again, 41 million dollars.\n",
            "[04:36.500 --> 04:41.000]  I mean, all of what you said, you know, two million dollars, you know, that's a good amount of money\n",
            "[04:41.500 --> 04:47.000]  for a startup which, you know, which has not yet built anything. What are you going to do with all this money?\n",
            "[04:48.500 --> 04:52.000]  I can solve the problem. I can have a perfect solution for the problem.\n",
            "[04:52.000 --> 04:57.500]  I think in the last week I've got lots of calls from lots of people telling me how I can.\n",
            "[04:58.000 --> 05:02.500]  I know you first, okay? I'll be landed in the country the same day. I'm in front of the queue.\n",
            "[05:03.000 --> 05:09.500]  No, but honestly, I think the key thing in this is to putting together an amazing team.\n",
            "[05:10.000 --> 05:14.500]  And we actually have an amazing team, but we believe that it is talent that will drive this kind of thing,\n",
            "[05:15.000 --> 05:19.500]  and so it is to get key talent. And of course the other thing is compute.\n",
            "[05:19.500 --> 05:25.000]  This is extremely expensive compute-wise to actually do these kinds of things.\n",
            "[05:25.500 --> 05:30.000]  And I think that those are the two primary things that, you know, we'd use this for.\n",
            "[05:30.500 --> 05:37.000]  Okay. I'm computing in my own head as an entrepreneur. Talent, okay, you have like 20, 15 people.\n",
            "[05:37.500 --> 05:41.000]  How much are you paying these guys? But okay, you won't touch on that.\n",
            "[05:41.500 --> 05:45.000]  But let's talk about what you guys actually built. What is OpenHati?\n",
            "[05:45.500 --> 05:49.000]  How would you explain OpenHati to many people here who might not have known about it?\n",
            "[05:49.500 --> 05:57.000]  So, I think OpenHati is, so first of all, right, we come from, I personally come from the open source ecosystem,\n",
            "[05:57.500 --> 06:05.000]  and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful.\n",
            "[06:05.500 --> 06:12.000]  And as a result of that, one of the first things we did was, hey, there are these open source large language models that exist, right?\n",
            "[06:12.000 --> 06:18.500]  I mean, everybody knows about the Llama family from Meta. There are others like Mistral.\n",
            "[06:19.000 --> 06:22.500]  There are a bunch of open source, you know, large language models.\n",
            "[06:23.000 --> 06:30.500]  And then we said, is there any way that they can existing open source model and teach it language skills, right?\n",
            "[06:31.000 --> 06:36.500]  I mean, and that is really the, you know, what we decide, what we said that can we do something like that?\n",
            "[06:37.500 --> 06:47.000]  And is this a, you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages?\n",
            "[06:47.500 --> 06:55.000]  Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things.\n",
            "[06:55.500 --> 07:01.000]  And I think that how do you actually take and make it understand Indian language, understand Indian context,\n",
            "[07:01.000 --> 07:04.500]  and all of those things in actually a, in an efficient way.\n",
            "[07:05.000 --> 07:07.500]  And therefore, this was an attempt to do that.\n",
            "[07:08.000 --> 07:13.500]  And it is, OpenHati is, you know, is currently based on the Llama 7 billion model,\n",
            "[07:14.000 --> 07:21.500]  but we will be releasing many more models in different languages, different sizes, and things like that as part of this, as part of this series.\n",
            "[07:22.000 --> 07:27.500]  And of course, you know, we will be building further models on those and doing other things to actually,\n",
            "[07:27.500 --> 07:30.000]  and we will also have endpoints that people can use.\n",
            "[07:30.500 --> 07:35.000]  So, therefore, it is not, it is definitely, you know, something that people can use to things.\n",
            "[07:35.500 --> 07:40.000]  And that is the essence of what this OpenHati is.\n",
            "[07:40.500 --> 07:47.000]  So, what does it mean to people in the audience here who are either doing their own startups or a business or developers?\n",
            "[07:47.500 --> 07:50.000]  How should they look at OpenAI? Oh, sorry.\n",
            "[07:50.500 --> 07:52.000]  Not OpenAI.\n",
            "[07:52.000 --> 08:00.500]  No, no, no. I think the way you look at it is that we, one of the important things that we are doing is we are not just building models.\n",
            "[08:01.000 --> 08:10.500]  We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of models,\n",
            "[08:11.000 --> 08:14.500]  some which are from us, some which are open source, some which may not be open source,\n",
            "[08:14.500 --> 08:26.000]  and actually to actually pull together and figure out how to deploy, you know, generative AI applications at scale and understand and evaluate their performance in an efficient manner.\n",
            "[08:26.500 --> 08:28.000]  And that is something that we are planning to do.\n",
            "[08:28.500 --> 08:33.000]  And this platform is, you know, in the next couple of months will be coming out there.\n",
            "[08:33.500 --> 08:35.000]  It will be available to developers.\n",
            "[08:35.500 --> 08:42.000]  But, of course, those who want to start with the open source things and hack with that, of course, please go ahead and do that as well.\n",
            "[08:42.500 --> 08:44.000]  That is phenomenal.\n",
            "[08:44.500 --> 08:49.000]  But how does it compare to OpenAI itself or Google?\n",
            "[08:49.500 --> 08:53.000]  See, at least the things that we are doing now, right?\n",
            "[08:53.500 --> 09:02.000]  I mean, one of the things that when we thought about building server, we said we want to build a full stack generative AI company and different people have,\n",
            "[09:02.500 --> 09:08.000]  and our understanding of full stack is that we need to know how to train models from scratch.\n",
            "[09:08.500 --> 09:14.000]  We need to know how to kind of figure out how to deploy models to solve real world use cases.\n",
            "[09:14.500 --> 09:22.000]  And we need to play in the ecosystem to make sure that we can actually deploy population scale applications, right?\n",
            "[09:22.500 --> 09:25.000]  So we were thinking about all of these things.\n",
            "[09:25.500 --> 09:29.000]  But still the models we were talking about are, you know, fairly small models.\n",
            "[09:29.500 --> 09:31.000]  They are fairly small models, right?\n",
            "[09:31.500 --> 09:35.000]  The 7 to maybe up to 70 billion kind of range we are talking about.\n",
            "[09:35.500 --> 09:40.000]  While these models like OpenAI and Google are obviously much bigger models, right?\n",
            "[09:40.000 --> 09:49.500]  But we want to understand the techniques and be able to build that muscle to do all of these things to make it available to people.\n",
            "[09:50.000 --> 10:00.500]  Now those models are, I mean, as I said, I think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day,\n",
            "[10:00.500 --> 10:12.000]  we believe that these smaller models can do many, many kind of domain specific tasks extremely well, probably even better than the larger models.\n",
            "[10:12.500 --> 10:14.000]  And that is really one of the key areas.\n",
            "[10:14.500 --> 10:17.000]  And so therefore the value of these kinds of things, right?\n",
            "[10:17.500 --> 10:22.000]  We are not aiming in these set of models to build any AGI, right?\n",
            "[10:22.500 --> 10:23.000]  That's not our goal here.\n",
            "[10:23.000 --> 10:32.500]  Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things.\n",
            "[10:33.000 --> 10:34.500]  And obviously all of this unique to India.\n",
            "[10:35.000 --> 10:36.500]  But what is unique about India?\n",
            "[10:37.000 --> 10:46.500]  I mean, is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems?\n",
            "[10:47.500 --> 10:53.000]  So I think that, I mean, there are quite a few things that are unique about India, right?\n",
            "[10:53.500 --> 10:57.000]  The first thing is I think that we are a voice first nation.\n",
            "[10:57.500 --> 11:01.000]  So therefore I think voice has to be the core to doing things.\n",
            "[11:01.500 --> 11:09.000]  The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective.\n",
            "[11:09.000 --> 11:18.500]  Now I would say that there are lots of interesting use cases where you can use open AI and the cost structure works depending on your application.\n",
            "[11:19.000 --> 11:24.500]  But when you want to scale things to a massive level and make it work, then you have to figure out how small models work.\n",
            "[11:25.000 --> 11:28.500]  So that's something that is also specific to India.\n",
            "[11:29.000 --> 11:35.500]  The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure.\n",
            "[11:35.500 --> 11:47.000]  When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that.\n",
            "[11:47.500 --> 11:52.000]  That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways.\n",
            "[11:52.500 --> 11:56.000]  And as a part of Aadhaar, building Aadhaar, no better person than you.\n",
            "[11:57.000 --> 12:08.500]  So in summary, what I'm hearing is small models specialized with, trained with Indic specific language data suited for Indian problems at a compelling cost point will be suited for us.\n",
            "[12:09.000 --> 12:12.500]  We're not solving some world autonomous vehicles or some complex problem.\n",
            "[12:13.000 --> 12:17.500]  We're solving some basic problems specifically focused on voice with multiple languages.\n",
            "[12:18.000 --> 12:20.500]  That is what you see as the future. Am I paraphrasing this correctly?\n",
            "[12:21.500 --> 12:27.000]  No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy.\n",
            "[12:27.500 --> 12:33.000]  But we will be building, you know, custom models to solve various other kinds of problems as well, right?\n",
            "[12:33.500 --> 12:43.000]  It's not just limited to, I think, in different domains, working in different domains, making, building things based on unique data that enterprises have and things like that.\n",
            "[12:43.500 --> 12:45.000]  So that's something that we'll also look at.\n",
            "[12:45.500 --> 12:46.000]  Fair enough.\n",
            "[12:46.000 --> 12:50.500]  So coming back to the elephant in the room, no fun intended with open Hati.\n",
            "[12:51.000 --> 12:54.500]  What about Bhavesh Agarwal and Krutram? What is your take on that?\n",
            "[12:55.000 --> 12:57.500]  I think it's great. I think it's wonderful, right?\n",
            "[12:58.000 --> 13:05.500]  I mean, the fact that the technology AI is so important that we need multiple people working on it.\n",
            "[13:06.000 --> 13:11.500]  The fact that there are other people thinking is actually validates that this is an important problem to be solved.\n",
            "[13:11.500 --> 13:17.000]  And I think that, and we need everybody to come together and do that.\n",
            "[13:17.500 --> 13:20.000]  So I really welcome that. I think it's great.\n",
            "[13:20.500 --> 13:26.000]  And I think that there will be different people will have different takes as to how to solve this kind of problem.\n",
            "[13:26.500 --> 13:31.000]  And hopefully as a result of that, the entire ecosystem benefits.\n",
            "[13:31.500 --> 13:36.000]  I have one more question, and then I want to talk about some of the predictions that you've boldly made.\n",
            "[13:36.500 --> 13:41.000]  So Vivek, I usually ask people about what do you think the future will be, and everybody usually hedges.\n",
            "[13:41.500 --> 13:45.000]  So Vivek, what do you think is going to happen by December 2024?\n",
            "[13:45.500 --> 13:48.000]  What do you think sitting in this room one year later we can expect?\n",
            "[13:48.500 --> 13:52.000]  And you made three bold predictions, so I want to talk about that.\n",
            "[13:52.500 --> 13:54.000]  Before that, I have one last question.\n",
            "[13:54.500 --> 13:58.000]  What are the top three applications that you think are relevant for India?\n",
            "[13:58.500 --> 14:00.000]  You heard Sridhar talk about medical.\n",
            "[14:00.500 --> 14:05.000]  Quick summary, what do you think the top three apps are for India for AI?\n",
            "[14:05.000 --> 14:14.500]  So, I mean, I think that, as you said, things like education and medical are clearly areas where I think that things can be leveraged.\n",
            "[14:15.000 --> 14:21.500]  The whole idea of all these kind of the DPI aspect of it is another major application where things can happen.\n",
            "[14:22.000 --> 14:24.500]  And here I'm talking about country specific work.\n",
            "[14:25.000 --> 14:29.500]  And I think the whole idea which Sridhar also talked about was the concept of software, right?\n",
            "[14:29.500 --> 14:38.000]  And I think that, and clearly we have a very large software industry, and how to reimagine those things in this context is also something that's going to be big.\n",
            "[14:38.500 --> 14:44.000]  Fair enough. Are you guys ready for Vivek Raghavan's bold predictions?\n",
            "[14:44.500 --> 14:48.000]  Yes? No? I'm not getting any yes here. This is like a big deal.\n",
            "[14:48.500 --> 14:52.000]  He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it?\n",
            "[14:53.000 --> 14:59.500]  All right. So I asked him, what do you think, you know, a year later, what do you think we can expect?\n",
            "[15:00.000 --> 15:05.500]  And he came up with three things, and usually people give very blah answers when you ask a question like this because they don't want to be caught wrong.\n",
            "[15:06.000 --> 15:07.500]  Not Vivek. Vivek is bold.\n",
            "[15:08.000 --> 15:13.500]  So he basically said three things, and I'm going to list out the three things and then ask him about it.\n",
            "[15:14.000 --> 15:21.500]  So number one, he says, I would prefer to talk to an automated customer service than a real person because they'll give me a better answer.\n",
            "[15:22.000 --> 15:24.500]  So that is Vivek Raghavan's prediction number one.\n",
            "[15:25.000 --> 15:32.500]  So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut in India.\n",
            "[15:33.000 --> 15:37.500]  He thinks there will be too much GPU, okay? So if you want a short Nvidia stock, this is a good time.\n",
            "[15:38.000 --> 15:44.500]  And number three, which was extremely unexpected, he said some companies will suddenly die.\n",
            "[15:45.000 --> 15:48.500]  Okay. So Vivek, these are not what I expected.\n",
            "[15:49.500 --> 15:56.000]  So do you want to quickly talk about each of them, why you just came up with these, and then we'll throw the open for audience questions.\n",
            "[15:56.500 --> 16:03.000]  So I don't think I quite said it the way that Vala and I am thinking, but it's interesting.\n",
            "[16:04.000 --> 16:20.500]  But I think the first thing that we said is I think that, and I don't think that this is, I think there will come a time when, you know, in areas of customer service, et cetera, when you want to do something very specific.\n",
            "[16:21.000 --> 16:30.500]  Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot.\n",
            "[16:30.500 --> 16:45.000]  But I think that there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to, could give.\n",
            "[16:45.500 --> 16:57.000]  And I think that that's just, I just said that there will come a time where, you know, it's not a human you're talking to, but it's probably more likely to solve your intent than the human person.\n",
            "[16:58.000 --> 17:02.500]  That's just something that I think that could happen.\n",
            "[17:03.000 --> 17:07.500]  Okay, definitely controversial, but we'll let it go. What about the GPU glut?\n",
            "[17:08.000 --> 17:19.500]  No, no, yeah, so I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go, right?\n",
            "[17:20.500 --> 17:34.000]  I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of forms, and I think that that will always go in a cycle.\n",
            "[17:34.500 --> 17:40.000]  But we may find out that there are many, many more interesting problems that people will be able to solve.\n",
            "[17:41.000 --> 17:55.500]  I still remember, you know, we were at a Gen AI event in Bangalore, and we were talking to people, and we said, you know, how many people have access to, you know, four A-hundreds?\n",
            "[17:56.000 --> 18:01.500]  This was the question that I'd asked, and nobody in the room, and these are all extremely enthusiastic Gen AI people, and nobody had access.\n",
            "[18:01.500 --> 18:15.000]  And I think that thing is going to change. You will be able to get these kinds of things, and people who want to hack and do things will have access to these things without, you know, having to write a, you know, a major check to do.\n",
            "[18:15.500 --> 18:23.000]  Vivek is also a semiconductor guy, before he went into Aadhaar, so I would take his predictions very seriously, so I don't know what I, I'm going to sell my media stock.\n",
            "[18:23.500 --> 18:27.000]  I would not do that, but that's not what I said.\n",
            "[18:27.500 --> 18:30.000]  I want to blame you for this, if it goes up.\n",
            "[18:31.000 --> 18:38.500]  But the third one is pretty strange. You know, companies are born, companies die, but you said some companies will suddenly die. What does that mean?\n",
            "[18:39.000 --> 18:46.500]  No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI.\n",
            "[18:46.500 --> 18:54.000]  AI is a tool, right? And you have to use that, and you have to use that within your business process, right?\n",
            "[18:54.500 --> 19:11.000]  And how AI is being used, and so, and what's going to happen is that, I mean, I think this is true with, with, you know, when someone said in terms of, you know, people, they said that the people who leverage AI will be, will, will be more effective than those who don't leverage AI.\n",
            "[19:11.000 --> 19:22.500]  And that's true for organizations also. Organizations that leverage AI in, fundamentally in their core business processes, will be more effective than those who don't, right?\n",
            "[19:23.000 --> 19:29.500]  And I think that's the thing, and you won't know the difference until one day it becomes too obvious, and it will be too late.\n",
            "[19:30.000 --> 19:36.500]  And I think that's the reason why everybody needs to think about what it means for your business.\n",
            "[19:36.500 --> 19:50.000]  Because you will, everything will be fine. Everything will be fine, and one day somebody in your, either, either, either your competitor in your space or somebody brand new coming into your space will be re-imagining your business process completely.\n",
            "[19:51.000 --> 19:58.500]  And at that stage you will find that it's, you know, it's a, it's a very big, very tall, you know, mountain to climb.\n",
            "[19:59.000 --> 20:10.500]  And that's why I think it's important for both people and entities to think about how they will, you know, they, they will upgrade themselves or they will modify their business processes to, you know, to accomplish.\n",
            "[20:10.500 --> 20:21.000]  That's a very nuanced answer, and everybody here who's running a business should really think about it, because life will be the same, and then suddenly, suddenly something will, you know, then there will be a step change.\n",
            "[20:21.500 --> 20:27.000]  Vivek, I have a few more questions, but I'm sure the audience has a lot of questions for you. So, how are we doing on time?\n",
            "[20:27.500 --> 20:35.000]  Okay. So, does, okay, a lot of questions, so I'd love to, is there a mic that we can pass around?\n",
            "[20:40.500 --> 20:54.000]  Thank you. My name is Karthik. I work for IT service industry. So, you're saying that you're working on LLM, sorry, it's a fine-tuned LLM on top of LLama.\n",
            "[20:54.500 --> 21:04.000]  My basic question, fundamental question is we don't have a foundational model for India. Most of the models are basically using English or those kind of things.\n",
            "[21:05.000 --> 21:16.500]  So, for example, even Andrew was talking about the tokenizers and things like that. So, are you working on anything like that, or do you want to use mostly the existing models and run on top of it?\n",
            "[21:17.000 --> 21:20.500]  You asked a good question. You asked a cherry question for himself.\n",
            "[21:21.500 --> 21:38.000]  No, I think the interesting thing is that if you look at, and we have actually a blog on this, on our website, I think one of the things that we actually built a customized tokenizer, which actually fundamentally changes the cost of some of these generations in Indian languages.\n",
            "[21:38.000 --> 22:00.500]  And I think that we're not just fine-tuning, we're actually, we are leveraging the existing pre-training, but we are doing what's known as continual free training, which actually, but having said that, you know, I think that when we have to figure out where is the data to train an extremely large model from scratch, and some of those things are things which will happen over time.\n",
            "[22:00.500 --> 22:14.000]  But I think that, I think that, yes, I think that we will be doing various kinds of things, but the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that?\n",
            "[22:14.500 --> 22:20.000]  And that's the problem that we have, that we think we have solved, and it's going to be the heart of this OpenRT series.\n",
            "[22:20.500 --> 22:24.000]  It's extremely well explained in the blog, even I could understand it, so.\n",
            "[22:25.000 --> 22:44.500]  Hi, I'm Prashant, I work for a fintech company. My question is like, unlike China, we never had a consumer-facing application coming out from India, and in web one, web two, crypto and all, why do you think it will be different this time in like AI?\n",
            "[22:44.500 --> 23:10.000]  Because will the DPI and other things will serve the same purpose what the Great Firewall did in China, or do you think, like in, because AI is a strategic sector, no outside country can work in NASA projects, maybe, or government contract will go to them, what exactly is the moat here for an Indian company?\n",
            "[23:11.000 --> 23:36.500]  So, I think the question is, I don't know the answer to these questions, right, and I think that it's difficult to predict, but I do believe, and as I'm repeating, that the combinatorial effect of being using Gen AI at a large scale, in addition, along with the DPI work that we've done in India, will have people, and I think that in the end,\n",
            "[23:36.500 --> 23:57.000]  it is, the intent is that people need to be able to use it, and they will vote by things that are useful for them, and if that doesn't happen, you're right, and I think that we have to figure out what is the mechanism of delivery of apps, right, I mean, where do Indians consume content, that's the question.\n",
            "[23:57.000 --> 24:26.500]  I'm so sorry, but we are out of time, Vivek will be outside, so he would be able to answer the question, do we have time for one last question? Can I, can I just take one last, yeah, thank you, thank you, I'm Manish Kothari, I'm from ISBR Business School, good that I got a chance to ask you this question, during lunchtime, there were a few of our educationists whom we were talking about, and there was one from school, and we are from the MBA institutions, we were thinking of these present generations, how do we get them into what you are doing?\n",
            "[24:27.500 --> 24:49.500]  There is one thing that they have been regularly that the concentrations that they're working on, but artificial intelligence and getting into this, getting them into their academics and making them a part of it is very important, including the trainers who train them, making them future ready into what you are doing is amazing, and the speed that which is growing, it is calling for a lot of training that needs to be done.\n",
            "[24:50.000 --> 25:04.000]  Can you from your angle throw some light on how we could make them future ready? How these people who are, who are management graduates and from schools who are coming out, how do we get into this part of technology that you spoke about?\n",
            "[25:05.000 --> 25:22.000]  So this is really a challenge, because I think everyone will need to understand at some level what this technology does, and I think that we have to rethink how we get everyone into these, and this kind of education has to be at many different levels, right?\n",
            "[25:22.000 --> 25:34.000]  There are, from a core set of having people who are extremely good at some, and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools.\n",
            "[25:34.000 --> 26:03.000]  By the way, the most important thing about, and maybe that's part of what makes an LLM interesting, is that how you use it, your mileage varies by that, and to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people, and because asking the, you know, things in the right way and having the right kind of applications will make a huge difference to how people can leverage these tools.\n",
            "[26:04.000 --> 26:11.000]  Thank you very much Vivek, very good luck to Sarvam, and good luck to India, I think it's going to be a lot on your shoulders.\n"
          ]
        }
      ],
      "source": [
        "!whisper \"audio.mp3\" --model medium.en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsyWob5mqc1A"
      },
      "source": [
        "As we can see that the transcript is already time aligned, there is no need to explicitly time align. The above block produces various output files that are : audio.json , .srt, .tsv, .txt, .vtt.\n",
        "We will be using .json for semantitc chunking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFhi-vLEujQ3"
      },
      "source": [
        "The srt file could be viewed for time aligned transcript."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGAAwvDaZ_ww"
      },
      "source": [
        "## 4. Semantic Chunking of Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiHKJduTrCGq"
      },
      "source": [
        "Here, the audio.json file contained some chunks that were greater than 15sec.To make them all lesser than 15 sec and also of the desired format, we do the following modifications on the audio.json file and write it into output.json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZGzuuAfULHJ",
        "outputId": "47fa7cc2-add7-48b1-e54c-45f0af021baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output written to output.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def process_json(json_data):\n",
        "    segments = json_data.get(\"segments\", [])\n",
        "    output_list = []\n",
        "    chunk_id = 1\n",
        "    for segment in segments:\n",
        "        chunk_length = segment[\"end\"] - segment[\"start\"]\n",
        "        text = segment[\"text\"]\n",
        "        start_time = segment[\"start\"]\n",
        "        end_time = segment[\"end\"]\n",
        "\n",
        "        # Check if chunk length is greater than 15 seconds\n",
        "        if chunk_length > 15.0:\n",
        "            # Calculate mid time\n",
        "            mid_time = start_time + (end_time - start_time) / 2\n",
        "            # Split text into two parts\n",
        "            text_part1 = text[:len(text) // 2]\n",
        "            text_part2 = text[len(text) // 2:]\n",
        "\n",
        "            # Append first chunk\n",
        "            output_list.append({\n",
        "                \"chunk_id\": chunk_id,\n",
        "                \"chunk_length\": mid_time - start_time,\n",
        "                \"text\": text_part1,\n",
        "                \"start_time\": start_time,\n",
        "                \"end_time\": mid_time\n",
        "            })\n",
        "            chunk_id += 1\n",
        "\n",
        "            # Append second chunk\n",
        "            output_list.append({\n",
        "                \"chunk_id\": chunk_id,\n",
        "                \"chunk_length\": end_time - mid_time,\n",
        "                \"text\": text_part2,\n",
        "                \"start_time\": mid_time,\n",
        "                \"end_time\": end_time\n",
        "            })\n",
        "            chunk_id += 1\n",
        "        else:\n",
        "            # Append chunk as is\n",
        "            output_list.append({\n",
        "                \"chunk_id\": chunk_id,\n",
        "                \"chunk_length\": chunk_length,\n",
        "                \"text\": text,\n",
        "                \"start_time\": start_time,\n",
        "                \"end_time\": end_time\n",
        "            })\n",
        "            chunk_id += 1\n",
        "\n",
        "    return output_list\n",
        "\n",
        "# Read JSON file\n",
        "with open(\"audio.json\", \"r\") as f:\n",
        "    json_data = json.load(f)\n",
        "\n",
        "# Process JSON data\n",
        "output_list = process_json(json_data)\n",
        "\n",
        "# Write the formatted output to a JSON file\n",
        "output_file = \"output.json\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(output_list, f, indent=4)\n",
        "\n",
        "print(f\"Output written to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V9xhPARqVsk"
      },
      "source": [
        "##  GRADIO INTERFACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQyJrNUf4RWA",
        "outputId": "b319b141-1771-4b5e-ad1b-faa6ce499da4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=dd2748f6440ed5e787082632de7b86d3445f77029371d6e6202c8b916a24d42e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.31.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.3 (from gradio)\n",
            "  Downloading gradio_client-0.16.3-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/315.8 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.3->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.3->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=95c91ed59db5d51f2443246664be38faf64644ffd255cf82aa9a51d4e28a37b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.3 ffmpy-0.3.2 gradio-4.31.1 gradio-client-0.16.3 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.4 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube\n",
        "from pytube import YouTube\n",
        "import os\n",
        "!pip install ffmpeg\n",
        "import ffmpeg\n",
        "!pip install gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLMX_TpG5jw0",
        "outputId": "7927b05f-58d2-4be0-84f2-09a9e0e9981e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-9qh6aaik\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-9qh6aaik\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=00fa71a687377b0b313d422053b23bb4a196ef43868eedf50456c61bf521c2d7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7mp214v5/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [830 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,374 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,798 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,445 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,110 kB]\n",
            "Fetched 10.0 MB in 4s (2,405 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7NlsUnD1OP-"
      },
      "outputs": [],
      "source": [
        "def download_vdo_and_extract_audio(video_link):\n",
        "  yt = YouTube(video_link)\n",
        "  stream = yt.streams.first()\n",
        "  stream.download(filename=\"video.mp4\")\n",
        "  !ffprobe video.mp4  # display information about its streams, and other metadata\n",
        "  !ffmpeg -i video.mp4 -map 0:a -acodec libmp3lame audio.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGU0Kfem57UR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def process_json(json_data):\n",
        "    segments = json_data.get(\"segments\", [])\n",
        "    output_list = []\n",
        "    chunk_id = 1\n",
        "    for segment in segments:\n",
        "        chunk_length = segment[\"end\"] - segment[\"start\"]\n",
        "        text = segment[\"text\"]\n",
        "        start_time = segment[\"start\"]\n",
        "        end_time = segment[\"end\"]\n",
        "\n",
        "        # Check if chunk length is greater than 15 seconds\n",
        "        if chunk_length > 15.0:\n",
        "            # Calculate mid time\n",
        "            mid_time = start_time + (end_time - start_time) / 2\n",
        "            # Split text into two parts\n",
        "            text_part1 = text[:len(text) // 2]\n",
        "            text_part2 = text[len(text) // 2:]\n",
        "\n",
        "            # Append first chunk\n",
        "            output_list.append({\n",
        "                \"chunk_id\": chunk_id,\n",
        "                \"chunk_length\": mid_time - start_time,\n",
        "                \"text\": text_part1,\n",
        "                \"start_time\": start_time,\n",
        "                \"end_time\": mid_time\n",
        "            })\n",
        "            chunk_id += 1\n",
        "\n",
        "            # Append second chunk\n",
        "            output_list.append({\n",
        "                \"chunk_id\": chunk_id,\n",
        "                \"chunk_length\": end_time - mid_time,\n",
        "                \"text\": text_part2,\n",
        "                \"start_time\": mid_time,\n",
        "                \"end_time\": end_time\n",
        "            })\n",
        "            chunk_id += 1\n",
        "        else:\n",
        "            # Append chunk as is\n",
        "            output_list.append({\n",
        "                \"chunk_id\": chunk_id,\n",
        "                \"chunk_length\": chunk_length,\n",
        "                \"text\": text,\n",
        "                \"start_time\": start_time,\n",
        "                \"end_time\": end_time\n",
        "            })\n",
        "            chunk_id += 1\n",
        "\n",
        "    return output_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w2TwDoRe0hrL",
        "outputId": "223fadfe-2ae7-4011-9369-bfbf8cfc0708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://074f2d16c032035ef1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://074f2d16c032035ef1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2020-06-09T06:22:53.000000Z\n",
            "  Duration: 00:00:58.54, start: 0.000000, bitrate: 301 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 169 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2020-06-09T06:22:53.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 06/08/2020.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2020-06-09T06:22:53.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 06/08/2020.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2020-06-09T06:22:53.000000Z\n",
            "  Duration: 00:00:58.54, start: 0.000000, bitrate: 301 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 169 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2020-06-09T06:22:53.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 06/08/2020.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2020-06-09T06:22:53.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 06/08/2020.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to 'audio.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    TSSE            : Lavf58.76.100\n",
            "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2020-06-09T06:22:53.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 06/08/2020.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libmp3lame\n",
            "size=     915kB time=00:00:58.51 bitrate= 128.2kbits/s speed=40.5x    \n",
            "video:0kB audio:915kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.036924%\n",
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:15<00:00, 98.2MiB/s]\n",
            "[00:00.000 --> 00:18.240]  Two little hands do clap clap clap Two little legs go tap tap tap\n",
            "[00:18.240 --> 00:27.120]  Two little eyes open wide One little head goes side to side\n",
            "[00:27.120 --> 00:37.840]  Side to side, side to side Two little hands do clap clap clap\n",
            "[00:37.840 --> 00:48.640]  Two little legs go tap tap tap Two little eyes open wide\n",
            "[00:48.640 --> 00:55.440]  One little head goes side to side Side to side, side to side\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Google\n",
            "  Duration: 00:26:15.06, start: 0.000000, bitrate: 453 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 354 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Google\n",
            "  Duration: 00:26:15.06, start: 0.000000, bitrate: 453 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 354 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "File 'audio.mp3' already exists. Overwrite? [y/N] y\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to 'audio.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    TSSE            : Lavf58.76.100\n",
            "  Stream #0:0(eng): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libmp3lame\n",
            "size=   24611kB time=00:26:15.05 bitrate= 128.0kbits/s speed=44.8x    \n",
            "video:0kB audio:24611kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.001373%\n",
            "[00:00.000 --> 00:04.500]  Congratulations to you, Mr. Raghavan, for that. Thank you so much for joining us. Over to you.\n",
            "[00:08.500 --> 00:10.500]  Hi, everybody. How are you?\n",
            "[00:11.500 --> 00:17.500]  Okay, I am not hearing this at all. Is this like a post-lunch energy downer or something?\n",
            "[00:18.000 --> 00:20.500]  Let's hear it. Are you guys awake?\n",
            "[00:21.500 --> 00:27.000]  Alright. You better be because we have a superstar guest here.\n",
            "[00:27.500 --> 00:31.500]  You heard the $41 million and I didn't hear honestly anything she said after that.\n",
            "[00:32.500 --> 00:38.500]  So, we're going to ask for about $40 million from him by the end of this conversation, okay?\n",
            "[00:39.500 --> 00:45.500]  But let's get started. I want to introduce Vivek and Pratyush, his co-founder who is not here.\n",
            "[00:46.000 --> 00:50.500]  We wanted to start with playing a video of what OpenHati does.\n",
            "[00:51.000 --> 00:55.500]  I encourage all of you to go to the website servom.ai and check it out.\n",
            "[00:56.500 --> 01:04.000]  But let me start by introducing Vivek. Vivek is a dear friend and he is very, very modest, one of the most modest guys that I know.\n",
            "[01:04.500 --> 01:12.000]  But his personal journey, Vivek, you got a PhD from Carnegie Mellon. You started and sold a company to Magma.\n",
            "[01:12.500 --> 01:17.000]  And Vivek and I moved back to India. We were both in the valley on the same day, actually.\n",
            "[01:17.500 --> 01:25.000]  And you've been in India for the last 16 years. And what most people don't know is your journey at Aadhaar.\n",
            "[01:25.500 --> 01:38.000]  Vivek spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today.\n",
            "[01:38.500 --> 01:47.000]  So, please give it up. Honestly, when I think of selfless service, truly selfless service, I always think of Vivek.\n",
            "[01:48.000 --> 01:54.500]  And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush, his other co-founder.\n",
            "[01:55.000 --> 02:05.500]  Pratyush had a PhD from ETH at Zurich. He was at IBM Research. He was at Microsoft Research, playing a key role, and a faculty at IIT Madras, and at AI for Bharat.\n",
            "[02:06.000 --> 02:13.500]  So, that's a little brief introduction about them. These guys are modest, modest engineers, so they don't toot their own horn.\n",
            "[02:13.500 --> 02:17.000]  So, forgive me for tooting their horn in this case.\n",
            "[02:17.500 --> 02:25.000]  But let's jump right in about the money. Funding. 41 million bucks, man. That's a lot of money, right?\n",
            "[02:25.500 --> 02:32.000]  Every entrepreneur here is saying, what the hell did these guys do? What did the investors see to write such a big cheque?\n",
            "[02:32.500 --> 02:40.000]  No, I think it's a new trend of what's going on in India. I think that for the very first time,\n",
            "[02:40.000 --> 02:45.500]  I think the investors have looked at, you know, let's try and build something deep tech out of the country,\n",
            "[02:46.000 --> 02:50.500]  and let's try to figure out how to build something as a foundational technology out of the country.\n",
            "[02:51.000 --> 02:59.500]  And that's really what's really exciting, you know? And I think that about, you know, as Balazs was mentioning,\n",
            "[03:00.000 --> 03:06.500]  for the past 15 years, I've been kind of working in kind of, you know, both digital public infrastructure\n",
            "[03:06.500 --> 03:13.000]  and kind of non-profit kind of things. But when this whole thing of generative AI came about,\n",
            "[03:13.500 --> 03:19.000]  I, you know, we said, okay, how can I actually make a difference in this space?\n",
            "[03:19.500 --> 03:25.000]  And I said, maybe this is the opportunity to actually come out and really build something,\n",
            "[03:25.500 --> 03:32.000]  you know, and the only way that we realize that you can do it is actually in the private sector.\n",
            "[03:32.000 --> 03:37.500]  And I think that's, and then we went out there and we said we want to build something which is a continuation, right?\n",
            "[03:38.000 --> 03:42.500]  I mean, and fundamentally, the question is, the reason of what we want to do at ServamAI\n",
            "[03:43.000 --> 03:49.500]  is we want to basically make generative AI available and accessible to the people in the country.\n",
            "[03:50.000 --> 03:55.500]  And that's the intent. And when we said that we want to do this, there was a resonance in the investment community.\n",
            "[03:56.500 --> 04:03.000]  And I think it's a responsibility to really to show that something like this can be built out of India.\n",
            "[04:03.500 --> 04:09.000]  So we see that as confidence and a responsibility. And I also hope it's a trend that, you know,\n",
            "[04:09.500 --> 04:14.000]  that there are many more people like us who are backed, because if you look at it,\n",
            "[04:14.500 --> 04:19.000]  maybe it's a large number in, you know, in the Indian context, but in the global context,\n",
            "[04:19.500 --> 04:25.000]  I think there is just, there should be many, many more entrepreneurs who are backed to do things in India.\n",
            "[04:25.500 --> 04:31.000]  I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Krutim.\n",
            "[04:31.500 --> 04:36.000]  So we're going to come back to that question. But again, 41 million dollars.\n",
            "[04:36.500 --> 04:41.000]  I mean, all of what you said, you know, two million dollars, you know, that's a good amount of money\n",
            "[04:41.500 --> 04:47.000]  for a startup which, you know, which has not yet built anything. What are you going to do with all this money?\n",
            "[04:48.500 --> 04:52.000]  I can solve the problem. I can have a perfect solution for the problem.\n",
            "[04:52.000 --> 04:57.500]  I think in the last week I've got lots of calls from lots of people telling me how I can.\n",
            "[04:58.000 --> 05:02.500]  I know you first, okay? I'll be landed in the country the same day. I'm in front of the queue.\n",
            "[05:03.000 --> 05:09.500]  No, but honestly, I think the key thing in this is to putting together an amazing team.\n",
            "[05:10.000 --> 05:14.500]  And we actually have an amazing team, but we believe that it is talent that will drive this kind of thing,\n",
            "[05:15.000 --> 05:19.500]  and so it is to get key talent. And of course the other thing is compute.\n",
            "[05:19.500 --> 05:25.000]  This is extremely expensive compute-wise to actually do these kinds of things.\n",
            "[05:25.500 --> 05:30.000]  And I think that those are the two primary things that, you know, we'd use this for.\n",
            "[05:30.500 --> 05:37.000]  Okay. I'm computing in my own head as an entrepreneur. Talent, okay, you have like 20, 15 people.\n",
            "[05:37.500 --> 05:41.000]  How much are you paying these guys? But okay, you won't touch on that.\n",
            "[05:41.500 --> 05:45.000]  But let's talk about what you guys actually built. What is OpenHati?\n",
            "[05:45.500 --> 05:49.000]  How would you explain OpenHati to many people here who might not have known about it?\n",
            "[05:49.500 --> 05:57.000]  So, I think OpenHati is, so first of all, right, we come from, I personally come from the open source ecosystem,\n",
            "[05:57.500 --> 06:05.000]  and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful.\n",
            "[06:05.500 --> 06:12.000]  And as a result of that, one of the first things we did was, hey, there are these open source large language models that exist, right?\n",
            "[06:12.000 --> 06:18.500]  I mean, everybody knows about the Llama family from Meta. There are others like Mistral.\n",
            "[06:19.000 --> 06:22.500]  There are a bunch of open source, you know, large language models.\n",
            "[06:23.000 --> 06:30.500]  And then we said, is there any way that they can existing open source model and teach it language skills, right?\n",
            "[06:31.000 --> 06:36.500]  I mean, and that is really the, you know, what we decide, what we said that can we do something like that?\n",
            "[06:37.500 --> 06:47.000]  And is this a, you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages?\n",
            "[06:47.500 --> 06:55.000]  Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things.\n",
            "[06:55.500 --> 07:01.000]  And I think that how do you actually take and make it understand Indian language, understand Indian context,\n",
            "[07:01.000 --> 07:04.500]  and all of those things in actually a, in an efficient way.\n",
            "[07:05.000 --> 07:07.500]  And therefore, this was an attempt to do that.\n",
            "[07:08.000 --> 07:13.500]  And it is, OpenHati is, you know, is currently based on the Llama 7 billion model,\n",
            "[07:14.000 --> 07:21.500]  but we will be releasing many more models in different languages, different sizes, and things like that as part of this, as part of this series.\n",
            "[07:22.000 --> 07:27.500]  And of course, you know, we will be building further models on those and doing other things to actually,\n",
            "[07:27.500 --> 07:30.000]  and we will also have endpoints that people can use.\n",
            "[07:30.500 --> 07:35.000]  So, therefore, it is not, it is definitely, you know, something that people can use to things.\n",
            "[07:35.500 --> 07:40.000]  And that is the essence of what this OpenHati is.\n",
            "[07:40.500 --> 07:47.000]  So, what does it mean to people in the audience here who are either doing their own startups or a business or developers?\n",
            "[07:47.500 --> 07:50.000]  How should they look at OpenAI? Oh, sorry.\n",
            "[07:50.500 --> 07:52.000]  Not OpenAI.\n",
            "[07:52.000 --> 08:00.500]  No, no, no. I think the way you look at it is that we, one of the important things that we are doing is we are not just building models.\n",
            "[08:01.000 --> 08:10.500]  We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of models,\n",
            "[08:11.000 --> 08:14.500]  some which are from us, some which are open source, some which may not be open source,\n",
            "[08:14.500 --> 08:26.000]  and actually to actually pull together and figure out how to deploy, you know, generative AI applications at scale and understand and evaluate their performance in an efficient manner.\n",
            "[08:26.500 --> 08:28.000]  And that is something that we are planning to do.\n",
            "[08:28.500 --> 08:33.000]  And this platform is, you know, in the next couple of months will be coming out there.\n",
            "[08:33.500 --> 08:35.000]  It will be available to developers.\n",
            "[08:35.500 --> 08:42.000]  But, of course, those who want to start with the open source things and hack with that, of course, please go ahead and do that as well.\n",
            "[08:42.500 --> 08:44.000]  That is phenomenal.\n",
            "[08:44.500 --> 08:49.000]  But how does it compare to OpenAI itself or Google?\n",
            "[08:49.500 --> 08:53.000]  See, at least the things that we are doing now, right?\n",
            "[08:53.500 --> 09:02.000]  I mean, one of the things that when we thought about building server, we said we want to build a full stack generative AI company and different people have,\n",
            "[09:02.500 --> 09:08.000]  and our understanding of full stack is that we need to know how to train models from scratch.\n",
            "[09:08.500 --> 09:14.000]  We need to know how to kind of figure out how to deploy models to solve real world use cases.\n",
            "[09:14.500 --> 09:22.000]  And we need to play in the ecosystem to make sure that we can actually deploy population scale applications, right?\n",
            "[09:22.500 --> 09:25.000]  So we were thinking about all of these things.\n",
            "[09:25.500 --> 09:29.000]  But still the models we were talking about are, you know, fairly small models.\n",
            "[09:29.500 --> 09:31.000]  They are fairly small models, right?\n",
            "[09:31.500 --> 09:35.000]  The 7 to maybe up to 70 billion kind of range we are talking about.\n",
            "[09:35.500 --> 09:40.000]  While these models like OpenAI and Google are obviously much bigger models, right?\n",
            "[09:40.000 --> 09:49.500]  But we want to understand the techniques and be able to build that muscle to do all of these things to make it available to people.\n",
            "[09:50.000 --> 10:00.500]  Now those models are, I mean, as I said, I think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day,\n",
            "[10:00.500 --> 10:12.000]  we believe that these smaller models can do many, many kind of domain specific tasks extremely well, probably even better than the larger models.\n",
            "[10:12.500 --> 10:14.000]  And that is really one of the key areas.\n",
            "[10:14.500 --> 10:17.000]  And so therefore the value of these kinds of things, right?\n",
            "[10:17.500 --> 10:22.000]  We are not aiming in these set of models to build any AGI, right?\n",
            "[10:22.500 --> 10:23.000]  That's not our goal here.\n",
            "[10:23.000 --> 10:32.500]  Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things.\n",
            "[10:33.000 --> 10:34.500]  And obviously all of this unique to India.\n",
            "[10:35.000 --> 10:36.500]  But what is unique about India?\n",
            "[10:37.000 --> 10:46.500]  I mean, is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems?\n",
            "[10:47.500 --> 10:53.000]  So I think that, I mean, there are quite a few things that are unique about India, right?\n",
            "[10:53.500 --> 10:57.000]  The first thing is I think that we are a voice first nation.\n",
            "[10:57.500 --> 11:01.000]  So therefore I think voice has to be the core to doing things.\n",
            "[11:01.500 --> 11:09.000]  The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective.\n",
            "[11:09.000 --> 11:18.500]  Now I would say that there are lots of interesting use cases where you can use open AI and the cost structure works depending on your application.\n",
            "[11:19.000 --> 11:24.500]  But when you want to scale things to a massive level and make it work, then you have to figure out how small models work.\n",
            "[11:25.000 --> 11:28.500]  So that's something that is also specific to India.\n",
            "[11:29.000 --> 11:35.500]  The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure.\n",
            "[11:35.500 --> 11:47.000]  When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that.\n",
            "[11:47.500 --> 11:52.000]  That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways.\n",
            "[11:52.500 --> 11:56.000]  And as a part of Aadhaar, building Aadhaar, no better person than you.\n",
            "[11:57.000 --> 12:08.500]  So in summary, what I'm hearing is small models specialized with, trained with Indic specific language data suited for Indian problems at a compelling cost point will be suited for us.\n",
            "[12:09.000 --> 12:12.500]  We're not solving some world autonomous vehicles or some complex problem.\n",
            "[12:13.000 --> 12:17.500]  We're solving some basic problems specifically focused on voice with multiple languages.\n",
            "[12:18.000 --> 12:20.500]  That is what you see as the future. Am I paraphrasing this correctly?\n",
            "[12:21.500 --> 12:27.000]  No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy.\n",
            "[12:27.500 --> 12:33.000]  But we will be building, you know, custom models to solve various other kinds of problems as well, right?\n",
            "[12:33.500 --> 12:43.000]  It's not just limited to, I think, in different domains, working in different domains, making, building things based on unique data that enterprises have and things like that.\n",
            "[12:43.500 --> 12:45.000]  So that's something that we'll also look at.\n",
            "[12:45.500 --> 12:46.000]  Fair enough.\n",
            "[12:46.000 --> 12:50.500]  So coming back to the elephant in the room, no fun intended with open Hati.\n",
            "[12:51.000 --> 12:54.500]  What about Bhavesh Agarwal and Krutram? What is your take on that?\n",
            "[12:55.000 --> 12:57.500]  I think it's great. I think it's wonderful, right?\n",
            "[12:58.000 --> 13:05.500]  I mean, the fact that the technology AI is so important that we need multiple people working on it.\n",
            "[13:06.000 --> 13:11.500]  The fact that there are other people thinking is actually validates that this is an important problem to be solved.\n",
            "[13:11.500 --> 13:17.000]  And I think that, and we need everybody to come together and do that.\n",
            "[13:17.500 --> 13:20.000]  So I really welcome that. I think it's great.\n",
            "[13:20.500 --> 13:26.000]  And I think that there will be different people will have different takes as to how to solve this kind of problem.\n",
            "[13:26.500 --> 13:31.000]  And hopefully as a result of that, the entire ecosystem benefits.\n",
            "[13:31.500 --> 13:36.000]  I have one more question, and then I want to talk about some of the predictions that you've boldly made.\n",
            "[13:36.500 --> 13:41.000]  So Vivek, I usually ask people about what do you think the future will be, and everybody usually hedges.\n",
            "[13:41.500 --> 13:45.000]  So Vivek, what do you think is going to happen by December 2024?\n",
            "[13:45.500 --> 13:48.000]  What do you think sitting in this room one year later we can expect?\n",
            "[13:48.500 --> 13:52.000]  And you made three bold predictions, so I want to talk about that.\n",
            "[13:52.500 --> 13:54.000]  Before that, I have one last question.\n",
            "[13:54.500 --> 13:58.000]  What are the top three applications that you think are relevant for India?\n",
            "[13:58.500 --> 14:00.000]  You heard Sridhar talk about medical.\n",
            "[14:00.500 --> 14:05.000]  Quick summary, what do you think the top three apps are for India for AI?\n",
            "[14:05.000 --> 14:14.500]  So, I mean, I think that, as you said, things like education and medical are clearly areas where I think that things can be leveraged.\n",
            "[14:15.000 --> 14:21.500]  The whole idea of all these kind of the DPI aspect of it is another major application where things can happen.\n",
            "[14:22.000 --> 14:24.500]  And here I'm talking about country specific work.\n",
            "[14:25.000 --> 14:29.500]  And I think the whole idea which Sridhar also talked about was the concept of software, right?\n",
            "[14:29.500 --> 14:38.000]  And I think that, and clearly we have a very large software industry, and how to reimagine those things in this context is also something that's going to be big.\n",
            "[14:38.500 --> 14:44.000]  Fair enough. Are you guys ready for Vivek Raghavan's bold predictions?\n",
            "[14:44.500 --> 14:48.000]  Yes? No? I'm not getting any yes here. This is like a big deal.\n",
            "[14:48.500 --> 14:52.000]  He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it?\n",
            "[14:53.000 --> 14:59.500]  All right. So I asked him, what do you think, you know, a year later, what do you think we can expect?\n",
            "[15:00.000 --> 15:05.500]  And he came up with three things, and usually people give very blah answers when you ask a question like this because they don't want to be caught wrong.\n",
            "[15:06.000 --> 15:07.500]  Not Vivek. Vivek is bold.\n",
            "[15:08.000 --> 15:13.500]  So he basically said three things, and I'm going to list out the three things and then ask him about it.\n",
            "[15:14.000 --> 15:21.500]  So number one, he says, I would prefer to talk to an automated customer service than a real person because they'll give me a better answer.\n",
            "[15:22.000 --> 15:24.500]  So that is Vivek Raghavan's prediction number one.\n",
            "[15:25.000 --> 15:32.500]  So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut in India.\n",
            "[15:33.000 --> 15:37.500]  He thinks there will be too much GPU, okay? So if you want a short Nvidia stock, this is a good time.\n",
            "[15:38.000 --> 15:44.500]  And number three, which was extremely unexpected, he said some companies will suddenly die.\n",
            "[15:45.000 --> 15:48.500]  Okay. So Vivek, these are not what I expected.\n",
            "[15:49.500 --> 15:56.000]  So do you want to quickly talk about each of them, why you just came up with these, and then we'll throw the open for audience questions.\n",
            "[15:56.500 --> 16:03.000]  So I don't think I quite said it the way that Vala and I am thinking, but it's interesting.\n",
            "[16:04.000 --> 16:20.500]  But I think the first thing that we said is I think that, and I don't think that this is, I think there will come a time when, you know, in areas of customer service, et cetera, when you want to do something very specific.\n",
            "[16:21.000 --> 16:30.500]  Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot.\n",
            "[16:30.500 --> 16:45.000]  But I think that there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to, could give.\n",
            "[16:45.500 --> 16:57.000]  And I think that that's just, I just said that there will come a time where, you know, it's not a human you're talking to, but it's probably more likely to solve your intent than the human person.\n",
            "[16:58.000 --> 17:02.500]  That's just something that I think that could happen.\n",
            "[17:03.000 --> 17:07.500]  Okay, definitely controversial, but we'll let it go. What about the GPU glut?\n",
            "[17:08.000 --> 17:19.500]  No, no, yeah, so I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go, right?\n",
            "[17:20.500 --> 17:34.000]  I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of forms, and I think that that will always go in a cycle.\n",
            "[17:34.500 --> 17:40.000]  But we may find out that there are many, many more interesting problems that people will be able to solve.\n",
            "[17:41.000 --> 17:55.500]  I still remember, you know, we were at a Gen AI event in Bangalore, and we were talking to people, and we said, you know, how many people have access to, you know, four A-hundreds?\n",
            "[17:56.000 --> 18:01.500]  This was the question that I'd asked, and nobody in the room, and these are all extremely enthusiastic Gen AI people, and nobody had access.\n",
            "[18:01.500 --> 18:15.000]  And I think that thing is going to change. You will be able to get these kinds of things, and people who want to hack and do things will have access to these things without, you know, having to write a, you know, a major check to do.\n",
            "[18:15.500 --> 18:23.000]  Vivek is also a semiconductor guy, before he went into Aadhaar, so I would take his predictions very seriously, so I don't know what I, I'm going to sell my media stock.\n",
            "[18:23.500 --> 18:27.000]  I would not do that, but that's not what I said.\n",
            "[18:27.500 --> 18:30.000]  I want to blame you for this, if it goes up.\n",
            "[18:31.000 --> 18:38.500]  But the third one is pretty strange. You know, companies are born, companies die, but you said some companies will suddenly die. What does that mean?\n",
            "[18:39.000 --> 18:46.500]  No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI.\n",
            "[18:46.500 --> 18:54.000]  AI is a tool, right? And you have to use that, and you have to use that within your business process, right?\n",
            "[18:54.500 --> 19:11.000]  And how AI is being used, and so, and what's going to happen is that, I mean, I think this is true with, with, you know, when someone said in terms of, you know, people, they said that the people who leverage AI will be, will, will be more effective than those who don't leverage AI.\n",
            "[19:11.000 --> 19:22.500]  And that's true for organizations also. Organizations that leverage AI in, fundamentally in their core business processes, will be more effective than those who don't, right?\n",
            "[19:23.000 --> 19:29.500]  And I think that's the thing, and you won't know the difference until one day it becomes too obvious, and it will be too late.\n",
            "[19:30.000 --> 19:36.500]  And I think that's the reason why everybody needs to think about what it means for your business.\n",
            "[19:36.500 --> 19:50.000]  Because you will, everything will be fine. Everything will be fine, and one day somebody in your, either, either, either your competitor in your space or somebody brand new coming into your space will be re-imagining your business process completely.\n",
            "[19:51.000 --> 19:58.500]  And at that stage you will find that it's, you know, it's a, it's a very big, very tall, you know, mountain to climb.\n",
            "[19:59.000 --> 20:10.500]  And that's why I think it's important for both people and entities to think about how they will, you know, they, they will upgrade themselves or they will modify their business processes to, you know, to accomplish.\n",
            "[20:10.500 --> 20:21.000]  That's a very nuanced answer, and everybody here who's running a business should really think about it, because life will be the same, and then suddenly, suddenly something will, you know, then there will be a step change.\n",
            "[20:21.500 --> 20:27.000]  Vivek, I have a few more questions, but I'm sure the audience has a lot of questions for you. So, how are we doing on time?\n",
            "[20:27.500 --> 20:35.000]  Okay. So, does, okay, a lot of questions, so I'd love to, is there a mic that we can pass around?\n",
            "[20:40.500 --> 20:54.000]  Thank you. My name is Karthik. I work for IT service industry. So, you're saying that you're working on LLM, sorry, it's a fine-tuned LLM on top of LLama.\n",
            "[20:54.500 --> 21:04.000]  My basic question, fundamental question is we don't have a foundational model for India. Most of the models are basically using English or those kind of things.\n",
            "[21:05.000 --> 21:16.500]  So, for example, even Andrew was talking about the tokenizers and things like that. So, are you working on anything like that, or do you want to use mostly the existing models and run on top of it?\n",
            "[21:17.000 --> 21:20.500]  You asked a good question. You asked a cherry question for himself.\n",
            "[21:21.500 --> 21:38.000]  No, I think the interesting thing is that if you look at, and we have actually a blog on this, on our website, I think one of the things that we actually built a customized tokenizer, which actually fundamentally changes the cost of some of these generations in Indian languages.\n",
            "[21:38.000 --> 22:00.500]  And I think that we're not just fine-tuning, we're actually, we are leveraging the existing pre-training, but we are doing what's known as continual free training, which actually, but having said that, you know, I think that when we have to figure out where is the data to train an extremely large model from scratch, and some of those things are things which will happen over time.\n",
            "[22:00.500 --> 22:14.000]  But I think that, I think that, yes, I think that we will be doing various kinds of things, but the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that?\n",
            "[22:14.500 --> 22:20.000]  And that's the problem that we have, that we think we have solved, and it's going to be the heart of this OpenRT series.\n",
            "[22:20.500 --> 22:24.000]  It's extremely well explained in the blog, even I could understand it, so.\n",
            "[22:25.000 --> 22:44.500]  Hi, I'm Prashant, I work for a fintech company. My question is like, unlike China, we never had a consumer-facing application coming out from India, and in web one, web two, crypto and all, why do you think it will be different this time in like AI?\n",
            "[22:44.500 --> 23:10.000]  Because will the DPI and other things will serve the same purpose what the Great Firewall did in China, or do you think, like in, because AI is a strategic sector, no outside country can work in NASA projects, maybe, or government contract will go to them, what exactly is the moat here for an Indian company?\n",
            "[23:11.000 --> 23:36.500]  So, I think the question is, I don't know the answer to these questions, right, and I think that it's difficult to predict, but I do believe, and as I'm repeating, that the combinatorial effect of being using Gen AI at a large scale, in addition, along with the DPI work that we've done in India, will have people, and I think that in the end,\n",
            "[23:36.500 --> 23:57.000]  it is, the intent is that people need to be able to use it, and they will vote by things that are useful for them, and if that doesn't happen, you're right, and I think that we have to figure out what is the mechanism of delivery of apps, right, I mean, where do Indians consume content, that's the question.\n",
            "[23:57.000 --> 24:26.500]  I'm so sorry, but we are out of time, Vivek will be outside, so he would be able to answer the question, do we have time for one last question? Can I, can I just take one last, yeah, thank you, thank you, I'm Manish Kothari, I'm from ISBR Business School, good that I got a chance to ask you this question, during lunchtime, there were a few of our educationists whom we were talking about, and there was one from school, and we are from the MBA institutions, we were thinking of these present generations, how do we get them into what you are doing?\n",
            "[24:27.500 --> 24:49.500]  There is one thing that they have been regularly that the concentrations that they're working on, but artificial intelligence and getting into this, getting them into their academics and making them a part of it is very important, including the trainers who train them, making them future ready into what you are doing is amazing, and the speed that which is growing, it is calling for a lot of training that needs to be done.\n",
            "[24:50.000 --> 25:04.000]  Can you from your angle throw some light on how we could make them future ready? How these people who are, who are management graduates and from schools who are coming out, how do we get into this part of technology that you spoke about?\n",
            "[25:05.000 --> 25:22.000]  So this is really a challenge, because I think everyone will need to understand at some level what this technology does, and I think that we have to rethink how we get everyone into these, and this kind of education has to be at many different levels, right?\n",
            "[25:22.000 --> 25:34.000]  There are, from a core set of having people who are extremely good at some, and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools.\n",
            "[25:34.000 --> 26:03.000]  By the way, the most important thing about, and maybe that's part of what makes an LLM interesting, is that how you use it, your mileage varies by that, and to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people, and because asking the, you know, things in the right way and having the right kind of applications will make a huge difference to how people can leverage these tools.\n",
            "[26:04.000 --> 26:11.000]  Thank you very much Vivek, very good luck to Sarvam, and good luck to India, I think it's going to be a lot on your shoulders.\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Google\n",
            "  Duration: 00:26:15.06, start: 0.000000, bitrate: 453 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 354 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Google\n",
            "  Duration: 00:26:15.06, start: 0.000000, bitrate: 453 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 354 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "File 'audio.mp3' already exists. Overwrite? [y/N] y\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to 'audio.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    TSSE            : Lavf58.76.100\n",
            "  Stream #0:0(eng): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libmp3lame\n",
            "size=   24611kB time=00:26:15.05 bitrate= 128.0kbits/s speed=44.9x    \n",
            "video:0kB audio:24611kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.001373%\n",
            "[00:00.000 --> 00:04.500]  Congratulations to you, Mr. Raghavan, for that. Thank you so much for joining us. Over to you.\n",
            "[00:08.500 --> 00:10.500]  Hi, everybody. How are you?\n",
            "[00:11.500 --> 00:17.500]  Okay, I am not hearing this at all. Is this like a post-lunch energy downer or something?\n",
            "[00:18.000 --> 00:20.500]  Let's hear it. Are you guys awake?\n",
            "[00:21.500 --> 00:27.000]  Alright. You better be because we have a superstar guest here.\n",
            "[00:27.500 --> 00:31.500]  You heard the $41 million and I didn't hear honestly anything she said after that.\n",
            "[00:32.500 --> 00:38.500]  So, we're going to ask for about $40 million from him by the end of this conversation, okay?\n",
            "[00:39.500 --> 00:45.500]  But let's get started. I want to introduce Vivek and Pratyush, his co-founder who is not here.\n",
            "[00:46.000 --> 00:50.500]  We wanted to start with playing a video of what OpenHati does.\n",
            "[00:51.000 --> 00:55.500]  I encourage all of you to go to the website servom.ai and check it out.\n",
            "[00:56.500 --> 01:04.000]  But let me start by introducing Vivek. Vivek is a dear friend and he is very, very modest, one of the most modest guys that I know.\n",
            "[01:04.500 --> 01:12.000]  But his personal journey, Vivek, you got a PhD from Carnegie Mellon. You started and sold a company to Magma.\n",
            "[01:12.500 --> 01:17.000]  And Vivek and I moved back to India. We were both in the valley on the same day, actually.\n",
            "[01:17.500 --> 01:25.000]  And you've been in India for the last 16 years. And what most people don't know is your journey at Aadhaar.\n",
            "[01:25.500 --> 01:38.000]  Vivek spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today.\n",
            "[01:38.500 --> 01:47.000]  So, please give it up. Honestly, when I think of selfless service, truly selfless service, I always think of Vivek.\n",
            "[01:48.000 --> 01:54.500]  And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush, his other co-founder.\n",
            "[01:55.000 --> 02:05.500]  Pratyush had a PhD from ETH at Zurich. He was at IBM Research. He was at Microsoft Research, playing a key role, and a faculty at IIT Madras, and at AI for Bharat.\n",
            "[02:06.000 --> 02:13.500]  So, that's a little brief introduction about them. These guys are modest, modest engineers, so they don't toot their own horn.\n",
            "[02:13.500 --> 02:17.000]  So, forgive me for tooting their horn in this case.\n",
            "[02:17.500 --> 02:25.000]  But let's jump right in about the money. Funding. 41 million bucks, man. That's a lot of money, right?\n",
            "[02:25.500 --> 02:32.000]  Every entrepreneur here is saying, what the hell did these guys do? What did the investors see to write such a big cheque?\n",
            "[02:32.500 --> 02:40.000]  No, I think it's a new trend of what's going on in India. I think that for the very first time,\n",
            "[02:40.000 --> 02:45.500]  I think the investors have looked at, you know, let's try and build something deep tech out of the country,\n",
            "[02:46.000 --> 02:50.500]  and let's try to figure out how to build something as a foundational technology out of the country.\n",
            "[02:51.000 --> 02:59.500]  And that's really what's really exciting, you know? And I think that about, you know, as Balazs was mentioning,\n",
            "[03:00.000 --> 03:06.500]  for the past 15 years, I've been kind of working in kind of, you know, both digital public infrastructure\n",
            "[03:06.500 --> 03:13.000]  and kind of non-profit kind of things. But when this whole thing of generative AI came about,\n",
            "[03:13.500 --> 03:19.000]  I, you know, we said, okay, how can I actually make a difference in this space?\n",
            "[03:19.500 --> 03:25.000]  And I said, maybe this is the opportunity to actually come out and really build something,\n",
            "[03:25.500 --> 03:32.000]  you know, and the only way that we realize that you can do it is actually in the private sector.\n",
            "[03:32.000 --> 03:37.500]  And I think that's, and then we went out there and we said we want to build something which is a continuation, right?\n",
            "[03:38.000 --> 03:42.500]  I mean, and fundamentally, the question is, the reason of what we want to do at ServamAI\n",
            "[03:43.000 --> 03:49.500]  is we want to basically make generative AI available and accessible to the people in the country.\n",
            "[03:50.000 --> 03:55.500]  And that's the intent. And when we said that we want to do this, there was a resonance in the investment community.\n",
            "[03:56.500 --> 04:03.000]  And I think it's a responsibility to really to show that something like this can be built out of India.\n",
            "[04:03.500 --> 04:09.000]  So we see that as confidence and a responsibility. And I also hope it's a trend that, you know,\n",
            "[04:09.500 --> 04:14.000]  that there are many more people like us who are backed, because if you look at it,\n",
            "[04:14.500 --> 04:19.000]  maybe it's a large number in, you know, in the Indian context, but in the global context,\n",
            "[04:19.500 --> 04:25.000]  I think there is just, there should be many, many more entrepreneurs who are backed to do things in India.\n",
            "[04:25.500 --> 04:31.000]  I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Krutim.\n",
            "[04:31.500 --> 04:36.000]  So we're going to come back to that question. But again, 41 million dollars.\n",
            "[04:36.500 --> 04:41.000]  I mean, all of what you said, you know, two million dollars, you know, that's a good amount of money\n",
            "[04:41.500 --> 04:47.000]  for a startup which, you know, which has not yet built anything. What are you going to do with all this money?\n",
            "[04:48.500 --> 04:52.000]  I can solve the problem. I can have a perfect solution for the problem.\n",
            "[04:52.000 --> 04:57.500]  I think in the last week I've got lots of calls from lots of people telling me how I can.\n",
            "[04:58.000 --> 05:02.500]  I know you first, okay? I'll be landed in the country the same day. I'm in front of the queue.\n",
            "[05:03.000 --> 05:09.500]  No, but honestly, I think the key thing in this is to putting together an amazing team.\n",
            "[05:10.000 --> 05:14.500]  And we actually have an amazing team, but we believe that it is talent that will drive this kind of thing,\n",
            "[05:15.000 --> 05:19.500]  and so it is to get key talent. And of course the other thing is compute.\n",
            "[05:19.500 --> 05:25.000]  This is extremely expensive compute-wise to actually do these kinds of things.\n",
            "[05:25.500 --> 05:30.000]  And I think that those are the two primary things that, you know, we'd use this for.\n",
            "[05:30.500 --> 05:37.000]  Okay. I'm computing in my own head as an entrepreneur. Talent, okay, you have like 20, 15 people.\n",
            "[05:37.500 --> 05:41.000]  How much are you paying these guys? But okay, you won't touch on that.\n",
            "[05:41.500 --> 05:45.000]  But let's talk about what you guys actually built. What is OpenHati?\n",
            "[05:45.500 --> 05:49.000]  How would you explain OpenHati to many people here who might not have known about it?\n",
            "[05:49.500 --> 05:57.000]  So, I think OpenHati is, so first of all, right, we come from, I personally come from the open source ecosystem,\n",
            "[05:57.500 --> 06:05.000]  and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful.\n",
            "[06:05.500 --> 06:12.000]  And as a result of that, one of the first things we did was, hey, there are these open source large language models that exist, right?\n",
            "[06:12.000 --> 06:18.500]  I mean, everybody knows about the Llama family from Meta. There are others like Mistral.\n",
            "[06:19.000 --> 06:22.500]  There are a bunch of open source, you know, large language models.\n",
            "[06:23.000 --> 06:30.500]  And then we said, is there any way that they can existing open source model and teach it language skills, right?\n",
            "[06:31.000 --> 06:36.500]  I mean, and that is really the, you know, what we decide, what we said that can we do something like that?\n",
            "[06:37.500 --> 06:47.000]  And is this a, you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages?\n",
            "[06:47.500 --> 06:55.000]  Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things.\n",
            "[06:55.500 --> 07:01.000]  And I think that how do you actually take and make it understand Indian language, understand Indian context,\n",
            "[07:01.000 --> 07:04.500]  and all of those things in actually a, in an efficient way.\n",
            "[07:05.000 --> 07:07.500]  And therefore, this was an attempt to do that.\n",
            "[07:08.000 --> 07:13.500]  And it is, OpenHati is, you know, is currently based on the Llama 7 billion model,\n",
            "[07:14.000 --> 07:21.500]  but we will be releasing many more models in different languages, different sizes, and things like that as part of this, as part of this series.\n",
            "[07:22.000 --> 07:27.500]  And of course, you know, we will be building further models on those and doing other things to actually,\n",
            "[07:27.500 --> 07:30.000]  and we will also have endpoints that people can use.\n",
            "[07:30.500 --> 07:35.000]  So, therefore, it is not, it is definitely, you know, something that people can use to things.\n",
            "[07:35.500 --> 07:40.000]  And that is the essence of what this OpenHati is.\n",
            "[07:40.500 --> 07:47.000]  So, what does it mean to people in the audience here who are either doing their own startups or a business or developers?\n",
            "[07:47.500 --> 07:50.000]  How should they look at OpenAI? Oh, sorry.\n",
            "[07:50.500 --> 07:52.000]  Not OpenAI.\n",
            "[07:52.000 --> 08:00.500]  No, no, no. I think the way you look at it is that we, one of the important things that we are doing is we are not just building models.\n",
            "[08:01.000 --> 08:10.500]  We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of models,\n",
            "[08:11.000 --> 08:14.500]  some which are from us, some which are open source, some which may not be open source,\n",
            "[08:14.500 --> 08:26.000]  and actually to actually pull together and figure out how to deploy, you know, generative AI applications at scale and understand and evaluate their performance in an efficient manner.\n",
            "[08:26.500 --> 08:28.000]  And that is something that we are planning to do.\n",
            "[08:28.500 --> 08:33.000]  And this platform is, you know, in the next couple of months will be coming out there.\n",
            "[08:33.500 --> 08:35.000]  It will be available to developers.\n",
            "[08:35.500 --> 08:42.000]  But, of course, those who want to start with the open source things and hack with that, of course, please go ahead and do that as well.\n",
            "[08:42.500 --> 08:44.000]  That is phenomenal.\n",
            "[08:44.500 --> 08:49.000]  But how does it compare to OpenAI itself or Google?\n",
            "[08:49.500 --> 08:53.000]  See, at least the things that we are doing now, right?\n",
            "[08:53.500 --> 09:02.000]  I mean, one of the things that when we thought about building server, we said we want to build a full stack generative AI company and different people have,\n",
            "[09:02.500 --> 09:08.000]  and our understanding of full stack is that we need to know how to train models from scratch.\n",
            "[09:08.500 --> 09:14.000]  We need to know how to kind of figure out how to deploy models to solve real world use cases.\n",
            "[09:14.500 --> 09:22.000]  And we need to play in the ecosystem to make sure that we can actually deploy population scale applications, right?\n",
            "[09:22.500 --> 09:25.000]  So we were thinking about all of these things.\n",
            "[09:25.500 --> 09:29.000]  But still the models we were talking about are, you know, fairly small models.\n",
            "[09:29.500 --> 09:31.000]  They are fairly small models, right?\n",
            "[09:31.500 --> 09:35.000]  The 7 to maybe up to 70 billion kind of range we are talking about.\n",
            "[09:35.500 --> 09:40.000]  While these models like OpenAI and Google are obviously much bigger models, right?\n",
            "[09:40.000 --> 09:49.500]  But we want to understand the techniques and be able to build that muscle to do all of these things to make it available to people.\n",
            "[09:50.000 --> 10:00.500]  Now those models are, I mean, as I said, I think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day,\n",
            "[10:00.500 --> 10:12.000]  we believe that these smaller models can do many, many kind of domain specific tasks extremely well, probably even better than the larger models.\n",
            "[10:12.500 --> 10:14.000]  And that is really one of the key areas.\n",
            "[10:14.500 --> 10:17.000]  And so therefore the value of these kinds of things, right?\n",
            "[10:17.500 --> 10:22.000]  We are not aiming in these set of models to build any AGI, right?\n",
            "[10:22.500 --> 10:23.000]  That's not our goal here.\n",
            "[10:23.000 --> 10:32.500]  Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things.\n",
            "[10:33.000 --> 10:34.500]  And obviously all of this unique to India.\n",
            "[10:35.000 --> 10:36.500]  But what is unique about India?\n",
            "[10:37.000 --> 10:46.500]  I mean, is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems?\n",
            "[10:47.500 --> 10:53.000]  So I think that, I mean, there are quite a few things that are unique about India, right?\n",
            "[10:53.500 --> 10:57.000]  The first thing is I think that we are a voice first nation.\n",
            "[10:57.500 --> 11:01.000]  So therefore I think voice has to be the core to doing things.\n",
            "[11:01.500 --> 11:09.000]  The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective.\n",
            "[11:09.000 --> 11:18.500]  Now I would say that there are lots of interesting use cases where you can use open AI and the cost structure works depending on your application.\n",
            "[11:19.000 --> 11:24.500]  But when you want to scale things to a massive level and make it work, then you have to figure out how small models work.\n",
            "[11:25.000 --> 11:28.500]  So that's something that is also specific to India.\n",
            "[11:29.000 --> 11:35.500]  The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure.\n",
            "[11:35.500 --> 11:47.000]  When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that.\n",
            "[11:47.500 --> 11:52.000]  That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways.\n",
            "[11:52.500 --> 11:56.000]  And as a part of Aadhaar, building Aadhaar, no better person than you.\n",
            "[11:57.000 --> 12:08.500]  So in summary, what I'm hearing is small models specialized with, trained with Indic specific language data suited for Indian problems at a compelling cost point will be suited for us.\n",
            "[12:09.000 --> 12:12.500]  We're not solving some world autonomous vehicles or some complex problem.\n",
            "[12:13.000 --> 12:17.500]  We're solving some basic problems specifically focused on voice with multiple languages.\n",
            "[12:18.000 --> 12:20.500]  That is what you see as the future. Am I paraphrasing this correctly?\n",
            "[12:21.500 --> 12:27.000]  No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy.\n",
            "[12:27.500 --> 12:33.000]  But we will be building, you know, custom models to solve various other kinds of problems as well, right?\n",
            "[12:33.500 --> 12:43.000]  It's not just limited to, I think, in different domains, working in different domains, making, building things based on unique data that enterprises have and things like that.\n",
            "[12:43.500 --> 12:45.000]  So that's something that we'll also look at.\n",
            "[12:45.500 --> 12:46.000]  Fair enough.\n",
            "[12:46.000 --> 12:50.500]  So coming back to the elephant in the room, no fun intended with open Hati.\n",
            "[12:51.000 --> 12:54.500]  What about Bhavesh Agarwal and Krutram? What is your take on that?\n",
            "[12:55.000 --> 12:57.500]  I think it's great. I think it's wonderful, right?\n",
            "[12:58.000 --> 13:05.500]  I mean, the fact that the technology AI is so important that we need multiple people working on it.\n",
            "[13:06.000 --> 13:11.500]  The fact that there are other people thinking is actually validates that this is an important problem to be solved.\n",
            "[13:11.500 --> 13:17.000]  And I think that, and we need everybody to come together and do that.\n",
            "[13:17.500 --> 13:20.000]  So I really welcome that. I think it's great.\n",
            "[13:20.500 --> 13:26.000]  And I think that there will be different people will have different takes as to how to solve this kind of problem.\n",
            "[13:26.500 --> 13:31.000]  And hopefully as a result of that, the entire ecosystem benefits.\n",
            "[13:31.500 --> 13:36.000]  I have one more question, and then I want to talk about some of the predictions that you've boldly made.\n",
            "[13:36.500 --> 13:41.000]  So Vivek, I usually ask people about what do you think the future will be, and everybody usually hedges.\n",
            "[13:41.500 --> 13:45.000]  So Vivek, what do you think is going to happen by December 2024?\n",
            "[13:45.500 --> 13:48.000]  What do you think sitting in this room one year later we can expect?\n",
            "[13:48.500 --> 13:52.000]  And you made three bold predictions, so I want to talk about that.\n",
            "[13:52.500 --> 13:54.000]  Before that, I have one last question.\n",
            "[13:54.500 --> 13:58.000]  What are the top three applications that you think are relevant for India?\n",
            "[13:58.500 --> 14:00.000]  You heard Sridhar talk about medical.\n",
            "[14:00.500 --> 14:05.000]  Quick summary, what do you think the top three apps are for India for AI?\n",
            "[14:05.000 --> 14:14.500]  So, I mean, I think that, as you said, things like education and medical are clearly areas where I think that things can be leveraged.\n",
            "[14:15.000 --> 14:21.500]  The whole idea of all these kind of the DPI aspect of it is another major application where things can happen.\n",
            "[14:22.000 --> 14:24.500]  And here I'm talking about country specific work.\n",
            "[14:25.000 --> 14:29.500]  And I think the whole idea which Sridhar also talked about was the concept of software, right?\n",
            "[14:29.500 --> 14:38.000]  And I think that, and clearly we have a very large software industry, and how to reimagine those things in this context is also something that's going to be big.\n",
            "[14:38.500 --> 14:44.000]  Fair enough. Are you guys ready for Vivek Raghavan's bold predictions?\n",
            "[14:44.500 --> 14:48.000]  Yes? No? I'm not getting any yes here. This is like a big deal.\n",
            "[14:48.500 --> 14:52.000]  He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it?\n",
            "[14:53.000 --> 14:59.500]  All right. So I asked him, what do you think, you know, a year later, what do you think we can expect?\n",
            "[15:00.000 --> 15:05.500]  And he came up with three things, and usually people give very blah answers when you ask a question like this because they don't want to be caught wrong.\n",
            "[15:06.000 --> 15:07.500]  Not Vivek. Vivek is bold.\n",
            "[15:08.000 --> 15:13.500]  So he basically said three things, and I'm going to list out the three things and then ask him about it.\n",
            "[15:14.000 --> 15:21.500]  So number one, he says, I would prefer to talk to an automated customer service than a real person because they'll give me a better answer.\n",
            "[15:22.000 --> 15:24.500]  So that is Vivek Raghavan's prediction number one.\n",
            "[15:25.000 --> 15:32.500]  So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut in India.\n",
            "[15:33.000 --> 15:37.500]  He thinks there will be too much GPU, okay? So if you want a short Nvidia stock, this is a good time.\n",
            "[15:38.000 --> 15:44.500]  And number three, which was extremely unexpected, he said some companies will suddenly die.\n",
            "[15:45.000 --> 15:48.500]  Okay. So Vivek, these are not what I expected.\n",
            "[15:49.500 --> 15:56.000]  So do you want to quickly talk about each of them, why you just came up with these, and then we'll throw the open for audience questions.\n",
            "[15:56.500 --> 16:03.000]  So I don't think I quite said it the way that Vala and I am thinking, but it's interesting.\n",
            "[16:04.000 --> 16:20.500]  But I think the first thing that we said is I think that, and I don't think that this is, I think there will come a time when, you know, in areas of customer service, et cetera, when you want to do something very specific.\n",
            "[16:21.000 --> 16:30.500]  Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot.\n",
            "[16:30.500 --> 16:45.000]  But I think that there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to, could give.\n",
            "[16:45.500 --> 16:57.000]  And I think that that's just, I just said that there will come a time where, you know, it's not a human you're talking to, but it's probably more likely to solve your intent than the human person.\n",
            "[16:58.000 --> 17:02.500]  That's just something that I think that could happen.\n",
            "[17:03.000 --> 17:07.500]  Okay, definitely controversial, but we'll let it go. What about the GPU glut?\n",
            "[17:08.000 --> 17:19.500]  No, no, yeah, so I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go, right?\n",
            "[17:20.500 --> 17:34.000]  I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of forms, and I think that that will always go in a cycle.\n",
            "[17:34.500 --> 17:40.000]  But we may find out that there are many, many more interesting problems that people will be able to solve.\n",
            "[17:41.000 --> 17:55.500]  I still remember, you know, we were at a Gen AI event in Bangalore, and we were talking to people, and we said, you know, how many people have access to, you know, four A-hundreds?\n",
            "[17:56.000 --> 18:01.500]  This was the question that I'd asked, and nobody in the room, and these are all extremely enthusiastic Gen AI people, and nobody had access.\n",
            "[18:01.500 --> 18:15.000]  And I think that thing is going to change. You will be able to get these kinds of things, and people who want to hack and do things will have access to these things without, you know, having to write a, you know, a major check to do.\n",
            "[18:15.500 --> 18:23.000]  Vivek is also a semiconductor guy, before he went into Aadhaar, so I would take his predictions very seriously, so I don't know what I, I'm going to sell my media stock.\n",
            "[18:23.500 --> 18:27.000]  I would not do that, but that's not what I said.\n",
            "[18:27.500 --> 18:30.000]  I want to blame you for this, if it goes up.\n",
            "[18:31.000 --> 18:38.500]  But the third one is pretty strange. You know, companies are born, companies die, but you said some companies will suddenly die. What does that mean?\n",
            "[18:39.000 --> 18:46.500]  No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI.\n",
            "[18:46.500 --> 18:54.000]  AI is a tool, right? And you have to use that, and you have to use that within your business process, right?\n",
            "[18:54.500 --> 19:11.000]  And how AI is being used, and so, and what's going to happen is that, I mean, I think this is true with, with, you know, when someone said in terms of, you know, people, they said that the people who leverage AI will be, will, will be more effective than those who don't leverage AI.\n",
            "[19:11.000 --> 19:22.500]  And that's true for organizations also. Organizations that leverage AI in, fundamentally in their core business processes, will be more effective than those who don't, right?\n",
            "[19:23.000 --> 19:29.500]  And I think that's the thing, and you won't know the difference until one day it becomes too obvious, and it will be too late.\n",
            "[19:30.000 --> 19:36.500]  And I think that's the reason why everybody needs to think about what it means for your business.\n",
            "[19:36.500 --> 19:50.000]  Because you will, everything will be fine. Everything will be fine, and one day somebody in your, either, either, either your competitor in your space or somebody brand new coming into your space will be re-imagining your business process completely.\n",
            "[19:51.000 --> 19:58.500]  And at that stage you will find that it's, you know, it's a, it's a very big, very tall, you know, mountain to climb.\n",
            "[19:59.000 --> 20:10.500]  And that's why I think it's important for both people and entities to think about how they will, you know, they, they will upgrade themselves or they will modify their business processes to, you know, to accomplish.\n",
            "[20:10.500 --> 20:21.000]  That's a very nuanced answer, and everybody here who's running a business should really think about it, because life will be the same, and then suddenly, suddenly something will, you know, then there will be a step change.\n",
            "[20:21.500 --> 20:27.000]  Vivek, I have a few more questions, but I'm sure the audience has a lot of questions for you. So, how are we doing on time?\n",
            "[20:27.500 --> 20:35.000]  Okay. So, does, okay, a lot of questions, so I'd love to, is there a mic that we can pass around?\n",
            "[20:40.500 --> 20:54.000]  Thank you. My name is Karthik. I work for IT service industry. So, you're saying that you're working on LLM, sorry, it's a fine-tuned LLM on top of LLama.\n",
            "[20:54.500 --> 21:04.000]  My basic question, fundamental question is we don't have a foundational model for India. Most of the models are basically using English or those kind of things.\n",
            "[21:05.000 --> 21:16.500]  So, for example, even Andrew was talking about the tokenizers and things like that. So, are you working on anything like that, or do you want to use mostly the existing models and run on top of it?\n",
            "[21:17.000 --> 21:20.500]  You asked a good question. You asked a cherry question for himself.\n",
            "[21:21.500 --> 21:38.000]  No, I think the interesting thing is that if you look at, and we have actually a blog on this, on our website, I think one of the things that we actually built a customized tokenizer, which actually fundamentally changes the cost of some of these generations in Indian languages.\n",
            "[21:38.000 --> 22:00.500]  And I think that we're not just fine-tuning, we're actually, we are leveraging the existing pre-training, but we are doing what's known as continual free training, which actually, but having said that, you know, I think that when we have to figure out where is the data to train an extremely large model from scratch, and some of those things are things which will happen over time.\n",
            "[22:00.500 --> 22:14.000]  But I think that, I think that, yes, I think that we will be doing various kinds of things, but the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that?\n",
            "[22:14.500 --> 22:20.000]  And that's the problem that we have, that we think we have solved, and it's going to be the heart of this OpenRT series.\n",
            "[22:20.500 --> 22:24.000]  It's extremely well explained in the blog, even I could understand it, so.\n",
            "[22:25.000 --> 22:44.500]  Hi, I'm Prashant, I work for a fintech company. My question is like, unlike China, we never had a consumer-facing application coming out from India, and in web one, web two, crypto and all, why do you think it will be different this time in like AI?\n",
            "[22:44.500 --> 23:10.000]  Because will the DPI and other things will serve the same purpose what the Great Firewall did in China, or do you think, like in, because AI is a strategic sector, no outside country can work in NASA projects, maybe, or government contract will go to them, what exactly is the moat here for an Indian company?\n",
            "[23:11.000 --> 23:36.500]  So, I think the question is, I don't know the answer to these questions, right, and I think that it's difficult to predict, but I do believe, and as I'm repeating, that the combinatorial effect of being using Gen AI at a large scale, in addition, along with the DPI work that we've done in India, will have people, and I think that in the end,\n",
            "[23:36.500 --> 23:57.000]  it is, the intent is that people need to be able to use it, and they will vote by things that are useful for them, and if that doesn't happen, you're right, and I think that we have to figure out what is the mechanism of delivery of apps, right, I mean, where do Indians consume content, that's the question.\n",
            "[23:57.000 --> 24:26.500]  I'm so sorry, but we are out of time, Vivek will be outside, so he would be able to answer the question, do we have time for one last question? Can I, can I just take one last, yeah, thank you, thank you, I'm Manish Kothari, I'm from ISBR Business School, good that I got a chance to ask you this question, during lunchtime, there were a few of our educationists whom we were talking about, and there was one from school, and we are from the MBA institutions, we were thinking of these present generations, how do we get them into what you are doing?\n",
            "[24:27.500 --> 24:49.500]  There is one thing that they have been regularly that the concentrations that they're working on, but artificial intelligence and getting into this, getting them into their academics and making them a part of it is very important, including the trainers who train them, making them future ready into what you are doing is amazing, and the speed that which is growing, it is calling for a lot of training that needs to be done.\n",
            "[24:50.000 --> 25:04.000]  Can you from your angle throw some light on how we could make them future ready? How these people who are, who are management graduates and from schools who are coming out, how do we get into this part of technology that you spoke about?\n",
            "[25:05.000 --> 25:22.000]  So this is really a challenge, because I think everyone will need to understand at some level what this technology does, and I think that we have to rethink how we get everyone into these, and this kind of education has to be at many different levels, right?\n",
            "[25:22.000 --> 25:34.000]  There are, from a core set of having people who are extremely good at some, and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools.\n",
            "[25:34.000 --> 26:03.000]  By the way, the most important thing about, and maybe that's part of what makes an LLM interesting, is that how you use it, your mileage varies by that, and to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people, and because asking the, you know, things in the right way and having the right kind of applications will make a huge difference to how people can leverage these tools.\n",
            "[26:04.000 --> 26:11.000]  Thank you very much Vivek, very good luck to Sarvam, and good luck to India, I think it's going to be a lot on your shoulders.\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from pytube import YouTube\n",
        "import json\n",
        "\n",
        "def semantic_chunking(video_link):\n",
        "    download_vdo_and_extract_audio(video_link)\n",
        "    !whisper \"audio.mp3\" --model medium.en\n",
        "\n",
        "    with open(\"audio.json\", \"r\") as f:\n",
        "      json_data = json.load(f)\n",
        "\n",
        "    # Process JSON data\n",
        "    output_list = process_json(json_data)\n",
        "    return output_list\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=semantic_chunking,\n",
        "    inputs=gr.Textbox(lines=5, placeholder=\"Enter the youtube url here....\"),\n",
        "    outputs=gr.JSON()  # Specify the output component\n",
        ")\n",
        "interface.launch()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt5sxyzJHxzM"
      },
      "source": [
        "The Gradio interface is running fine ,however it took much more time to run in interface as compared to normally running, as the video duration is long (about 26 mins). For short videos , it runs pretty quickly. It is a future scope to improve it for longer videos.\n",
        "I am attaching a screenshot that shows the output:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qIAgju4JDVr"
      },
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABGsAAAJHCAYAAAAnl9vqAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAANkqSURBVHhe7P0LgFXVfTf8f2GY4Q4KjlwMdRSwKUqIEFOcvKRgbSSP/0olJulDJKlGAn1C9F+f6eOFat7KA8Z/pj4VeVoRo4kofYgGCn2taKxYeTtSlVHCJUYgHjI6XIZBYLjNDMP8129d9ll7n30ucz8zfD+wZu211m+vfTmH4Zx11t6nV7MCIiIiIiIiIiLKC71tTkREREREREREeYCDNUREREREREREeYSDNUREREREREREeYSDNUREREREREREeaTdbzDcdO4czp1rBu9bTERERO2tV69e6N27Fwp6t8/nTXzdQkRERB2lLa9b2m2wRro523SOL3aIiIiow8mLnz4FvXXeGnzdQkRERJ2lNa9b2u0yKL7gISIios7iBltai69biIiIqLO05nVLuwzWyBRivuAhIiKiziSvPeQ1SEvxdQsRERF1tpa+bmmXwRq51puIiIios7XmNQhftxAREVFXaMlrkHYZrOGnU0RERNQVWvMahK9biIiIqCu05DVIu9xguKHxrF1K79TpM6g/09Cq6cpERER0fpFvTejbrwgD+vezNekVFfaxS7nJ9XVLQ0MjzjY1obmbz8Rp7U2YiYiIzkctHSLp1VtuHlyAoqLCdn3d0uGDNfIi5/jxk+jXV15w9UWh2jG+aCAiIqJ05KVJo3ptcep0Pc7UN2DIkIH6RVA67TlYI69bTpw4pV9s9e9XhIIM2+0Oqg8cxqgRw/nai4iIKAfyGmT/wVqMHnmRrclNk3r9cPpMg/6wZ9CgAe3yuqXdvg0qjhyoDNQMGtgfFwwdpEea+GKBiIiIMpHXCvKaQV47yGsIeS3RDp8tZSXbkIGaIYMH6u1294EapzPOHRERUU/Q2v8z5TWDvHaQ1xDyWqI9/u/t0MEaGVWSGTWy00REREQtJa8h5LWEvKboaLKN/v36om9Roa0hIiIiyp28hpDXEu3xuqXDBmtkJKm+vkFf+kRERETUWvJaQl5TdOQMEem7ob5Rv8DiLGAiIiJqDXkNIa8l5DVFW1+3dOhgjXwtldyjhoiIiKi15LWEvKbo6MGac+fOoaCgQycdExERUTdUe+Qo/vWVN4Ik5XTktUTj2bP5PVgj+OkUERERtYV7LdHRgzXyjZV83UJERERR//nO+/gvN0zHH17zeZ2EDNjEDdq01+sWfnxERERElIN/euH/we8+rrYl4NjxupS61jq+czN21tlCjlqzDhEREbXey6/+O3bvTaSkjsDBGiIiIqIc/d5nRtslYOiQwao8ypbSO171Ht597z18bAdWGg9sx0fHzPLxfbtx/Nhu/HtFJd569x1VfwYH9n2M2tA6qu4DFafXOIqP9h0FQuvoBiIiIupAMotm3NhLMfWazwdp+LALbGv742ANERERURYye2bo0MG2lDRE1VVV7belVMf/3xX4h52DcMWYfqh47uf48Jx6sbf9dfzb70z7b//9Lfx24ChcVHAWw8eMx8iBR7HtF2vwytFRap0z2Lj6dRyHqluv4vQaH+Hf/v0jILSObiAiIqIOMn5ciV3qPBysISIiIspix67dGDp4kC0lDR0yCMfqTthS1Bns/HV/XP+V8Rhy0R/gy+P2o+LXtsnXZxD69+mDAUMuULkqNxZjwsSRap1r8fm+H9tBmojoOkRERNRhxo/lYE2g8fRRnD5rCwF/GnAb1X+MnTKNWJw9geOpG0vyY4mIiOi881++8kf43cf79X1qhOQy20Zm1Vw1YbyuS9UPQwbW4Zi9/On06T4YGhnvOXvOLsQ6gNojfVBoS9q5DK9XiIiIqEMdOXI0fL+aPR1zvxqRp4M1Z7Fz3U+wscoWA/404DY69iusk2nESuPODVj2b2Y5lhdLRERE56fjdcm7+Zr71YzWAziynM6V143H+8/8BD/96QqsOV2KmZcCIy8dhQP/9ix+unot3jlo4i6/vB/eWbcab+rXPlXY+NPV+OmKNdgx6cu4EiNx2eWfmrp1v8IBvUZ0HSIiIupIcn8a901Qjlwe1VGzbno1t8P3YDY0pn7K09TUhE+P1mH0yItsTRpnT+B00yD072vL9apcMAh9Gk8AfQehUA8nncVpmWJcdAJv/v3rGHHPt6FP0bkzOH3yDNDfnwJsYhv7DMKQTPOCD/0r/ufGUfibb18d2ofG02dQqNYz21P9yn75sbLN02qTA/uZfoiIiKjDVR84jAsvGIyCggJbk1RU2LLrgNK9bqk9cgyfGX2xrUnlZtW4wZloOb2zaKzvg0L3WkecVXV9wrNmGuvVa5rCo3j9x6+q1zpzcOVZ1e4dWqNap1Ct4zPr9LOvl1LJeRt58TD07s0r34mIiLI5d+4caj89jiGDB6JvUWhua4t8XH0Iw4cNbdPrlq7/n/vk23js2bfQqAtH8ebKNXi/Cdj5wk/w+mFVde5jvPL3j+GxX/wr1jz/Ev7dfah1+j389O9+gn+prMS6//W/8cohVSexyx7DP7z6JjaufAx/928fm9hsfr0Wf/emfE51AK8vW4G/e/oneP5f1uBHf/ss3q03Ic6Bf/sZ1vyWU5CJiIjONzIo4w/MRMvpRQZqRGSgRhT2lUGXPuh/wSDVFh6oEdGBGmHWsQUiIiJqFw0NZoSiK3X9f+9DP4drTu4ygyJ1lXh/wAR8wXtB0/jeK6i49Cbc+xdz8Be3z8If2ddEH//bmyj60+/jG390HebMvQzv/fuvTWzJbPz3r92Eb9w5G5dveQVvRQZbshuEP/r2fNwxZz5u/uxH2LHHViunt6/Gz3Ej/mJi6g0GiYiIiNruInx5/mxcaUtERETUeXr16oVBA/ri1OkzXT5gkwefxVyEa75wBu9vO4Pj23ajcNLVoU+aao+cwJhxqTfuO6zqf1exGj9drdLrRzHykn4m9rLLbMRluGzMCRw/Zos5K5QPuwLBjf/2v4mV/7ofjU22TEREREREREQ9SmFhIfoU9Na3dak7cQr1XTRokxcTZ4dcMxnY8Sbe2t4f114dvhfM8GGDULVntymcO40GO3gyctQgDL3qJvzFnDkmlV4Wid2ND6sGYfhQU2y78fjGX38H13y03lxyRURERJTH5FPBtlxvT0REdL6RmTVynxm5Z83AAX1R39CA48dP6HvAtSS1h/y4yrnv1bim91t4bdjV+HxkjwqvvgGl+36O/7lyNf5xxavYaQe1Rv7x13D5lhX4O/lmhKdX4Oc7z6Jwytfwp8c2mNi/24ADf3RD6JKqkKEXYvhvt+Pd5Bc7ZDZqFEb2vghf/tp4vLf6X3Eg41dtEhEREXUdmbp99NgJDOhfpF94EhERUW7k/80+ffqgf/9+GDJoAAYP6o9hFwzChUMHZk0SN/zCweil/rRV138bVI7k2w7kJnpRjaf9b42y6k+gsTD8TVLhiUvqxA9W7aE4IiIiylfyKVVXfxtUdyDHcep0vZ62PaB/Xwwa2F+fMw7YEBERtYwbKmnNkMmBQ0fa/Lql2wzWtN5RfPTebtTaknEBrrh6PIbYEhEREeW3zhqs6e5fcS3737eojz4nRUVyH74+HKghIiLqZO3xuuU8GKwhIiKi7q4zBmuOHDmOi4YP0Z+gtcPLo07nBmVkwEbOk+QcqCEiIup8HKwhIiKi80JnDNbI65aRFw+zNd2XG6DhQA0REVHXaI/XLbxbCxEREZEls1G6e5JBGg7UEBERdW8crCEiIiIiIiIiyiMcrCEiIiIiIiIiyiMcrCEiIiIiIiIiyiMcrCEiIiIiIiIiyiMcrCEiIiIiIiIiyiN599XdJ06exukz9Th79izavmdERESUL+QLivr06YP+/fpi0MD+tjY3nfXV3S193UJEREQU1R6vW/JmsOasjS/o3VvtfAF69w5/5SS/gpKIiKj7ib7MOHeuWb1uaELTuXP6RUyfmBcxcfJrsGY7lk+Yh3K9PAdrd92JyXqZiIiIqIcN1tTUHtU7LQM1MjATHZzhYA0REVH3E32ZIWVJMmAjrx+Kh19gWzLLu8Ga+R/hmytuQrGtISIiInJ6zGCNXPrU0NCI/v0K0bt3b53c4AwHaYiIiLo/93JD8nPnzun81OkGFBUV5nRJFAdriIiIqLvoMYM1Mqumf78ivdNuoMYlIiIi6hncSw4ZrJEkrx9On2nIaXYNB2uIiIiou+gxgzX7Dx7GMHsgnFVDRETUM7mXHJLLYI28VjiiXiuMGpH9tQIHa4iIiKi7aI/XLXnx1d3y2s2fTeMSERER9Rxx/9e3/SMjIiIiop4nLwZrhHvRRkRERD0f/98nIiIiSi9vBmuIiIiIiIiIiIiDNUREREREREREeYWDNUREREQttXkprpkwFSUTlqHSVhERERG1l+4xWFNfjZ2762yh4x3fncBxuyzb3vNJgy30AJ18LjMJnef29GkCO9M8ZvV1dahvsoW2yrAdIiLqySZi4a4tSOh0JybbWiIiIqL20j0Ga46+i8fXJ2zBV41Nr1Xb5TpUvra9Hd78J/Cy6rOvLdW//Sq21hfZUr7zz0caac9lZwuf55bJcpwfbcDjb0cGpOqrsf6H96L8p8/gwVvvxcaDtj4nDdj59L2Y841v63TP0x+iXqrjtpNOXQIV/6cc5a/U2orsal5ZiiUZ4qX9nheSj6WUn91mlnc+PQ8L/uqHuOevJT2BisPJ9uOvlWPJa26/G1BRXo5Nqp2IiIiIiIjyQ/e6DKqpAcc/9WZG1H2ITW8nbN1+bH3pNzjk2k+ZGQ8yk+K4fmedVK9ijp+yBdVnvd/+u3dRc/lEO4jQgK3vF+Gqy2Wd5AyK+jpvNsUptT2Vgm3IPvrLajsZ13XH4q8n6r026d/rw/XrBH2GzkeGbQnpw+9T6LpInC+mPXQuhYrR7Wr/j7vt+8uOPc/wZ7r4+5jp+CPHKfTj7O+HkO269fqOxqwHf4RFP7gTj/zgImx6t1Y1h/cpWg4c3oQnf3sTnvn5s1it0qIbh4cHmfzjk3MU8zjWH69TPw5jj7+P6Y7XOXUYVdFj8p0qwrE3VicHnlT8cXc+jgzGV+/9WzzyY0kLUHpRsn3ItBswdN0rqJLA323AGtxg2omIiIiIiCgvdJ/Bmt0vovyHT2DN39+NG8vfRb3Mrnh8A7ZufwVrntuAtaueR8WOCvzzcyr/BKj8hz/HgnvL8fhPn8fj3/02lm+TN9MN2Pn4Qjz+xm9Q8bNyrPlAvbHe+CB+f/EbZqaEUrP1BMZ9cbApNP0GO/t+AVfKoM3jS7BJT0b4EGv+6/ex5reyXI31i36BPQdewf/42YdSoWct/PHfVZj+3n0C5ZtrM69bIMvK8U1Y8ohdD3XY9DcrsPUsULXhh7jth/+Cl9ctwW1/rd5gy5vxwxvxP/5hu44EtmNl2UbUhM7HK9h5qhYby54IrqOv/IcfYqObPbH1GZQ/8jTWPPkg5nz/FbWucmo7lt+5BP9cUYFn71SxkZkn9ZVP4Lb5T2DTG/+CJeVvqDf91dj41/PwoHrT/88/nId7NtiZLttU3J3lKP/H5/Hkojvw4JOrsfzv7PIryVko7jwfUsf37G6pUce89EY8XmEGPSr/vhwVp+T4l+LBn2zCpnUP4rZHoo+7Os46tR9/pfbjBRXz+FI8qx5Tcfy1ZXhQtvvDO7DgBbtv+lyr7fzrYcz4wnDsee5e+1goH/wUd23YhYrH3WwUm15Qj2vfvhi6q0I9r0zfQ0YM17moemkZyv/+eawp/z7mPL4d9Wkex76XTETpxNG61vEfk5p//SFW2lkxuavDlFtKUfETt70c9Z2Ib15fgTXqXO98aTuum+sGJ4mIiIiIiCgfdJ/Bmkv/FGX/807M+9s78WcvvIs9GI0Z352OMVNuwbwffAv/9S9uwZTLp+M7P1iAGb8nK4zGV39QhjJVXvTILdixXt7oH8aOyhJMmf4FzPzLMnzzs0UYcuOPkPjb6fbNah22HhiGKRfqAvDrrcAXrlALRbjqD4GK99Wb9d/+Csdv/BKqttWq8A+x9ZIpuPLyz2HK1l+hCg3YsX00vlf0LnY2ATtVzJTPD8+8rtkScOEMzOrzCjZ9qpbrt2PrhdMxBe9izT9NxEM/noNv3v63eGjKi3jWDmak8s/HLZhsx5tifX4Oyu5fgHn3/Ahlv/c8Xv+tDIo8g75/+bf49o03YN79U7BpvRl8Mqrxzz8+gm8vuxOzbp6Dh+5R5+s/V2PN5xfhkdtvwbd//LeY/E+rUWFHDIZMV/3/fxeodBP2fHoFFqptlS26BYe2u0t2kud5zJTPYetWVa+Oeeclt6Pff/5Gtatzc3gKrlLHMOam+/HQD27CzK/fjhnbK7AzcpxX7nL7cRNm3XM/vq0eUzFk2nw8ZLeLN7abASmlZsPj2PmnD2HmCODKaZ/DprfMPu1881eYMe3zKP2Bm41i09fV4z94Oh76x+mo+vvvY/b3l2Hj7uRjMOaG+Si7R53Lv/1bfLPyFWwdEPM4dthISB3qh07HvEs3YKUejPS9i8f/0ly2NeeHbwTH7xT/l9vQ7/nv48mTt+hzQURERERERPmj+wzWFHnveE815DCTQL1p72MXR47GuE8O47h6o//NH9+A4z+5FwvufRE73SUmbnZL3VZUjfwSim1x59vAlElmecjnp+DQ+79BzbZqjJldiqHbt+P4rl8BE0tU6xWYMv5d7Dz4G1T2nYJvTmzA1t3V2PPryzBOvRHOvK5ThNKZw1FRod6Av10BTP8c+h5VfUz5fYyxEWOumIiqw8nZKa1WkDyXxZcPQc1RoObjBHZseAIrH1dpbTXGXT7IRoha1Ay5ClcNsEXl+MFqTPkDt/+jMX5Kte5H62P7H1iEId62Av55Hj8FV72rzs1OdT7+8Gu48tRW7PzkA+wZ/1ndfrzyp7jnr57Axnc/wqGYcSq9H6HzaPX1tnvWPVtqUfHSIJT+ob0H0VWlmPLmu6jCh6jYVorS31PtcTNrxIgv4Ns/Xom1D34BO+4ptzOlFHes6hyM+aycg5jH0UZ0lDG3fAt4cgP0BKXAF/CDfzSXba3+2+nBczrQdyJKL9uO8ddxVg0RUUepLJdvizJpeQd+ZVTNurs7ZTtERETUebrPYE06Td6wjXozf8Yu6sJZu/jrHagYf5l5w3rhRMwq+xGeuLkaj8vNW+UeK7aL+vcTGDLJXeKSwI76K3ClG8gZ8TmUHtyOlw+MxuQRV2DKgF9hTaXMnDFTWK78w4uwY+N29P3872PIVVfg2JuvJmfOZFm33g0aTZqJMW+8gn/eDJROKQIuGI1xW7djj70PyZ7t2zFuhLtEy+70qTocMkuGfz6EXrcBx9xAighi6rCzoghjLlFv+MeW4OJpt2PeDxaYdL25ZMfs23AUH9+BHW4/5b4nI0Zjq5sp06TO1dbRKL7AFLMJneeC38fkC3+Dl7f3w+QrB2PcHxxHxUs7MEbPaPoQax4vwrz/tQCzZkzE+IFmFc0eQ2g/hD1X8YZjZvkC71s7rsDML29HxYYKVF0/A2NUe+zMmk+rUeUGZ0Z8AVMmHE7e58gNBDV9iK2bSzBG7v0SfRzTSj5Hjx2310M1yf1vzOKZsw2qv0xTpKy+EzHvzxPYtDWHWCIi6hQygDIbK+03Rq0Ebr0b61t0c/uWKMFjm8y3Uy3kV1MRERH1CN17sEYGQf5zBZY8vhoVh0tw5SUvYvkjcpmKNFbj5fJylD9ejrt+dAZ/89/kZrbvYuX8e1X8E1jyfDVmTBru3bOmAVt3DELp5bpn4Lfv4vhVX/BmHZTgqt/boF52mZku4yaewJNvTsRkewlJ389/Accf/xXG/IF6c37JZzF0w9MY8oe/bxozrbvtp7j+G6uxR8IKrsDMKW9g+eAbUCob7vsFfO8Hh7HkznKsfOhuLPntt/BNmRVy0ecw44NluOeRcnUsH6LvJbKyEjofwzF5xoco/6tlKH/oCewpSt4vpe/2F7HkIVX/13dj04wyzFL7UXxTGaZs+L7q8wmsXPpDPFvZ4O3baPzZohL88/d+qM/nPWWv4FDpfMw7sAR3qb6X3LkEVX8xx+xzVpHzrC8xO4HH3x+F8Wr9MROH4OUnizBZj3KVoHRyBVaqfSr/m9XY6sY9vOPcOnYOvv1bsx/l996Lle9mmnm0HStn3Ju8d48yZtpEbHroI5ROT96HJsWpD/HsX37bHOv378A/X74AM+wNeQ+9ofZjqZyDH6P+oQWYLIN70ccRtdj0w29jzoP/gq3L/gpz1DndqWqvLC3B4/csVY9POSpq7ONTn1DbmocHH/ohHlz7BfzZFzMN9iT1nXYbrqp5xZaIiKhr1aJiI/DYXPXaQ5uIby4Bqj6xRUXPupm/IeUy1dYoVv+fVFXk/m2DRERElP96NSt2udUaGt0UlqSmpiZ8erQOo0dm/5qZ6gOHUTx8KAoKCtCrVy+dWkJmf/S1l+jUn2pQy0XqRdDdqJr7KGYNbgBUOUS+hafvYPR1s2ZkNsbZd7H8+SFYeLvM6FAvqP7PE9hzo3pT3hmTFWT7dl+Ov7QUay69H/OuMmVNZv+cLQpd2SP84/aF6uVbsaLHL9L0GXtu3LKSss161U8f1Y8Xk1F9+Dznwj2mUaF9yXU/VBz65jYAkkK+samPd24cOZcIbzv2cYyTZr/lm6n6Drb7Kd82pY41ZMBgDMlpcIyIKP/ISw9J8lqhpvZYzq8VLrxgsH6tEFVU6K57zk1bX7dkV4v185cAD6nXIfZDHZlp8wAW4YmbzYcDMlgz++k5WLvrTm/GZ+sFr3vs9oiIiKjrtMfrlu5/GZTiDx6kvKmPG6hQb3RDb45l+WADrrzeDSCoN8cjvoQpnXVViWy/KaG/zeiBN6bgz6Jv8AtiBlWUuIEaEaqPO36Rps/Yc+NJ2WbfHAZIfKHznJu4gRoR2pdc96O1AzXCH8Tyybl09Zkexzhp9jsYqFHqDyew49e/CaWqww22lYiI8pcM2kzFgnWps14ml8llS20dqNmO5fZeNRXXcaCGiIioJ+kRM2tiRWeI5LumBhw/Dgy5sA2DCdT1+DgSEWV1vs6sWXPpox12TxnOrCEiIsofnFmTSXSGSL4rKOIb/J6AjyMREckN62cCd63absvbsWYR9A39nfa8Z40MDlVhOko5UENERNRj9NzBGiIiIqIuUnzzo1iLefYrtecBz8XMetmcQJVdbIuadUtQdd1N5lsviYiIqEfgYA0RERFRBzD3pYn/Su32uWeNUxKatUNERETdHwdriIiIiLq1BO6aYW40vLzSVhEREVG3xsEaIiIiom5MLrlKN4OHiIiIuicO1hARERERERER5REO1hARERERERER5REO1hARERERERER5REO1hARERERERER5REO1hARERHlre1YPn8DamypbVrfV2X5VJSUb7elqFqsn78MHfNFVHUoX30IQ9cexUFbQ0REdD7gYA0RERERZTS5bAsSZRNtqbPIQM1pbLusCA/YGiIiovMFB2uIiIiI8kDNurtRMmGqTssj01SqXFswMyYyS6ZyGRasq/WWt2P9fNNXUB+hZ8tkmWnj71O4H7V9W19S/h+2Lsms17bZNm+/KgM1g7Dq2gJbQ0REdP7gYA0RERFRV6tchmv23obEri0qvYQxK+7Genfdz+aleBKLdNva8UuxJocRkI2LngEekr5W4qpFz6cMmshATcV1qn3FTSi2dXGKb35Ub/edJaW2xqgsn4cdS14y+3tdAndttg0hCVS14dqlL37lYqy6doAtERERnV84WENERETUxWr2JVB2nbvMaDhmrXgUs0bY4rT7sfjm4XpxzNhS7NgXP1PGN3PJIrv+aIyZFh40qSifitlYiYWTbUWL1aJqdym+Wmr2CZO/hcemmUXHDPJ4x0BEREQtwsEaIiIiovPF5qWoum4L1mJeyqVWRERElD84WENERETUxYovLUH56+7bluTblbzLoGKNxhi8gQobIzNzcjLtfnxzstwweCVwa7ZtpDMcY8ZX4OUKN8OnGlWRy6Da45412cl5knvmpPuWKiIiou6LgzVEREREXW3ynXhn7DP2Zr43omp+tkuIhmPW/BLcNcPc5PeBjbY6ZxOx8DlZP/OAjbvB8DWLKrBx0Y16WWbkyGDPVbZcMuEZ7IhcBmW07Z41OHAUc+Vru1efxuIzDbgi5Su8ZZCoFI/N7exvqSIiIup4vZoVu9xqDY1n7VJSU1MTPj1ah9EjL7I16VUfOIzi4UNRUFCAXr166UREREQ9k7z0kCSvFWpqj+X8WuHCCwbr1wpRRYV97FJu2vq6hfLEwQ1Y8CCwOMtNkomIiDpbe7xu4cwaIiIiovNZ5TI7Q8ZPHX0JUzv4JAHM/BIHaoiIqEfizBoiIiLqVJxZQ0RERD0ZZ9YQEREREREREfUwHKwhIiIiIiIiIsojHKwhIiIiIiIiIsojHKwhIiIiIiIiIsojHKwhIiIiylvbsXz+BtTYUtu0tK9arJ/vvh3qbqw/aKs7gnwNd/l2W3Da89ize/vVQxi6+gjetuX0TuGFtRKbTOU7bRMREVE74WANEREREcUYjlkrtiCx6yU8Ns1WtRcZnJkwFQvW1dqKLrbzCP4ERXiqny1nM6gIH865GMdsKrvS1hMREbUTDtYQERER5YGadXfbWSxTsbzSVlpVri2YaRKZdVK5LDnwoZe3B7Ni0g2IVJb7/bWcXt/ub3IbMhtnGSrVPpg2tWxb9D7b+JIZS3HVc1vwxM3Vpk6VNz49L+jPP/7UYzfM+fL7b61TeOGT3vjwK0W2nE0T9p2wi0RERB2EgzVEREREXa1yGa7ZexsSu8xMljErvMuONi/Fk1ik29aOX4o1OYxObFz0DPCQ9LUSVy16PmVAQwZaKq5T7StuQrGtawkZKNHr6/3dgu/tXeJdJrUas1+foevfWZLAk3Ygp2bdM9ix5CWzzqb7sWOFDL5MxEJbnnn7yqC/hZP1KjkcewJVbbw86+BbZ4DPXYARtpyTQeewyl0GtfYoOvIKMSIiOj9xsIaIiIioi9XsS6Dsuom2JJcfPYpZbvRg2v1YfPNwvThmbCl27Mt+6dDMJYvs+qMxZlp4QKOifCpmY2VyQKQVqvZWoPxWO0tGpdlPV6DqE9uIOVhbZo6l+NISbNxbrZdlnRbLcOzFNz+KxC7vPLXGgaNYhX74+khbzsWBJmw7DHzZXgL14ahGlL11yjYSERG1Dw7WEBEREZ0vNi9F1XVbsBbzUi61yl0tqnaX4rFNyZk1odkwaUwukxk4N5oBnhlv4KsPtW5WT3t6+1cNWPzRCXuj4BO448xZ/MnqGrxwwAbEGXkBVs0Zhi/a4ojLCoG6JlsiIiJqHxysISIiIupiMgOl/HX3bUhy35ds3740GmPwBipsjMzMycm0+/HNyTJwshK4tbXf8DQcpTOBu1a1ZH+jl061cUaM0h73rPniV5I3CT42ZxCe6tcHv5xTnJxpc+Ao5ka/7WnnkdClTwc/agQGF9iSYm+e3PrBMCIiIg7WEBEREXW9yXfinbHP2MuKbkTV/GyDGcMxa34J7pphLkN6YKOtztlELHxO1s80yOK+uvtG3LW5wm7LDI7IJUgyO8ft78sz3WVX6RXffBvgXToV+jrwEZfhqjQ3GM6s7fesycW2495lTlcO05c+XWHvWXPF/kKUXzvANiqfJLDRDooRERG1Vq9mxS63WkPjWbuU1NTUhE+P1mH0yItsTXrVBw6jePhQFBQUoFevXjoRERFRzyQvPSTJa4Wa2mM5v1a48ILB+rVCVFFhH7uUm7a+bqHWkIGf5zFmxZ0IxjDkW6v2fQtP2HvS9BQy4+cBLOpxx0VERLlrj9ctnFlDREREdD4LvmbbT+3xldhhY8YnMNvfxq3A93rggEbVXuCrpRyoISKituHMGiIiIupUnFlDREREPRln1hARERERERER9TAcrCEiIiIiIiIiyiMcrCEiIiIiIiIiyiMcrCEiIiLKBwc3YEH5dltoo/bsK52a1/DdbbuAxCp894MaW5nZe9u+g7EVJj2csJV54L1ti/Hz3A5BH687hrFy/LnKcJ5qPliMse+8hlx3oT216NjzlH5eBY/FLjzcEc8veb67x12nNpy3FvybySv+OeiQ52sNfv7OKrxnS478+2j54xnfV8tIH/5j7pI89u3Rv6Oes130779bavW/H/O7wTyG7fXYdSwO1hARERFRh5M3XLfgHuwt/ZlK9wDV7TRIYN9Adtqb35K55hhGX28r2q74sw9g7zXXo9iWqRVObjVvvhJbsadwnK5qdwPd81ce/xLcV92CwbrOfp52hJP7gWHl5vjPi+drMb5xjXu81b/34PF/AN/gP9bup6Yae4LHcC6uttX5jIM1RERERF1qO5bLV1nPWIqNT88Lvtp6ufvubP+rtedvMJ++6rq7sf6gjkDNurttW5a+lMpyr59OU4NNdcDDoyfY8gTcV7oAM2wpfsaN+bT5PZl1Im2hT569T0h3r8K40T/DTz5bnOxHYt0MGDvjQs9eseu4N8yu7paTe3Dfbm9d1RaecZLjJ99xs27cbITq1/DGkTLbbvuOi3fStJlZBsnjT56vyCyAaH8RmY493FcOg2qyr6Htyf65T67j+zLHYZZNTFs+6R6Hh4cBG1V/7x0Dbhhsq4NzKNt156ydPlEfOArTG6rN+Ur7OMY/T43kefEHcOKep6Yf/3GQdV053WOl1lGPZ/y/nxZyx+c/h11/sbNtvH1S58MdU6aBKvNvtwz3Nb6GW1x/ac5l/HM+eezZ+2pHwWPvP6+8x92vV7Hf/WBX7OPu0/uf8fHyH39DznHQX+zz0TwfglX0vqTfguM/H0PH0qJZVrK/q/CwOy67f/pxlH68xyb8e8E9lpLCx2v6NG1Zj8Ptq/o3+MbJR2x/7ljin0PJcyh17vFsp98dLSFf3d1W9Q2NKenU6TPNn+yvsRGZSVxDQ0NzU1NT87lz52wtERER9UTyf738ny//97fktYK8toh7zdFScX205HVLhzmwvnn+j39lC1a0butjzfPXHjbL0va99c2HXG5qjbi+rK0//sPmS//gseatttw5DjWvefuh5jWhnTQO/fqh5tt/7Rr8uJ3NS//j20Fb5fvfbl76kV4Mr3Pol823v/1L7/jVem8/27z01zttWZGY911Z+n22udKWROX7qfsWrpM+/W0oHz3bfHnQp/BjYo5XxSePMyLaV+SY/OOV5cvd/vtxkf4P/frZ2PMdFX/syXMdd75ShY/X3990fUlMsl7Wz7aN9MwxqL7fV4+7Oo/hvk370vd/2er+tdBzSAkes/SPu38eoo/V5f/h4rzzm+F5mtKXjQsda+h5JOvH//tptchzLLqP4e0rej/V8zC0TibxzwM5xrjnfPpjF217TqWI7f/bQZ3/+Pj/pkKPm/QR97jLsj2mnB+n0P54ffnPMykG209uQ1Prhx/LOJF1VN9LXV+ZHvcU5lzJccm5uV1+N7vte89l4T+moXPnbzPtecwisi2R7XddW353tMfrFs6sISIiIspXnyRCM2RKbl2NjXurTduIm7B45hu4ZsYb+OpDN+V8ScLksi1I7LoTk225q31cD9ww3O19MWYMBvaetMXCufiRnYnwmb7jsOeM+djz4/o9Ok+rMYGxw90sHqX4evxkkisXY2xhAruzfBjbchNwX3BpSDHGF+1JHkdLyeUmgycFj2nx8GuB+uQO3zHaTuEvHo1xjfvxsVqsOZOwsx7Mp8PFn53byks1arC74XrMLLFFdVwzB2Y7X8VqWyV4pVaCZBZVCRbqx601fbWW6huvAUO9xz2wB3v6Tmr7ZQ/Bp/IqqX+GL+rnVPrHPdPzdPqwBfbx8Z6PGZ6n/nOgpvYtjLPHKZfQ3efOrz/bR6T599Nu9GUlU5LntWQK7vC3L9S5GB/MJmq9uOd8xmPvFNfb54Dal34leMM+PldPSl4m5deL2Mfd2rTtO/pS0eCYMimZiYcbvEv/hs005yfL744Wkce3cRWmque7nr2inp/3yWOZy+OeIvl74Ab/d3MG4f8bZDZm8tKlTOcxd7n8fmqn3x2txMEaIiIiojxVsy+BmUteQmKXDLDYVDbRtvYE8mLZLrbA1ZN+hoX19nKM3W/hhpLI/TMKr8WMUIV/WYJcHmGr25U/nV4uL7LVrSADLy2l73uj78XwNezVlzVFLxvIVQ32tub8qDds4+q2oaZmG14pcm/kWtlXK1099B7vjZdvnPemrw3s/S5eHOgNHmR43LM+T1NkeJ4WT8IN9s35x/UlyeP0L3mRyzxsdac4uT/79vw39e2tK489g9ClQ9Wv2dosGldh71D13MIjocuA0pOB7YS99C8RPL9b87sjLRk81L9Tks9jPWiTy+PeLeTy+6mdfne0EgdriIiIiPJUcel0YNHzcLeckXvTLFhXawqVy3DN3tuQ2DQdLz+Y+z1ouuaeNWbGTPKGrOZN6cMJU29mZAhzb5ux6s1wJvJmaKN6Y5PrzT5rPvgF9rgbo5aW4+FC25DBZ/p6+yWfJJul9BIbcV+Ru3lluXpD3/qb3OpPw2Xgw5ZlJgX6ZjnIxGt2cEY+gZYBhdbO7JFPl1/TbwKNXdh4sgTjs75fmYA7Br+FqTIo4d2bKF1fMuPgqWPu+RDzpkm/EW/hgFPJhBYNDJg31S2/D8XVo+diT429T0eGx719n6fuzbk6h0gOhv28JoGHx9ttjJ8L9RsjN/Y+HrkNDKQhMyrcjZ1FYiueKhqdZUCqvbT+2Fv7uOdmF546UoIX9WP4M2wZfX1u+1U4F3eUyABf7jdfL/7s11SszMb5WnImT9rfHcUYi7ewyTbkNqizCz+394ORgUe5ybKeJdSej7vMlPL68mejhX4H6/8z2vsxa+3vus7DwRoiIiKifDDiMlwVvSnwiJvwxHPAbFt3zcbpWHzzcHOD4VuBtTLLxl0ONWFZMKgT25dvcwJVdrGzyMwP+dTYfOL8CDD6Z3q6v9QHsw8qyrC3OPubWvcmJfj02r6pNzejfARP2an7yUuCvoZxwc19N6oX4yW4L5G8Kaa8KYjeZDe0TkK94XHcp/nyibm9LEZ/2qwvS3DH9wR2D70We6q9NxcDRwHpbjAc7Us+0S7eb4/hO5ha/zXvxrRx1BvXM/vtjBqTcr2cIu7Yr55UjrE1rq9fYKx6I5zLIIi8UZwemdWUtq/Q+foF9kQG0PSbyYHJN6GtYs+vfxPl1JuRtuISCvX4/EgGpuR8ZXjc0z1P08n2PJXzu6da/dsJLvUyl58Fj1/1aCwsWoV7U44xhsyOsAMEWbkbtPo3GNY3hZ2A+8aPwnK9vyrVjMIWfVmQnW0Ue0PXTOQyslxvCpzt2LP11dpLZ7KZgDuGJYLt3ntmCm5Qz4/cB8XUOZVvGtudy4CNDDYAd/iX/qX93RE+X/fWmfBMaj6oxt7gd7NK/qV/sY97a4TP1/KG5GBn+P+G3H8PpbIz1vznY7bfdTn97uh4veTGNXa51Roaz9qlpKamJnx6tA6jR15ka9KrPnBY/fIZioKCAvTq1UsnIiIi6pnkpYckea1QU3ss59cKF14wWL9WiCoq7GOXctPW1y3U1eSNoHoje433wl29sP7umZlZBjSoo8mMhXuxoF0eBxl4k1kpOd2/Iy/l9/O0PR8r6ioyCLEVM7vJ11Cfb9rjdQtn1hARERFRtzK+KPlJrE7VsDe0pa5hPrmeesTdWLitojf+7J7y+XkavnkrdTfmUq5HkjcWph6JM2uIiIioU3FmDREREfVknFlDRERERERERNTDcLCGiIiIiIiIiCiPcLCGiIiIiIiIiCiPcLCGiIiIiIiIiCiPcLCGiIiIKG/I1/1+B9/9oMaWszHfwvNwwhZzUfMavluxGD/PdRP5SB+D/Yadd15TZ62Tyfa37bKFbsDtr3x1dM7PLSIi6kocrCEiIiLKG8X4xjU/w09y/nrfCbiv9Ge4ryVfcVx8PX5S+gC+0dJv7bUDJF3/Zn8XHt79Fm4Y/zPsVce+ZfBbmNqdBk6IiIhywMEaIiIioi5W88FiM0vEptBMmcSqZFswKGFm4Jj6yCwZPXtiV9CeHFwxs3DMOqvwnq01falysB2/zVtn9yqMG51tIEnF+zNdQjM5/O23YdAnsRVPDfxaMNhU/Nmv4Y6GarVNc078c/feNq/sn0e3j94MnYcT7pxmmnVkj0GdizdOPhL0F2yjRTN+ZHvhbcnzIDgvsY97pvNLREQ9CQdriIiIiLpY8Wcf0LNEJL040FYKefNfMwpbbNuWvr+wb87NDJy9peV4uNCE+t448gugRNrvwbgjG+3gi5mFI3V36LLvNdxybIrZxrAEltsBgJoPfoE9w8p1/d7xc7FH7U9rhwakL4w2xyFpYb3br3bQuB8fyzkpvh5PHUsObGxsmIs7ZNaRnEd7fDoV78e9cox6lpEc8zjg2DZ7zjLNOrLnUJ2L6QPvCfozM5t24eHd+7HQ1sk2Ms/4kf0twX3Vyf196kgJFspgWNrHvZXkOCdNUMc3twWztoiIqCtxsIaIiIgoX53cDwyepN7WG8XDrwXqs79pnz5sgR1wKMbYwgR2Z13lerwob+aV4n4leMNu4+P6PTpvD9LXU9UyU8TM3Ll60lxcbZraT8kUO8tGSWzFHnfu1Hn0Z8KMrX4tOEbnKYzOMEiTg5pq7Bk4JXlM/r6kUzITDzdsNYNWsr/DZpr1W/m4ExFRz8HBGiIiIqI8VXOmJXcObn9XT5IZMGVmgEPuE1NyfTCA0FLSl55xMn4UlutBE/9yqzYqHIXP6IUJmFn0FjbVyLkDbhhu9lbO43Q3Q8glOzjl3DE0XG4xGRCyi7krxozBCWxUD/N7xxKh/SUiovMbB2uIiIiI8pSeUVG3LZidUVP7FtC3LdM/WkbuobJxqBvgyOWmxMUYCzNYIvxBh5oPXjODM/rSI7l8y5/xY+4Fk9OlPjJj5eQvgnu9yOVVTxWNDgaRrh5agldqd2FT/SjMsJX6PAaXg5njavd7vej9srNkhNxbx9uvdOSeO6j+Dm6Bdx+etI97+vNrtOA8Ogc3YMGEqVheactERJQXOFhDRERElK9kYEPufaJnonwHU+u/Zu854m6GW4b7Gvfgvt25zFSxN8eteARPyT1qZDnLTXDdQEJw+VDWr/y292HR+/Md3Ftnq9W2N9XvtzNqJJXhlcHuUq2k6KVJ8SbgvvHX4hW7jal112KLP0umZArGHXkEr/RNXkakz+NomGO26/zI3RtGykfcJVoq5fLNUsWjMS7lBsOyX27WkEpyz5nI7J14EzBzYGRmT9rHPd35DcvtPFqfJLBx2v345mRbJiKivNCrWbHLrdbQeNYuJTU1NeHTo3UYPfIiW5Ne9YHDKB4+FAUFBejVq5dORERE1DPJSw9J8lqhpvZYzq8VLrxgsH6tEFVU2Mcu5aatr1s6mnyDkcxmadHXcXcIGRDaiPHXePeWkW8fOjOTN6ltVzKIthUzSzvgHj45qFl3Nx7AIjxx83BbQ0REbdUer1s4s4aIiIioq3lf03zLyesxs8sHaozxRYlgNopO1TDfVkTtwnxl+yPJGwt3gaq9wFdLOVBDRJRvOLOGiIiIOpW89Jg/fz7+9//+35xZQ0RERD0OZ9YQERFRt7NgwQKsWLHCloiIiIgoioM1RERE1GlkRo0M1LTDxF4iIiKiHouDNURERNQpOFBDRERElJu8GKyRW9TwdRsREVHP5QZqHLkUSv7v523qiIiIiFLlxWBNnz599I39iIiIqOeJG6iRsvzfL68BKJtarJ+/DJW21Dat6KtyGRasq7WFMPna55L5G1Bjy/ng7VcPYehqk8p32koiIqJuJi8Ga/r364vT9Q2cFk1ERNTDRAdqXPncuXP6/355DUDdV/HNjyKx4ibky5d5H3yrBn+C/jg252KV+gPbavDCAdtIRETUjeTFYM2ggf3R1HQOp06f0QM2LhEREVH3lWmg5tTpev1/v7wGICEzXqaiZIJN5dt1bWW5lG/EXZtXY3akTWa8ROOFWUclmfHiYlR7xr7iHNyABRJz62psXHSjiZ9wN9YfVG1ptq1n4ZSrpOqXV9pjCmbehI9xeWh6z3YsV3XpZvDk5hTe3A889bnBtjwYcy8D9rWlSyIioi7Sq7kdRkUaGs/apSSZ2vzp0TqMHnmRrcnsrI0vKOiNAf37obBPH/TuzQvZiYiIeopz55rRePYsTp+u1//vX3jBYPQpKLCtmVUfOKzjC2LiiwpbdilVe7xuaXcyyLHvW3ji5uG6WLNuGSpK78SsEVKSQY7nMWbFnZisW8V2LJ//Eb6pZ7VI+xLgoUdtvJD2TcDMGVh480RbJ+L6yiKybyEyaPP6DCTK7DakvKIE7zwErHkwgTEPfQt40GwP5Xejaq7bx+h+yGDNPJTfvjLZV4udwgtrTwKlxfj6SFMjM23KMBCrrh1gKoiIiDpBe7xuyZvBGufEydM4fUa9iFMv5ji5hoiIqOeQmwnLPWrk0qeWzqjp6YM1cu+XaxZVqKVSPLbJH3QR2QdYZNZMxXVbsDAIkMGPZzCmFX2laOFgjY4t/Q8sWHUZnigbbbf3LVTNl1k9JsyIO9a2cIM1A4GKE9gwahDKcZKDNURE1Ol65GANERERUVSPn1kTsDNMQgMZcQMsUhce/Ch7LjJYE8y88XXVYM0MVEzYhNJdLdhui8XPrFk1pBhlV5oyERFRZ2iP1y15cc8aIiIiovNa5QZzLxhMxMJdW7D29gpUfaJb4lU+j7vGr0RCxSZ2vaTiS21DvpqI0ttX48ngnjQyKOV/K5WU23rPmgH48ijgjl/V2XIdVn0EXOqPMcngkrvvDhERUR7r8MGadpi4Q0REROexnv9aohbr9yVQNSN5893ZWOnNkhmOMeMjNwWe/C08tnuejV+CquumY8etZvDD3Eh4Hso3L8U1ut0fnIjpK5tLSoB0Nxi+dTXwtNmPbAMtk8tewlc3un7mAc+lzrLZuLfaLrXOiGuL8Uuctl/dfRqYlJxlI2rUecbtt7XjpVdEREQdo0Mvgzp27ASGXTgERUWFtpaIiIioZRoaGnHk0+MYOnTQeXAZFHWk1Hv7EBERtb+8vgyqV69eKCws0F/HTURERNRa8lpCXlPIawvqAG6WTCj5lyj1FLWo2j0HpRyoISKibqDDZtZIt42Njag7cRqDBw1o8bc+EBEREcm3RNadOKVeS/RHYWFh7IANZ9YQERFRPsn7mTWyY/37F+kXWUeP1elpzO0wNkREREQ9mLxWkNcM8tpBXkPIawl5TcGZNURERHS+6LCZNUK6lk+qzp49i/r6RpxtOsfBGiIiIspKBmb6FPRG376F6NOnT8bBGs6sISIionzSHjNrOnSwRkj3586d0y+CJJcyB2yIiIgoHRmUkdS7d2/9IkfyTLNqOFhDRERE+aRbDNY4bpCGAzVERESUjRuwyTRI43CwRqlchgX7voUnbh5uK9Kpxfr5z2PMitSvzQa2Y7n+Su18+7akU3hh7QncgSJ8OPsCZPzW7QNHMff1BmywRaAPfjlnGL5oS0RERJ2hWw3WEBEREXUEDtYo7TJYk58OvlWDMhRi0n5gbg6DNeUfFaHs2gG2goiIqPPl9Q2GiYiIiCh3leXJr85esK7W1m7H8vkbULnubtOmlmtsS42rm3A31u+zlRmY/m/EXZtXY7bdTkn5dtUiAzi2LH0dNPFm28tUMnFme8n2+P01TGx7fP13HVbV9cOqa1Nf7MaqPYdtdpGIiKg742ANERERUReTwY2K67Ygscuk7+1dkhw02bwUT2KRrl87finWyAjIwQ14YFEJ1ur4RcDG1SY2g8llEvsSHps2x66nUtlE1TIcs1a4NhMb2JzAmIdUPZ7BGrUP7ywBqj7Jsr+BBKpS6lrm7Vcb8eWvDLal3EyqO4Ohqw/pNPetU7aWiIioe+FgDREREVEXq9pbgfJbkzNVZj9doQdFtGn3Y7G9vGnM2FLs2FcLfJLAxttn2EuZhmPW/Dl6qd1Nm45Sue5odwlKvUusMu6vUnzzo0jsehSzMl6zlMXOI3jzkpbdb+bg8SYsRiGOzblYpUG4af9JvHDANhIREXUjHKwhIiIi6lK1qNpdisc2JWeqSMqvm/z6OmN/T+GF35zF4m1mhszQ1aex+EwDrlh9BG/biDgjri3GsWAmzgB8eRQgY1tERETdDQdriIiIiLrUcJTOBO5aJfePEXIPGf/eMTEuKcHMpzcF94Sp2ZewS50h+/62/Z41A/D12TI7xqX+eKBfET70v9lJvvlp9SGU77Rl5e1X/UufTuHN/cCl2e65TERElIc4WENERETUxeSyobWYZy8ruhEvz1yU+RKiETdh8ZJEcKPgBzba+qyGY8z4dDcYlpsPV+CuGbKceaAlt/1t+z1rcrHtePK+NF/8ilz6dMLOxjmBDaMG4usjbSMREVE3wq/uJiIiom6NX91NRERE+YRf3U1EREREHv9ruJMp+tXaRERElN84s4aIiIi6Nc6sISIionzSHjNrOm2w5tTpM2hoaMTZs022hoh6sj59ClBUVIgB/fvZmrbp/emH6H3yE/RqOA40n7O1RNQj9eqN5qIhODfwEpy78ApbmR4Ha4iIiCifdIvBmrPqxc+JulPqdVcvvVNxO5sL2clefq4WeqmFZJ5SEV0jJm+9rL17FWl3JyQuIN0KsR2EZOpF51kDVMoolw6SebP6ky0qJFNg7AotY/bH7Vd8Htqgfl7JmlakOTZvgZZ0Z8qRCL1/0bIrRss2z8CFOf5q6fKoc+eaVTKDs4MHD0SfVv7bR8MJ9Dn4n+p3SAF69RsKFPa3DXHsngQ7FLdnwosLHUA03osLiYtTHfnnWUtZ0ZC4ELt+ND6lPycuzm4/JBqnku4vLs7bUNo4Jy7OWz8QjdMlJRrnePFayoqGPl7JTTEpWmHXT4lPWdGIjUvdkPx/E/xzs5kUXUWwlo5Tv08k9+vVn1BZLZiHLy7O/V7y46Nxfry0+/3FrB8tS3xcvS7b/VcVfr+Oizfs+kFFsqeQ5AYjzZE4aSvoi+Y+/XF2ZKl6ZTPI1MfgYA0RERHlk7wfrJGujx5Tb7TkE/YWvpBqKf81n87VQvjFZUxAuCImb72svWcNUCnENTiZVkztoGXRSotXyCbcQfAmIEPu6LXc6k64u/i8DVK7i9s/L0I/0VwxWk6Tt0CmbuK7cy2W3h9VzphLnEouz8APS5c7TU0yC6YZFwwdrDYlrbmT3yGFH7+OXoX90Kv/MKlRyT0OSRIXKqtk9sPUJw/Tfxxj4lxZ4uPqdVmtL/2oivRxkfpQXIbtS5xakNxIxhl2/WRAsL6TLNuOQh3Yei9ea3WcE41TScelBFq2Ptc4J218TJwWjXNsvWQt2k9dUqLxucZZKecx1zgnUpFznEo6LhrYkjhvQ2njnLg4b/1ApBwU7ULvPmjuOxSNv/cnaX+HcLCGiIiI8kne32D49Ol69O7dC32LClVJvcXQL7JcLouRXL+I8/PcpfRgF/yu9aLL1U/TlsxNg1+WBZcLW9ZJpM+zRciCLEvXui6aC7sQ3j+zGCpEy0GeTKY2cy4/XW7/ps+FW0iXO7ocbgxvOT53f6Rk/noxruzlttH9iNTF5BmkrmKWXJ5Sox4kvaRzXW1+6AdPcle2uc6iucmC3BNtiguVZZfkZyjG21a0nMxVcrmIjTG5WYrmspQky5L6FJhfM/L7oKV6H92NXr17o1f/C1VJ3rhJOiejzGoxmWT4I9muyvoyKRsnZakP4lS9i3O568flKiZtnKvXcZF2l8v2VUr257d7/er+bO7idC4x4ThZNnGm3iXd7pK021z2wdUF7Tqpeq+/0HJOcfK42mWXUuK8dUNxsk9ybmTZ1UWOQSV3jlxMMl76NYN/Js5r9+JiHzvdHt6+rnd5Spzk0Ti7fhDn5SlxthyKU/V2/6UuaPeSiwvabW5Scv91WXJ/2YszyWvT7bKuV++35xKnk7Sp3F8nGqPXtXFBnVuO6df155KO8eLONaLX2VP69wERERHR+UK9DtSvjNok7hMq6fbY8RMoKixEgX2z1hKyV/LeUHZO3vAFZS83DV5AuCImd6Ll7FJ6UwuZ9ycmD3ENTqYVUzvIGp01ICZvkXAH4RkD8bmj1wqvHp870XIOXDdOavdx++dF6AfWFaNlmzvRcg78btLlGen9UZGZ8haQaLfddHmLRDpoPndOLw4dMkjtnjRkJ79DCj95A737DgL69Lf9pduTcL2s62/F7Y6Lc6fJrWaeB0mu7NbT8XH1QW7rJU4tuO1njIurj5YlTi1k3b5sLxLnuDjNi3Ni43VHkUBNyl6PQTFLnKP7ldwUk2LiYgOjcSrlsv20cU5cXIbtpzTHxamAlOONxlmxcTHbT4lzWhunko6LBuYa50Tjs8QF/emSEo2PlKXYuwDNg0ai8ZLp6qkpK4fl5cyaymUouXW1Xpy55CU8cfNwvUxEREQ9X17PrJEX+3IzYTNQE31hlfpCK8q9FnORQTmosG0uVz91m/phYlyDn8uCKwu3kD1PqbELLpcGvZguF3YhvH9mMVn2cs3Pk8nUps/NX/XH5vZv+ly4hXS5o8vhxtQ9SM3dHymZv5nzIJkfQZY2d1Q5piqSmyWXp9SoE6eXdG7K0pbMbZ3k5ocph3KTBbkn2hQXmjEmZVsxuZ9cnawdKpvcLEVzWUqSZZdExjxSKbNj5PeBHgTIkR6AkJsJ9+krJakweSjZT9+lzUsy/KbrbQrKtg9d1stm/ZR414/LXX00t7MPQnFx8dLu8lB7ePuxcaH4aJxaP02cTkGcTdJuc5eCdpsH7apvP861m9ktbtnLU5KNk+Vs8XFxsr4f49pVrvfRW0cfg5fMMST3M3SM0h6Ks7kXZ9q9xyZjXEyu47znRly7y117Slxk+5E4l1y7Lntxrs7151IQr9vN88e1BSnSR8pykMw+6jY/pcTZ5LfpZbt+NPl9uXXOndW/D1ryO6TLTb4TiV1bkNh0P66yVURERES5Uq/r2v7KJ9MnVIMGDjBv2PRm9EKG3ImWs0vpTS3Ie1G/HA6IyUNyWSGaJ2WNdgtO1hVUapHMHZpP6KO5F5V59fi8DVK7S92/UIR+gF0xWra5Ey3nwO8mXR7mWiy9P6qcKXdkNa8YR5pdWLq8RVI6UAsp+xcKCOUpz5eYPKpR/Z5IN7ocR36H9EtsQK8LL1f92e2pjoPdlLKrVylZVvunArLF6SUvzrDr63ZDxyc7spld34szbH2yQytS1v3lEOekxDm2XjK3OzqPxkfKQTEa59h6yWL7c6JxuqRE4yPltHGWPj+Sm2LaOFef0hyt8OJy6bclj0uoPydSke38Obo/1WG27QfFuDhvh4JiOM5Vuzi3WROX/PftBGW7oo736m21Lefy78/mKXFp4m0c+g3FmZKb2vQJldOZ96ypWbcMFaV3YtYIW0FEREQ9Xt7fs0ZTL7DkNZa80tIvtlyebPByWXBl4Ray5yk1dsEvy7LL5Ucol0VZkHKoIUOu+XkymdoMuVqQkpT1T/M3fS7cQk555iBvT7xcfprc/M2cay4X0bpsuSc1xCy5PKVGnUC9pHNdbX4ED6JkNjc/TDmUmyzIHVWONsWFhuvc/tmyt61oOchdcmvGxdjcLCX7si2h3E8iY55SaRf8XBZdLj+8XO+B3g+XmzY/t632Z1uoN2rybk7esMnbN53LJ/Jm5kXQHsTZehcv9dFc2iJxLul+XZ3uL7ls2m3Zbj9oC5JXH02uL72cJc5PKTF23VB/tt7N6PBS6BhUcucuaA+Wpd7MtjBxXu7Fhc5xKM6u7+Jc7uKCeLt+Spy3vo6LtLtc4kL9ufbk+jpJu811kjidS4y3n7bN9OutH01enE5+nU623yDOpqDdpQxxcdtPibPrx8bZfv11InHmGJNxoXOg6s25TNa5c+3qzDlOxgWPgY1z/QXt0TxtnDmmdP11Swc34IG9MzhQQ0RERC2mXgu1/RVQ5pk1mb5mNz3ZKXmLlzbPGqBSiGtwMq2Y2kHWaLfgZF1BpRYJdxB8gpkhD3GrO+Hu4vM2SO0ubv+8CDmBMjAQypPNsXkLZOomvjvXYsXuXzSXOJVcOQMdliVvkZQO1EJ0/1xAtKxy87i4UnzeJqqDxrOtnFkz9FK1enT/bFlVhE9/muNQATnFufogLk28F+DqjWScE8Rbpl3KXmRQVAvB4+OLlHW7t34gGqeS6zcksn7aOCdSn237Kc1xcZHta9E4x4sL9jPL9kPi4tT60k/G/bRiz1+MlP6cSEVKf040TqXgeH25xjm2vsVxuqSE412zO16bSYVKyd8njvv357px66f+O5SyWl/iU+qVAcO65cya5L1r5mDtrjsx2dQSERFRD9Y9ZtbISyz9Ks0uB0mkz7NFyIJeTpcLtxBtcGXN1YcabZ5MpjZDrhakJGX90/xNnwu3kC53dDnc6G05be7/MX+9GFf2clswuZelzTNIXcUsuTylRp3AcG5/6OeO5K5sc51Fc5MFZU/QlCYX4Tp/T+WHLWXMVXJlkSHWLEVzWUqK1sXFCF1OCbILfi6LriwFvWhyvQd6v1xu2vzcttqfcbnh8pDYylzJGzV52+bl8u5Qv6Hz8mi7zs3sgbRxLpd4aXd50G4/6ffjbFmW/X5ccnEuuf5C7TqZ2SFBm1tW+xzUpbR5y3ZmQ2zy44J4L+k6u/2YuJRjcnE2mfbk9oN424cuB3Exue7HPjbZ4lzu4oJ477GJi5NyNA/FRWZxSL3LbV0wg8e2SXJxOnn9uXXC8WYbyf685biUEmfOka7LGOflfrLHmD3OyzPF2WQeu2TfoXNin1euLWj3+jOPnXn+6LKL07lX77fr5W7o4AYseH2GuXcNB2qIiIioBTp8sEZ/oqySzuSPLOvctCXrvbLO4+qSufxIzXWAzuWPXk6X22XTX6QcrddJVss9lwXJXJ4So/7IgslNWbe5PLrsl6P1OSS1SijXi6FcL+iyzvU21KJeweSurPMgJkOeIakfGXNZDNdFHmud+blpM7lNKTGR3EvqR8Y815ggZd22yuVPkMvPZIw0SFu6XOLMcjK5ssszpmCbaXLpRi/H57IgcWbRLOuil7u2IG+t5ib1/u2cTU3qPZ7K1Rs6l+TNndQ327igPYiTtsiy7stLut6Lc+vqdtNvqM7FuaRjInE62X6j6/pxOrdxbr2gTda19a7OT9E4KYfiZF1b7+L95WicLetzqJOsq855EOe1y7KNg9u+rXPx+rFTyfUX5EG7zfW6ycc2GRfefjLetqeLk3qdR7Yv7S6XdpdLnKzvxcmyaTf9ujrXf9Cuc4kJbz+Z7Po2PpRcnd52Ms7tm0myb3ZZ9+dtw8aYfZQ+bDkUJ+fAxXntLtdxZt3UONNvEBfEx8VF2nVu1w/ivFzaXa7jJE+2y7J5TMz6OrY7GnEZrtr9EWpsMTe1WD9/KkrKt9syERERnY86fLAmzQf5JpcFVxZuQeeuwcu1THkymdoMcwDM34y5S/4xZMxDwo3xeyI/XdmVbJ3+mzkPJZEt96SGmCW/LMuu3o/QeWgWhuTAyY9+hW07a9Bgy/rEuVyk5CYLck+0KS40XGf3y+Vpt+nlfnJ1aXKzFM1lKSlaFxcjdDklyC74uSy6XH54uVmU/ZBC6v6Zn6Ycro0rx4g2pgSrBVm2SfeZLW+tZvMJu0vq3Zv+pF2X9WBQctm0Sy6fzptP6IO2IHn10eT6ii4Hya4b6k/q0yS/TS+bfTf7mEyhY3Dtrk7abe62r+O9ONce5Hbd1Di7votzuYvz4/12l9tzp8vZ4mL7S66vk7R7y5LX79+Juo8+RaOtN/25GNuvbUtJtu1M4n3U1TSE6kySN/wyIGDLksf2J3EqT4kzgwm6zk9xcdEY3S710ocsuzqbe8nN+nFxyXNg1o+eM3euXZ1rD/JInOsvHBd5bNPG2XaXB3He+tE8FJemXbavc1Mvy36cWe6OJmLh/ATWVNpiTqpRtbkUj82daMtERER0PuqEmTUmyY+MubwQS8llweTyR5bT5jYmmdtWP5c2W9Z/VcqUu6TLeiGZB334uW5N5qE/qpPMuVpHlm1SVVlzP0kWzk3BL8ty2lz1qf/oPFpWNZKrJHn9nn/HU4v+ErNmfwd/9heL8U+VR6Uj/O7VR3Hfc7/CSR2rO0nmKovm0mbKJg8nG+PyYB2TR/vSuUp+nilFY9XPlNxtK8j1Hz9PJvkRzk2Mn+sFKdvclSVP2Z9oLn9CuVknVNZ/TC5CZfPX5tGyyf1ktpshlz+yXZ28coa81dSbwOATdz+3n77HtgefzCfjXFI/QmWdJMZbJ7Y9XVtc8uNi1lGVoTZd9uKCdld2bZKr5Noz5pnibH86z6U/Py4uXtr93NWf/gifri7H4R/ORc0j5fh0y8c402TidJI4m7vU+O4jqP+3nTgrZa+/IN6V/eT1h3OHUP/qY6h/5xNTPrkbR1/ehlMuzl/HLUdTqD+bx6WW9Be3HE1Bm/r3Ehsn/9gibTFxsefMi4uew+AxkFwl156SR/rLGpetPz93cXHxtr9u65ISYF+tLeTg4EfYMW06SnlTYiIiovNaJ9yzRtEfqptP2EO5lilPJlObPjd/o3nQZH7YpMvCLaTLQ8KN6ffExZll98f8zZwnk/ywy5lyT2qIWfLLsuxyP0Ln0Vka7oefy34d+Dcs+ZtV+PVl38bjT/wjnvj+pTjxySkJsrEm9xbT5i454ZjU/dMy5X5ydWlysxTNZSkpWhcXE0gJsgt+Losulx9ervdA75fLTZvLzU9TDtfGlWNEG+NyL+k+M+Rmyf1JlpO5jfXy1jOfsqt3buFP6KVezzTwytJuy3GfzJuy+QQ/lCIxZgaLjXN1blm9aUzGuTov18uybkycTrZff51ojF43XVzymF1y58YlfYxeXPic2HodF24Pctm+vDkO+vPbvX51f7bexQXx9ah7+e9w9vQU9LvrHzBozrVAVbVaJXW/glyvq/QuNNuX+rjt2zp//1zqheEYOu9JXDTzM7odhz7A2Xd+h3Oun0i8Tq5O8qDdbD+U4uKCeC/pOrufWeNsHoqLbDtokz5tm6uLSe6x02WVu3Nn+jXPK9cWtLs6lVKeO0Gc2X7ysfDa/VzHee1B7m1f2l0ejdPHmNxPXa+Xuxm5sfCEqSiZsRQ7bFVOPkkAM7+EYlskIiKi85N6LdT2V0CZvlVhwIB+6oWWfZ2lF1qQt0i4A/kkX94khnPXasoh4dXjcydaboXkfrnuUvc3tANyAr1ibO5EyznI1K3f3QdPzsN/PzAXP39wGgb6EWr/Plh5G/77R7fiuYevx4XNJ1H18tP48bNbsbexEJNu+R/4v/98HIqO/hprn3gO/+fdapyEqv9zVX+Lqq99E4/9cD++9N1GPPv/+zeMWfC/8dd/NCDr/uQspQO1IAMnfp52C9HnT3zeJpk6jtlA3PMl9fnTjjLtV+z+RZub1e+Ec636NigMkLcs6TYQqQ/Y+lzjnLTxMXFaNM6x9ZK1aD91SYnG5xpnyfZaFedEKnKOU0nHycIxHHv6r9B40SIMuelyFEm787vXUase2r7fn4FBqnji9XLU4xsYft3v4cTLd+DMkT9DwZn/F03VjcC4ORj4javRv/cxHP/FT9D0e9OB//wnNB0tRK8/+i769qtE/b/9Es1FX0LR7d/GkKHHcXztU2i88BYMH7cXtWtfQ/MJtVsXDkfvL92OCycNCQ7H7b/bbUf+Wwx+PUhZ/TG5K0fqg7h08fbfZa79Slyo3q6v80icWsi6/Zg4IxmnSbuOS0YYkbIUTce6mMrWtzhOl5RovCn3GvqZ7vltUERERHTe6RbfBiWvv+SnvACUZZObgpTT5sItpMtDwo16Gym5/HRlV7J1+m/mPEiOW06XZ6D71LmRLKepUSdOLwW5aQvl7iSbH6Ycyk0W5J5oU1xoL9Tgdx81YtLVf6AHakybzd02bG3Dr9bi/372LGYv+yleeuYHGPvq/8K63aptyECMnTYfK/7pSfz8f1yLg//nX/BunapvasSnBzZiyS+G4q5l/4C7/q8Buh/Tm9uWKxvRuriYQEqQXfBzWXS5/NBtpmzOufx0uYnxc9tqf0pupMtDsgVL7iW9jSy5/0eYPFpO5rIUzj3pQvzcS7o6lOulVpG3qPIJe5DrN35enX4j55btp/42zq2TbDfJlXWcy3Vc5NP8tHGRdpe7WQd+XFx82jhbH8R5eSROlv04XZZ+g2WTu/5cMvFm5oOuc7lOZkZDqC1tnFcO4mRd1zYEfUtvQK/3l+C4+j1wdEc1zjTZ+MaTaD4iM/Jsuf4DNNfLPWZkXeXASRTM+hsM/sv/it6Jf8Sp/zS3Z20+/gGa3vodCv78hxjwx2PQ/O//iPozX8TABX+FAvwHGrcfUlHnVNxvTH+XlKLfNWNU3RdQ+J3vYeCEwaoTOQfh/Q/Okd5377GJtAe5Pd4gj7a7XNpd7j/mrt3lobiYdp0nH9tQXFx8DnE6eXE6yXmxcaHk6oI4L/eTPcbscV4eirPrp4kjIiIiOp900j1rmm2eLKvXX3o5ba4Xkrl8UpiS65+SuyXvj+okc67WkWWbVFXW3E+SZc7lT4Zc9an/pMnVgl5On+tO0uaSpeam2eXhZGKCZNdxedCHUiSDg1JWyc8Ns/zbd9/EgYub8bt/WYVnX9iGIwNO4dd7DqG59+9h0vgGbPuXNXh2w7s4glM4cdpuS6Ubv/6nuLy4PwrVNlydtCaXTZIf4dzE+LleSJNH9z0llz8ZcxWm/8Tn9m/G3E9mu5lzvehy+SPLmXLvjzC5Lds+/NwWTIzkUkybm5hkcmWby59I3lpy2YxO9l4WwX0svBSUI/e7SGl3ZYmz98EIcqmP5n5/7Rqnzkgb+9PJi5PllHZXtm063i3HJd0mD5hbTpO8/jLF9fv9WzD0B/ei8LJ6nN3wAE48/v/gxClpk+eD3Y5O+oG2fanlC8egcFg/9B32eRReqaqOyn2xVJsYfyWGqLYBF8sgzOXoc9Ul6DdkPPqMUyF1x5JxehsF6N1H8kL07t9X/e5y24uk4DhkH1SKi5FkjzX2HPtl25879649Jff762ZxLrm4oOwtpyS/rRVxREREROeTjr9njXyg7j5Uz5aHhBvjZwPIz2TZ/2P+Zs5DSWTLPdlX0VsJcrPk5aFZGpKbNn82h152uUjJTRbknmhTXGi4zu6XXpIfthTKL8Cwi4F3duxFg5T95JNyU6N6w3UpJnzuc5g0aRK+8hd/hT+/+kI07ngOC+56Dr+7eBr+/LaZ+AO7inC9pMtDUoLsgp/Losvlh5eHz7079mRufmbOnXDJcpXpciHLNuk+s+QqC3IRrYnmshTOPelCbK4z9UOfTsldOcjVH1vWMbomc95awafroSSfwJuZBv4n72Y58um8a3e5SuodpSon49Q7Ti9O3oC6ZZMH7Tapd5ChON0exMmbShfn5aE4u35snK138VIfzTPG2f0K4mx9JE72IShLWxBn6l0K2m0erB+JCyXXn0p9hl6OoTd+Fxfe+QP0Pv7PaNh9UsUIG6PXEf6y8MqNzWjSsUqwji3b5V56NmlqveGWbbL7FqSgTY7JOy7X5sep3D12Lrlzq8+JSu4cpeQ2Tp9j3Y+s48eZ7YcesxbFpdl+i+JsvzrOy0Nxsm44TpZNu+nXr9N5KM6uHxtn612dl4iIiIjOJ50ws0ZezMlf86LOz4MZAJLH1UXzFiS1SijXi6E82aZz+ZMpVz/McoY8Q1I/Qnlq0idLL5vcbtPl9lwmc9vm8rQxXtlL6kfGPL6tDyZe/8cY85//hJ9s/gT1Z5tR//Fb+D//tAv1sg2VhMRe9rmpKPrNr1E76nP43JSJ+NwV43DZyD7Y++6bqJo0E7O/9HsoPHEMJ/Re2vXsT9lUcpsmD+9HfJ4x6X69PFov3ehlk5u/fi5ttpyybHJX9mPSJvkTV47W+8mLMX/1hnSuMhuXzOVHMo+PSZvrPr3kytF6m9QP3eZyXR/JW6u5uUmlyKfskvvLfozffk7VSwriTFKFUB10XLIuaNf9Nqn2ZFvQ7sUhEqdz3W62n4zz2nOK8/qVuCA+S5zU69zWB3HJ3CUXZ5LXrvPkfrk6179fJ3EmeXVNh3DsFz/H0d9+isaz53DuxKfqmTAEvQb0Q3MveT7sxdlD53D201+h8UN5oO160nTqJM6pdZqObUXjTvUf1ZgRKJA2TT2f9DYkUCW1bMpSVLm3LMdedOHFqnAM507bOInX25FzI7kru378OHNcsXH63PhxXnsQJ+fOj0vmso4fJzF+nC5LvzbO1akfQawfF8T47bpf2+bio3E6t9v363SSdSNtaeO8uiBO1rVtfoqNs3WhOFnXtqlEREREdD7phHvW+J+vy0+TJ+tsrv+Gc1tI5n4S2XJPaohZ8nNZcnlKRGgWhuSmLZSHpxqYZZ1Hy6HFtLmfRDi3++XyYBt+rpJf9pOrS5PbpZS871W34m9/8AfY88QizP7mbZhdtgpV/QegUb2n+L0/mIKiD5/DuveAoj+cix/PasRP7roN/59bVNy9a/Hrk8Bnp/8pPrttBb759fm4/7WjuLDQ9eyosq6SXBZMbqok98qmpHPzM642mYdEK6PBKSurBVm2yexH+twsyYLLbZuX28CUss5jqjLlOlM/0ufqj5ebpcx5OAkv14vpc7MNteRyk7WK/kRdvTGXT9rVQjI378iT7ZA3smnaXa7jbO7ignh5M5hLnJdniHPJteuyegMatLt4WfZSEB+JM8nsY6gtNi6SgjhzjoJ6vz0U5+Wh5G0/U5yuG4A+Y4Cmn9+DYz/6Sxx78mXg//pvGHiZOsYxE9Bn6O9wduV/w9HnqtDr96/w1lOP+aijqP9f38eny3+O5nEL0P+qfrZdWt05c6Qs++Uk2+RcF1zyORQM3oyGv78LRyoOq9rkOU8+ZnJezIwO2Yeg3eVBXJp2nScf21BcXLyt8+PcTBMXF7Tb3K2TjPeSrjPbd3GxybX5cUG82X72OC+F4uz6ajl0DCoF+6zjvGNy7TpPbl/He3GmXfJuyH4j1IJ1Lfjq7laoWXe3+eYplZZX2koiIiLq1tTrIP1KqE0yfatC/359zTs12Uo0b4PU7uTFnHk558qpG/RyOewMzTpvgUzd5NZdZA29f1nyDKRVRWXMnWg5J2qFhhOngP4DUCSXH7j9On0SDUUDUdTbbqmpAScbizCwny3Lik1nceJcHwwqNNt124/mbZKpY527BSP5/EmfJ7mOWiC8OW8/4nN9OlOrvTx9S/o8gyyr+0+7II+EOdGyc+5cK78NqnCgrfHZLQQ7ELdFEY3TJSUan2uc5Z8ArSVxoQojJc6Ji1OBKccbjVNJ9xcX520obZwTF+etH4iUg6JZaDh9Gr369keh+72gj0PqG1HQrxAFKf0p5xrRcLYPiuRrpCLN5t9lUlAOd28rzM/G02fRu38fmF9XJt6GqzxatrnEqQXXX9r4lP7SxalcLWTdvsTF1Qe5LOmFoD/HxRl2/eSK4fUDtuzFGdE4K7mDVq5xTqQix7heF43vXt8GJQM1tybw2JISvIxv4Ymbh9uG9lezbhkqSu/ErBG2goiIiLpUt/g2KHkBJm929QsxP3eZSyJb7kkNMUvJ0GRNbC6vcGVJ5brGVCZzndmyjo3LTRasZhbT5n4S4Txu/zLkEqWXXS6LyVwvRXP1089dctxyujxEVRYNtgM1umyj+g80NyCWAKkqKMLA/l5ZfvQp1AM1sqz3JGb/zM+42mSeUTQ4ZWW14NWZ/YjkusmUzZIsuJZIjF0yP8NlnbtFJybEz3WmfqTL5Ydk8lMXc8jDSXi5Xkyfu4c3yO0PP5c2V/ayIG8tMwQrbzpV0p/em9khwSfz8kbPtdsUmiXh2nVu1w/ivDynOFWvUjLO1kfzjHF2/3Wc1x6Kk3XD29dJx5l6l4J2m7v9l33QdSlJ2lTurWPqvaTXtXFBnVuO6df155KOScYV9e9nBmqCPsxyUb8+dqAmkiSuVx/1H5ldDtpMn+5cujZ9zC5O5UG7TdJe1L8AfeS4vPaU3Pahz7GLC8Xb7Qdx0fZscdKvfW7qOK89Gue3u9w+LhKnk9Tb3CUXp8tBf2bZ9GvbgjqbR+KCmFCcbDvZdyjGTzrOLXv1ut9IW0xcaB+lbOO6l+1YLgM1mx7FrEttVURl+VSUzN8A811nbVNcWoKqio6dvUNERESdqxPuWSOpWScpBLn8CdpU7sqh+kjSbV6eIakfGfPoshRN2eY6M2Wdx247GhPJMyT1I5THJfUjlIeS248gt9tM2bZXDmJtHrTplfSyyaN9+G3JPGOKbiuaSzfBsl82uSxIvcuDGC83Ycm8RUn+ZMojy+qHLrvcVIVz+ZEsx6XUdcK5l/Q2vDxSr34k29QfVw7VR5L64eWSZcrjkhfjtqFzbx1bL5Xyx+W6rpX0vSoi996QN7zmvhbmnhb6Ph9e0u0qXucqmfuO2DhddnGm3yAuiLftWePC20/Gx8TJ+n67zu36QVwyd8nFmRRtT+6XLtt2HePX6W1LMnVBu+3X7VOoPZSH43Qu9bZf11+Qx8bZdj9e6l2/Os7mbnuhONfuxUuc358Xb1IyTpZNe3LZ7Jctu3bXZrfv4oIYWdZ10ibLts3VpY2T3CY/JhRnk1vH1bntR+P87fvJrROK89vcsqzrx9mk271+/X0Jxcm6XlwQL8nr123Db9e5XT+IM7l5LiT7Nc8F9Vh1KxOxcNej2We6bE6gyi62yYibULp3CdYftGUiIiLq9jrhnjUuN0t+LksuT4nQsy3UUpCbtlDuPsoPPu6P5iYLck+0KS40XGf3y+Vpt2lzIcsuuXKa3C6Ft6GXkqJ1cTGBoG+TpWxTGvSin8uCKZuq5LHqXP10ufkZV5vMM4oGp6ysFvSyyfU2suT+H7Nm5lyWwrknXYjNdaZ+pM/NVnRuK3WWIQ8n4eV6MVo2i6nlSHVM7mXBUyIoez8z5y5J5pdV0tXJ3G2jNcwn7e4T9+Qn7S6ZT9xdMp/IB2Vp95YlD8fb5OrkjWJcu0tBXGQ5iFHrp4uLSylxabafEpcmyf6rXB+jt07onOh2bz9du4636wdxXu7FBe0uzyku+di0rj9v/Wju4rx4l1y7m9Hh1jN1XtmmIN5Pui0820OnoC2yHE26H7P9rHHR5aAuuX13rC7FHoMku66Jt+t78UEeiotp17l5bqbExcXHxkWeW67d5Tou/BilxPUwk8u2ILHrTky25dbZjuX2XjUV1+UwOERERETdRsfPrNF/5LVW8hP2uFxejOlP39PmupMgl8VQrrJoLm2hPJRsjMuDdUzu+gjlKvl5pqR+mjxa9vLoNpNJ/VELfp38COdmHT/XC6HcJcnMcnJ/UnOzHy4364Ry/cfk5q+U/LIuBLnm514y+5Ehlz96uy3IvT/mb+bcFnSuujDFtLmJCZL8yZa7P1Jhl4Nc1UVzaXO5zqK5+uHnyRQtq2TCvNzG2Nws2Txa1pn8VClNro9JpeDY/LLOJQvnrRV80u7nXooty6fx+hN598l8MoXi/bZIXCh5/WWNi1uOpo7oL245moI29YDExskDFjlnajntObdxwTm39a49yF2c5F5/GfNMcW3pLy4+pj+XXFyoLDGun7h4VxdpS5u8/jKuY9vUQqg+pRzpL1186Fx4cSl5p8XJ74oMcRRDZvDIoM8WlL5+N2fWEBER9SAdf88a2JkDenaGfNLuctMWyuXjd5eLlNxkLtwups39JMK53S+Xp92ml/vJ1aXJ7VJ4G3opKVoXyv1AkRJkF1wuDbIoZV0lua6wf005mZsYl5ufcbXJPCRaGQ2OW9mrM/uRPjdLsuBy2+aVbWB8nkOIn+tM/Uifqz+2rE+rrsmch5Pwcr2YPjfbUEsutz/8PLw/Zlnn0bL3M+dcd6JSkOvKIDfVbj/tMQfN+qfLgry1gk/Y9YiP9wm8fNIvZWlXdUEub+5cfTQP4swbQF1v+3XJzSDQZd1ftF1yWTccl1w2/YZSSpxdPzbO9uuvkxJn14+N8/r121LivBS0mT7dudJ1KrlzGJRtnC67eJ3MtkOPlWv34kKPneQuzt9+tN3P7bGnxOl+7ewMaXd5bJxtd/U6zq5v64J421eyv2SMW18n+7iYZVdncz+pOL/PZJus623f78Nfjuxjsk36jbT5ycbJ4+z3lzwGWTd5bnWMa3d1KpljTMbpXMeZ7bv+gjwlzsul3uVZ43qW9rxnDVCLKkxHKWfWEBER9RgdP1ijXmiZT9ajybUlc1evc/mjc1cvSS3rehcTzaXNK3tJ/QjlcUn9COUZU3TbejW/7MdEy3pB/kZytWBzfzldHkpuG9FytD5IqhvdZnLz189Nm8tlHVOdPs+Y5E+mPJLUD92WzM02XFkW9XLa3Cxnzl1SZd2n/hmfR5L6odtcHmq3Zd0W5JK1JI/U6T6juf6pc6mUPzp3yba53LW5vGVJVsuQ622oZX369U9dDnJTaLlevdX7Snu/EnkT6HL5xF0+aXe53NNC5167zu29LoK4ZO6Si5MYP06X3b0yXLy0u7ZIXBDjt+t+bZuLV0n34dXpY3TtKg/adb/JYzN9JvfBxQW5jdO5bjf9psZ5/br2IE6O2Y+T3Lb78aE4L1frJPuz68fEuXuSuP5ccvuly/a8mGXbHsSb7QRtfnL1LsbVheIibX7yY9K1u/30U9DmkmwjTZy//y65tiBO1k0T5/YtiLNtoThZ148zufph6m2ce8xcnG7X8WZ9E+/q7GPgxbn2IM8aF+43GSf7GnnOuFx+u6jfB91J8HXat67GxkU3xn+Fdzvds6Zm3RJUXXcTim2ZiIiIur9e6o1VK99FJaX7Csy6ulPo3bs3ehf0Ui+2bEOOJFw+kM+UZySHJR/pZ8pb0GNcdO5rx8jaYeYAeeEq8xnCeTiqTeI3m3YDqc2p+5e+g5gOs4nrzsv1w5xaHcozy7RmDj1kWb3t+xfl1nQy9azyyA7oYjRPNuu8rQrU74LBgwe06Ku7++5/E73qj8bsQLTCllN2OGVFwz9ALdc4J1KRc5xKOi4amGucY+tbHKdLSjQ+Uk4bZ6Ucb5o4V5/SHKnw+8ul35acv1B/TjQ+JcCKxqnk+g0Jl91mXb1bzXG/r12D/Dccbne7bX+vS386LlLf4jiby/ZaFZcmXsep3/OS23ojWk7GO6Y92XMo3t9w0SDgki+gftSXu89Xd3cifnU3ERFRfmmPr+7usMGac+fO4fTpM7qtT5+YndEvwtSrsEy5Ey3HkFYVlTFvkawdehXB/iUD0r749fI2ydRx7AZcg2H2LzyYkjq40gZx+5Nh/7KHZ49IzTPIsrp+GqZWh/KWydRTtEdVjuyALkbzZHNo7fbhenb8Lannh9qB4M1ZkKtW1exyR/eiKvv1LUT//v30AG4u5HdI76O7UXj0Q/UuqsHWOt4GhL/BkGicSvowovExcVo0zrH1ksX250TjdEmJxtsAfQJtUYvGGe58u2b379ZVyE9dsnF+tyaX+NbEqVzHRepzjksXnyVOVYT3TyKM2HJQTNaHJDuy0sS5+pTmaIUXl0u/yR20MsSF+nMiFTnHqRQ+QVbQoEvp45xIvY6L24FonEq5bl/z4op/H2dHXINzF4yP/R3CwZq7cc2iCr1c9twWLGzbXYuJiIiojfJ6sEa6bWxsxMlTZ9SL7F56J91LsbiXdFn5K7oXe8Grd5u7gKCcnhedNm+RrB26BZv5+6ty86Ykmoe7aZPw5uJzT2pz6v6l78jlLZClO/0wp1aH8swyrRntIabHSLjen2geCXOi5dy4nhy/55g8sgMt2b+O4W+pF3qrnRg4sB8KCwvV/kh9du53yIADb6BXQ51USK3pNeVAggXLBvgHrkXjrNi4UIWREudE41TScSmBlq1vcZwuKdH4SDljnOoo1/Pi6kNxoRUNv7+s+2m3HxIp27D4/QxVGNnOn6P7y3H7Wlyct/2gGI1z4uJi9j8SZwavknFuLbek23Wc683+u9CtrhwXlyY+1ziXS3yoPkOcWmjN9g0bN2gEMGwcTo3+47S/Q873wRoiIiLKL3k9WCPkhU9DQyPO1JtPxfUlUfZFVvJFW/o8o5QV1IJ+tRcte3mGLcS1po/OQUs61OVwQPBiO0PeJuHNxeeOKuvTqBbTh6dvSZ9nkGX17PuTjYt0MvUU7VGVs+xA2/cvm0w9q1zvQDIPvRlyeWStjiBvquTffL9+RSgqKoz9ZZWJ/A45d+Y4+h9+B72aTgNn6/XOu/12e+6Oyx2I+XeS5P7dhOKDelMbylVA/HmKxpt+dXxKvV+2eUq/dn2dR+L8cpAn6zXdn9m+4+IcXU6uEF5fL3k1QTEZERYXF+7RiMbpktLaOEu21+q4mP1MiXPi4lSgPl5fyopGbJy3oaCYZv247cfvqKH3T3KVcuk3iNMlJRqfa5zlb19LE+fqQ3GhFQ3pr7eqLxwEDP0MMOAinC6eit79hqT9HcLBGiIiIsoneT9YI13Li5+zZ8+qJPk5nFVlIur5+qhfTH369FZJ8j5mdp0eUcmd/zuk78kECk/vR6+G46rhnI0goh5Jbi5eNASN/UehfmBJ1t8hHKwhIiKifJL3gzVCupd7T+hPyOUbH1S5HTZJRHlM3lDpWTW9e+tfUJK3dKDG4e8QovNPS3+HcLCGiIiI8kneDNY0npWv4czcjXuD1Q6bI6JuwL3ZyvQGqyX4O4To/JLr7xBpL+zTskssu9dgzXYsn/8RvrmiPb6au/V9VZZPxWysRKJsoq3x1WL9/OcxZsWdaO97Gx98qwZXfGR/71/UH8e+MtgsExER5bG8Gaxp0p9687IEIiIi6lwFBb1R0Du3b5lzOFjTHn35Omiw5sBRzK0AymdfgBE4hRfWnsC+378YZVfadiIiojzVHoM1LXt1k4a8SGqvT8+JiIiIciGvPVo6UJPP5Cu4SyZM1Wl5pa20qlzb/A2o0TUy8OKWlcplWLCu1lvejvXzTV9BfYTMlkn2F8/fp3A/avu2vqT8P2xdkllvGSKH0SIHawvsQI0YgC+P6oVtx0/pEhERUU/Xbq9w+hRwwIaIiIg6h7zmkNcePUblMlyz9zYkdm1R6SWMWXE31h+0bZuX4kks0m1rxy/FmhxGQDYuegZ4SPpaiasWPZ8yaCIDNRXXqfYss2yKb35Ub/edJaW2xqgsn4cdS14y+3tdAndttg0hCVS5Y2iFEVcOtgM14hTe3A/cdNkAWyYiIurZ2u1VjrtmXKYjc9CGiIiIOoKeTaNea8hrjp70eqNmXwJl17n7wQzHrBWPYpYbqZh2PxbfPFwvjhlbih374mfK+GYuWWTXH40x08KDJhX2/jMLW33NUi2qdpfiq6VmnzD5W3hsmll0zCCPdwxtYi6B2jBqIL4+0lYRERH1cO1yzxoiIiKi7iIf71kjlw2tufTRmAGU8H1mJO4BLMITN1eH7z8jlz7t+5aqHx5e1veTWQI8JAMncunSPOC5LSh93cysyXXAJrndaJ/S2nE3GE4O1AzCqms5q4aIiLqHvLlnDRERERG1XvGlJSh/fbstyeCHdxlUrNEYgzdQYWNkZk5Opt2Pb04GJpetBG7Nto10hmPM+Aq8XOFm+FSjKnIZVHvcs8YM1JwESi9OM1Aj50numePOGxERUc/BwRoiIiKirjb5Trwz9hl7M98bUTU/2yVEwzFrfgnummFu8vvARluds4lY+Jysn3nAxgy6TMU1iyqwcdGNellufiyDPVfZcsmEZ7AjchmU0bZ71mDnGdxxphl3vH4IQ1fbtPYokl3KIFEpHpsb93XiRERE3RsvgyIiIqLzSvf66m5K6+AGLHgQWNzuX0VORETUNrwMioiIiIjapnKZnSHjp7ZewtQJPkkAM7/EgRoiIuqROLOGiIiIziucWUNEREQdiTNriIiIiIiIiIh6GA7WEBERERERERHlEQ7WEBERERERERHlEQ7WEBERERERERHlEQ7WEBEREeWt7Vg+fwNqbKltWtpXLdbPd98OdTfWH7TVHUG+hrt8uy047XnsGew8gqGrD5m09ig68jCJiIhyxcEaIiIiIooxHLNWbEFi10t4bJqtai8yODNhKhasq7UVXaUO5duAX865GMdU+uWgBpS9dcq2ERERdR0O1hARERHlgZp1d9tZLFOxvNJWWlWuLZhpEpl1UrksOfChl7cHs2LSDYhUlvv9tZxe3+5vchsyG2cZKtU+mDa1bFv0Ptv4khlLcdVzW/DEzdWmTpU3Pj0v6M8//tRjN8z58vtvhZ3Al+cMwxdt8YuX9MGGuiZbIiIi6jocrCEiIiLqapXLcM3e25DYZWayjFnhXXa0eSmexCLdtnb8UqzJYXRi46JngIekr5W4atHzKQMaMtBScZ1qX3ETim1dS8hAiV5f7+8WfG/vEu8yqdWY/foMXf/OkgSetAM5NeuewY4lL5l1Nt2PHStk8GUiFtryzNtXBv0tnKxXyeHYE6hqy3VLVw4OBmrE25+cxQOXDLYlIiKirsPBGiIiIqIuVrMvgbLrJtqSXH70KGaNsMVp92PxzcP14pixpdixL/ulQzOXLLLrj8aYaeEBjYryqZiNlckBkVao2luB8lvtLBmVZj9dgapPbCPmYG2ZOZbiS0uwcW+1XpZ1WizDsRff/CgSu7zz1EZvv3oIf4L+KLvSVhAREXUhDtYQERERnS82L0XVdVuwFvNSLrXKXS2qdpfisU3JmTWh2TBpTC6TGTg3mgGeGW/gqw+1blZPR3ADNce+wlk1RESUHzhYQ0RERNTFZAZK+evu25Dkvi/Zvn1pNMbgDVTYGJmZk5Np9+Obk2XgZCVwa2u/4Wk4SmcCd61qyf5GL51q+4yYdrlnjSIDNW9ecnGagRr7jVgp31RFRETUsThYQ0RERNTVJt+Jd8Y+Yy8ruhFV87MNZgzHrPkluGuGuQzpgY22OmcTsfA5WT/TIIv76u4bcdfmCrstMzgilyDJ7By3vy/PdJddpVd8822Ad+lU6OvAR1yGq9LcYDizNt6z5sBRPH4YWLzNfnW3Tkfwtm0GqlG1uRSPzXWXqBEREXWOXs2KXSYiIiLq8Roaz9qlpKamJnx6tA6jR15ka6h9ycDP8xiz4k4EV0vJt1bt+xaesPekyUvyFeMPAotbeSNmIiI6P1UfOIwLLxiMgoICW5NUVNjHLmXGmTVERERE57Pga7b91PbLi6LGjE9gtr+NW4Hv5fNAjfgkAcz8EgdqiIio03FmDREREZ1XOLOGiIiIOhJn1hARERERERER9TAcrCEiIiIiIiIiyiMcrCEiIiIiIiIiyiMcrCEiIiIiIiIiyiMcrCEiIiLKB/I10eXbbaGN2rOvdGpew3e37QISq/DdD2psZTo1+Pk7i/HzIEzKq/CeLYmaDxZj7DuvqZbuahcerggfU8uknpN2oR6fsfI4OTk9XucBef5WfAdjdQqf9/e2yXO1gx4PIqIccbCGiIiIiLpc8WcfwN5rrufXZFMn2IWHd7+FG8b/DHtLf4YtwxK4xR/QIiLKAxysISIiIupS27F8wlSUzFiKjU/PQ4ksq7S80jZXLgvqSuZvMDNPdN3dWH9QR6Bm3d22LUtfSmW5108+kJkfboZDO7xhfm+bmy3xnWAGiZ61E5ldEpRjZ1jIrApbp+L0+rY/WQ7NTJH1vRlBu23s2IroTCK3Db9eZuO47WyzdWZ/M22j3fjH7voPZt7Ivtl9lbhsj03s45j+PIq4xyq91JlLsv7DieSy68vVRfdbtq/baopxR+kD+IYdGSzuV4LpfTlMSER5ppmIiIjoPFLf0JiSTp0+0/zJ/hob0UUOrG+e/+Nf2YIVrdv6WPP8tYfNsrR9b33zIZebWiOuL2vrj/+w+dI/eKx5qy13jkPNa97+dvPl/+GnZ5srbav20bPNl7+/0xZa59CvH2pe+pEtKJXvP9S8Rp+Ync1Lve2F6t/+ZfLcHfpl8+3+Pujys81rfu2f3Whf37bblPpvN9/uYr3jScaI5PpSH4oP+k23jVbQ/YbPvdlmeBvB/rpzoPKl6tiXSqxqy7x91VdwHuWxdufXijmP6R+r9GSd4HxJn3aboXp/++5YrOg2dbucE/85QETUDuQ1hby2iHvNkSvOrCEiIiLKV58kQjNkSm5djY17q03biJuweOYbuGbGG/jqQzflfPnQ5LItSOy6E5NtufOMw8P2spO9peV4uNBWt6OP6/fgqerkDItbTu7B3pPSMgEzByawW0/e2IWNDddihpywmmrsaVyFqTZ+7O5VeKOhOjyDRa0//rP+2Z2AO4apx0XP3pC+5uKOEt2gXI+FLrZkCu44uRXvqd52N1yPmUGM2xepH4cbhrv4md45ybSNVhh4jz3vKo2+3tTJsQ+cgqtNyeyvHHvxaIyT/OR+YOgUoL4GNWfcVJV0JuC+4BK2YowvcufdEzmP6R+r9Io/+zWMq9umH5+a2rcwrths8+N6JM+jqpkxGFn70uQYh5Xz8jsiykscrCEiIiLKUzX7Epi55CUkdskAi01lE20rhZnBj+SAkEn32UGOq4eW4JVa9Ta/phoYPMm8OVdv1t/wBzIkRd+4+wMaVvHwa7Hn2C4gsRV7XF9p1WBvo11sgZZtoxXk2O1iWDHGYj82nQHGDpTlamyql2XbHMu/zEsGXmy1L3QeMz9W6U3AzKK3sKmmBpvqSuwAmPSlG1uuZC5+EhqIIyLKHxysISIiIspTxaXTgUXPw91yRu5Ns2BdrSlULsM1e29DYtN0vPxg7vegybt71mSj74Xi3+clHTOj4r5q/34p3nolU/SsjPdq92NsMJtFZr/8Ihnj38smk+LrsRCPYGw1kjNpNDd7Rxa34ik9QCEzaV6zs2TELmw8WYLxxWYGih5A0iKDOmm3odh7zQT3ZmmNYOaPJftbNFqdRdkvYG89zD5iP/ZC9tfGxUlsxH1FbtCrHC8OHGcb0snyWGVw9ehr8cruMrwyeKYd/DF9+edxU50dXJJZQt4xymwen77PTUvvBRS5XxQRUUfhYA0RERFRPhhxGa6K3hR4xE144jlgtq27ZuN0LL55uHnDeCuwVmbZuMuhJiwLBnVi+/JtTqDKLnY5d2Pa6teAk4/oZf9ms/oSnIFfC24Gm4l8o9SLMsChZ3jIG/oF3noyK2MVbqkbZS6B0ibgvvHy5t/OCqkGXpw0QdXbmSJyWZTdp+jXO1899PrYWTevJFxfCTw8WvpSsZPKMbbG1lf8AmPHz9XrXT3pHow7UhbU74lcGpZuG86eMy0aZoiQYx+F5XrbKtWMwhZ97MBn+ibwVMMofCaynJZcwtXgztMT2D30WuyplvOV/jxmfqwyKJ6EGwq9y8cU6WthvTuPZdhb7G4ebC4nu0XXfwfLG2IGkRr342O7mAuZ7Ybbb8OsEbaCiKiD9JIb19hlIiIioh6vofGsXUpqamrCp0frMHrkRbaG8oXMftg4NJdLZDpXZ+xXvh57l5JZRQngR110nxmZmVZx3RYs7PybPhFRN1J94DAuvGAwCgoKbE1SUWEfu5QZZ9YQERERUZ6K3pw3D9hLkG5p601/M+mMbXRD+rKl3auCGwt3vlpU7Z6DUg7UEFEn4MwaIiIiOq9wZg0RERF1JM6sISIiIiIiIiLqYThYQ0RERERERESURzhYQ0RERERERESURzhYQ0RERERERESURzhYQ0RERJTXarF+/jJU2lLbtKKvymVYsK7WFsJq1t2NkvkbUGPLXa8O5asPYahLr9bZ+vTeftWLV2nuW6dsCxERUdfhYA0RERERtUrxzY8iseKmLvoa5VRvv3oamHQxjs2RNAhPnTiN8p22Ma0++KWON2nVtQNsPRERUdfhYA0RERFRl5MZL1NRMsGm8u26trJcyjfirs2rMTvSJjNeovHCrKOSzHhxMao9Y19xDm7AAom5dTU2LrrRxE+4G+sPqrY029azcMpVUvXLK+0xBTNvwse4PDS9ZzuWq7p0M3hydengXnbJ6YVLh9vFWKew74RdJCIiyiO9mhW7TERERNTjNTSetUtJTU1N+PRoHUaPvMjWdDIZ5Nj3LTxxsxlZqFm3DBWld2LWCCnJIMfzGLPiTkzWrWI7ls//CN/Us1qkfQnw0KM2Xkj7JmDmDCy8eaKtE3F9ZRHZtxAZtHl9BhJldhtSXlGCdx4C1jyYwJiHvgU8aLaH8rtRNdftY3Q/ZLBmHspvX5nsq5XksqY/OSxLvfDUdcX4+khdncYpvPDqGew7cRaLz0hZZtkMwxd1GxERUetUHziMCy8YjIKCAluTVFTYxy5lxpk1RERERF2sZl/Czl4xM1eKb3YDNelMxMLg8qPhGDO+AlWf6ELS5gTGlLZt4KM1Zs78kt6vHeNneMdQi6rdFbhrhptZIzN8EqiSWTqaOp5dW9ploObNS9wlTQOBikNZLoNqwr7DTbi01K4zCfiTHO5zQ0RE1NE4WENERETUxfS9X2SwYtdtqNIDGvZyo7TClxTNftpW+6ZNR2nGAZ/OVI2qzXOwVh+jS/5MoPYglzT1wZevtEUMwJdH9cK245luGDwYZXO82TdXFuKBE03IeOqJiIg6AQdriIiIiLpa5QY7OGNmmKy9PWamjK/yedw1fqUd9HhJxZfahnw1EaW3r8aTwT1p5LIn/1up2uOeNQNw6aCzeDOYSXMKb+5vxqQhyRsG629+Wns0ORhz4Cjmrj6Ct20ROxuxeFABkmNIdlAs0719iIiIOgAHa4iIiIi6VC3W70vYGTV2pgxWYmFwUxm5zClyU+DJ38Jju+fZ+CWoum46dtxqBj/MjYTnoXzzUlyj2/1ZOjF9ZXNJCZDuBsO3rgaeNvuRbaBlctlL+OpG18884LnU++Zs3Fttl1rni1/pD2xzX8N9AncM6o+yYKaNdeYc9tlFjLwAq+TSJ/fV3duAX35lsG0UMiOoFI/N7fzLyYiI6PzGGwwTERHReSUvbzBM+Um+EetBYHEefT05ERHlP95gmIiIiIjaxs2SCSX/EqXz2CcJwN4wmYiIqDNxZg0RERGdVzizhoiIiDoSZ9YQEREREREREfUwHKwhIiIiIiIiIsojHKwhIiIiIiIiIsojHKwhIiIi6u4ql2X96myjFuvnp7t58HYsnzAVy/PqzsJ1KJev1F57FMG3j2un8MJa9xXdNXjhgK1Oy483qXynbSIiIspDHKwhIiIiImUiFu7agoWTbbHLyUDNaWy7rAgP2Brn7VdPYMOoQTg252Icu64QG14/grdtW1qDivChxNtUdqWtJyIiykMcrCEiIiLKA5Xlya/OTs6S2Y7l8zegct3dpk0t19iWGlc34W6s32crMzD934i7Nq/GbLudkvLtqkVm29iy9BVMYZFtL1PJxJntJdvj99cwsW37+u+3X5WBmkFYdW30mzTq8ObhPvjBtQNMceQF+MFFTdiXcXaNaj9hF4mIiLoBDtYQERERdTEZ3Ki4bgsSu0z63t4lyUGTzUvxJBbp+rXjl2KNjIAc3IAHFpVgrY5fBGxcbWIzmFwmsS/hsWlz7HoqlU1ULcMxa4VrM7GBzQmMeUjV4xmsUfvwzhKg6pMs+xtIoCqlLndf/MrFWOUGZLJqxr5sV4ENOodV7jKolMuqiIiI8gsHa4iIiIi6WNXeCpTfmpypMvvpCj0ook27H4tvHq4Xx4wtxQ4ZlfgkgY23z4C5Ymk4Zs2fo5fa3bTpKB2h8t0lKLX7IDLur1J886NI7HoUs2TdDmPuZ5PTvWcONGHbYeDL9hKoD0c1ouytU7aRiIgo/3CwhoiIiKhL1aJqdyke25ScqSIpf+4dE5Uv+zsYZcG9Z3rh0uRYUqqRF2DVnGH4oi2OuKwQqGuyJSIiovzDwRoiIiKiLjUcpTOBu1bJ/WOE3EPGv3dMjEtKMPPpTcE9YWr2JexSZ8i+v+1xz5r0BuPLF53F425mzIGjePxwAS4daYpuxs1cf+bMziOhS58OftSouoneC4eIiCh/cLCGiIiIqIvJZUNrMc9eVnQjXp65KPMlRCNuwuIlieBGwQ9stPVZDceY8eluMCw3H67AXTNkOfNAS27727Z71sggzFx9j5nTWHymAVd495r54lcG4ab9J8z9Z15vxE3XJWfNOBv8mTNXDtOXPuk+VLpifyHKc74fDhERUefr1azYZSIiIqIer6HxrF1KampqwqdH6zB65EW2hoiIiKh1qg8cxoUXDEZBQeoszqLCPnYpM86sISIiIuox/K/hTqboV2sTERFRfuPMGiIiIjqvcGYNERERdSTOrCEiIiIiIiIi6mE4WENERERERERElEc4WENERERERERElEc4WENERERERERElEc4WENERETU3iqX8ZuYiIiIqNU4WENERETU3ibficSuLUhsuh9X2SoiIiKiXHGwhoiIiKiD1FQkMKZ0uC0RERER5YaDNUREREQd4eAGPLB3BmaNsGUiIiKiHHGwhoiIiKgjjLgJT1y3yd67ZhkqbTURERFRNhysISIiIuoIBzdgweszzL1rdt2JybaaiIiIKBsO1hARERF1hBGX4ardH6HGFnNTi/Xzp6KkfLstExER0fmIgzVEREREHWIiFs5PYE2Lrn+qRtXmUjw2d6ItExER0fmIgzVEREREHeWSEmBfrS3k4OBH2DFtOkp5U2IiIqLzGgdriIiIiNpb5TJzY+EZS7HDVuXkkwQw80sotkUiIiI6P/VqVuwyERERUY/X0HjWLiU1NTXh06N1GD3yIltDRERE1DrVBw7jwgsGo6CgwNYkFRX2sUuZcWYNEREREREREVEe4WANEREREREREVEe4WANEREREREREVEe4WANEREREREREVEe4WANERERUburxfr5U803Qqm0vNJWd4CadXd3ynaIiIio83CwhoiIiKid1axbgpdnvoTEri1IbLofO25dho4bRynBY5vUdtS2Fk62VURERNStcbCGiIiIqF3VourSRXji5uGmOOJL+Oq0BKoOmqKoLJ+KkvkbUGPLbVFcWoKqilpbIiIiop6AgzVERERE7Wo4Jk+2AzXi4H/gZUxH6QhbdjYnUGUX22TETSjduwTrvcEgIiIi6t56NSt2mYiIiKjHa2g8a5eSmpqa8OnROoweeZGtaScHN2DBjDfw1U2PYlZ0sKbNtmP5hHkoV0tlz/ESKCIionxRfeAwLrxgMAoKCmxNUlFhH7uUGWfWEBEREXWEDh2oEROxUO6Jo1Lp63dzZg0REVEPwsEaIiIiovYmAzUPAot3xQ/UtOc9a/Q9cuIusyIiIqJui4M1RERERO2sctVSbNy8FNfYr9SWtGBd5CbA7XTPGvnmqarrbkKxLRMREVH3x3vWEBER0XmlU+9Z0wlq1i1DRemdHXSpFREREbUU71lDREREdN5L4K4ZZvbO8kpbRURERN0aZ9YQERHReaWnzawhIiKi/MKZNUREREREREREPQwHa4iIiIiIiIiI8ggHa4iIiIiIiIiI8ggHa4iIiIjy1nYsn78BNbbUNq3vq7J8KkrKt9tSVC3Wz1+Gjri38cG3ajB09SGT1h7FQVtPRETU03GwhoiIiIgymly2BYmyibbUSXYewRV1/XBszsU6/XJQA1bttG1EREQ9HAdriIiIiPJAzbq79ddvx30Fd5VrC2bGRGbJVC7DgnW13vJ2rJ9v+grqI/RsmSwzbfx9Cvejtm/rS8r/w9YlmfXaONvmymE49pXBtiB64dLhdpGIiKiH42ANERERUVerXIZr9t6GxK4tKr2EMSvuxnp3zc/mpXgSi3Tb2vFLsSaHEZCNi54BHpK+VuKqRc+nDJrIQE3Fdap9xU0otnVxim9+VG/3nSWltsaoLJ+HHUteMvt7XQJ3bbYNIQlUtfm6pTqU28ug3rykGF8faauJiIh6OA7WEBEREXWxmn0JlF3nLjMajlkrHsWsEbY47X4svtlMKRkzthQ79sXPlPHNXLLIrj8aY6aFB00qyqdiNlZi4WRb0WK1qNpdiq+W2mkuk7+Fx6aZRccM8njH0GqDUWYvg/ryJ4dQzsugiIjoPMHBGiIiIqLzxealqLpuC9ZiXsqlVvnu0sG9sO34KVsiIiLq2ThYQ0RERNTFii8tQfnr7tuW5NuVvMugYo3GGLyBChsjM3NyMu1+fHOy3DB4JXBrtm2kMxxjxlfg5Qo3w6caVZHLoNrjnjVvv3oIc99KDs7sq2vGpCEDbEnIeZJ75qT7lioiIqLui4M1RERERF1t8p14Z+wz9ma+N6JqfrZLiIZj1vwS3DXD3OT3gY22OmcTsfA5WT/zgI27wfA1iyqwcdGNellm5Mhgz1W2XDLhGeyIXAZltO2eNV/8ysX4Qd2J4Ku7/wT9UXalbdRkkKgUj83t5G+pIiIi6gS9mhW7TERERNTjNTSetUtJTU1N+PRoHUaPvMjWUN47uAELHgQWZ7lJMhERUWerPnAYF14wGAUFBbYmqaiwj13KjDNriIiIiM5nlcvsDBk/tfFrtzvDJwlg5pc4UENERD0SZ9YQERHReYUza4iIiKgjcWYNEREREREREVEPw8EaIiIiIiIiIqI8wsEaIiIiIiIiIqI8wsEaIiIiIiIiIqI8wsEaIiIiory1Hcvnb0CNLbVNS/uqxfr57tuh7sb6g7a6I8jXcJdvtwWnPY89iwNHMXf1IQx9tc5WEBERdS0O1hARERFRjOGYtWILErtewmPTbFV7kcGZCVOxYF2trehKdSh//Rx+MOdiHPvKYFtHRETUtThYQ0RERJQHatbdbWexTMXySltpVbm2YKZJZNZJ5bLkwIde3h7Mikk3IFJZ7vfXcnp9u7/JbchsnGWoVPtg2tSybdH7bONLZizFVc9twRM3V5s6Vd749LygP//4U4/dMOfL77913n71DC69bhi+aMtERET5gIM1RERERF2tchmu2XsbErvMTJYxK7zLjjYvxZNYpNvWjl+KNTmMTmxc9AzwkPS1Elctej5lQEMGWiquU+0rbkKxrWsJGSjR6+v93YLv7V3iXSa1GrNfn6Hr31mSwJN2IKdm3TPYseQls86m+7FjhQy+TMRCW555+8qgv4WT9So5HHsCVW26PKsOb54owL6KQxgql0GtrsELB2wTERFRF+JgDREREVEXq9mXQNl1E21JLj96FLNG2OK0+7H45uF6cczYUuzYl/3SoZlLFtn1R2PMtPCARkX5VMzGyuSASCtU7a1A+a12loxKs5+uQNUnthFzsLbMHEvxpSXYuLdaL8s6LZbh2ItvfhSJXd55ao2djVh8pgmXll6MY3IZ1KQC3FFxFB15ex4iIqJccLCGiIiI6HyxeSmqrtuCtZiXcqlV7mpRtbsUj21KzqwJzYZJY3KZzMC50QzwzHgDX32odbN62t1F/fD1kXb5ykI8YBeJiIi6EgdriIiIiLqYzEApf919G5Lc9yXbty+Nxhi8gQobIzNzcjLtfnxzsgycrARube03PA1H6UzgrlUt2d/opVNtnBGjtMs9a2Rw5nAj3rZFPdNmUAGSu2a/ESvlm6qIiIg6FgdriIiIiLra5Dvxzthn7GVFN6JqfrbBjOGYNb8Ed80wlyE9sNFW52wiFj4n62caZHFf3X0j7tpcYbdlBkfkEiSZneP29+WZ7rKr9Ipvvg3wLp0KfR34iMtwVZobDGfW1nvWDEbZJOBP9P1qVNoG/DL0jVDVqNpcisfmukvUiIiIOkevZsUuExEREfV4DY1n7VJSU1MTPj1ah9EjL7I11L5k4Od5jFlxJ4KrpeRbq/Z9C0/Ye9LkJfmK8QeBxa28ETMREZ2fqg8cxoUXDEZBQYGtSSoq7GOXMuPMGiIiIqLzWfA1235q+1diR40Zn8Bsfxu3At/L54Ea8UkCmPklDtQQEVGn48waIiIiOq9wZg0RERF1JM6sISIiIiIiIiLqYThYQ0RERERERESURzhYQ0RERERERESURzhYQ0RERERERESURzhYQ0RERJQP5Guiy7fbQhu1Z1/p1LyG727bBSRW4bsf1NjKTGrw83e+g7EVkhbj526VnNfvCLvwsN4fL8kx5bsWnTN1jO+8ps5+ZzDn8+GELXaEuGPPdj7kueo/5zrAe9vaoX91HPHPwzT/dlql/Z/zccde88HijM8DaR/bxufle9uSxxC7rZTHXc7jKrxnS92e+x2cC30u7PnqwN8H2R53ahkO1hARERFRh3tvWxleGVyOvaU/w97x1+KV3fnwpmkC7tP7MxfTC+diiyxPmmDbqOXM+byvxBZzZgcQOmqgrPh6/KT0AXwj37+DvWSu+fcx+npb4RTjG9eo+tJyPFxoq1otP57zxZ99AHuvub5NX4t/9SQ5Jz/DiwNtRVR3edw7gz4X9nG3VecrPVDYwYO37YWDNURERERdajuWT5iKkhlLsfHpeSiRZZWWV9rmymVBXcn8DeYTUV13N9Yf1BGoWXe3bcvSl1JZ7vXTaXZh48nrsfCz9l2TeuOwcGACu1N2wrxpd7MkzItq82lwcuaExIQHeuQT9s78NDd2v2R2xzaVVN3DCTsTItsn2HpGyK5g1kRodkjcLAv36Xj1a3jjSJltz+1Nx8dun/198j9tD51Tf/aFVx/sk2zTxUh7+pkf5pP2ZH/Jx8lf5xHsGVaeedAg67En+ws/V9w2IoOD/vnN8RzGPe6u7paTe3Dfbttf1pkL6c9X1/LPV+T5GCP7scc87nHPa8s/vymPV4tkeNw9Znuu3X9Mcvx9kuFY4sj2vvvBa8l989dJ21fcY2Lrdq/CGycfCdpa+zswPDNK9R08hmb5Pfe4pHlsU5/vybYWn0evLzlf8b87wrOqgudp0I8cj1vPPr7eNqYeKcGLehBPYsLPj87+vySrZiIiIqLzSH1DY0o6dfpM8yf7a2xEFzmwvnn+j39lC1a0butjzfPXHjbL0va99c2HXG5qjbi+rK0//sPmS//gseatttw5djYv/Y9nmyttSVS+/+3mpR+phY+ebb7917L3kZhDv2y+/f2dthBuO/Trh+w6UlBxb/8yfPwt1ZI+0u2XOo7LpQ/VvvTtZ5vXHDrUvEbl/jGnkHX+4yEVKwWvr8j+hI5XBOcsF9Lvt4P44LxLvX/M3nFVvu/2KWbbirQvff+XMccmx5xcV8j6l8cdlxx7msc3o7hjT3ceA9G66GOj2oN9SSPd42755ywbOSfmMVBC58GKq9NSz2+rRZ5jIrRfSuX7uT0mccee9nF3Uo5RndPI83Fpjs/x5HM6Kv3jHn1eh48hh3+7of3N7XEJnRN/ncj58fct42MSek7mKOaxCB+7f1xy/uJ+d0SO13sssz7uUdFjUH35xx7XV+o5CZ97KYd/P4X3N3p+g+dBLvvbAvKaQl5bxL3myBVn1hARERHlq08SoRkyJbeuxsa91aZtxE1YPPMNXDPjDXz1oZtyvpxgctkWJHbdicm2nB+24eGKR4DRc3G1rdHT9oOZFsUYW5iciVP82a9hXN02/QlsTe1bGKdiO+1Khwz7NX3wJL0fe4qm5HzpxfRhC2ys19fJ/YDtSxQPvxaotxtpjcK5+JGd1fSZvuOw54zqq6YaexpXYar9tFl/St9Qrc/p1ZPkU2cdjuJ+JXgjZdt7sKfvpORjlcUd7nEtHo1xjfvxsVqsOdO+H1/Hnse0arC38TXcIsetZzFMwH3ZLgXK8Li3lFwCFFwqNnAUptvz3tU+rt+Dp6qTsxGunuT9e2yFuMc9Le/5qGdKqPN9n5uJ1852f7AYU+uuDf5NyPNhd4M3O6iiDPc1Znt81XMmuIyrGOOL9mDvSV3IaPqwmfacFmPGYOCVWrWRDP/eW/OYhGYo5TDjJ6O43x3y7wfXYobbYbl8z/v306LHXR27PztIz5zzft/E9ZU8JybJzK7wuY/+fpJ/73Yxokv/L8kBB2uIiIiI8lTNvgRmLnkJiV0ywGJT2UTb2t2Nw1h7r4k3juzHzNJ7gGp/Sro3zV6/ebLV2gTMLHoLm2pqsKmuBDNbfI+Utsi0X+2jvQcyYsmbpIH3mHukuGTffIbe7Kk3T6nG4YbhbXtLIwMWW/r+wm4nMlDX4ex9W1QK9iHrm9p2fNz9yz5kkMxWdzV3D5i940dhud6/8CUiHUoGw+xjsrDeXOaW7TKs1nkNr2ABtgx+C/cG/cub+evxot2+SckBy3jhy6ZuyWGgJp1M/95b85jo+wG548g2CNnF5NinyyWQwXnPts8ysDYOD4/34lUK3ycr+vtJ/r1/DXvtYFx4oK4r/y/JjoM1RERERHmquHQ6sOh5uFvOyL1pFqyrNYXKZbhm721IbJqOlx/M/R40XXPPGvWCeOBrWO7eHNWo5ZMlGG9fL5tPm9UL6tHALfaeBTUf/MLcx0S/GE+9serVo+UmxXLTYvdJdZK+n0HKfRTaR7b9ag/6k3X7aa+QT3zRt22DIylKpuCOk79I3qtCBhD0gMUuPKXv6WDeBG0ZfX3H3JBUbe9e9aY5/s1WR1NvtD8wgzP6ja3cdDXL7Jb2e9zVtmsSyTeb7XLDVzOQ1NbBjZoPXjMDAXrgRI6x9bOHWm6XekzMxvQAhXrepc7oag/m3lnFn12AG+rK7P1JIr+f9PnMMiiS2Ij7itxgZzleHDjONmSWPCYZHIAeVMj0770zHpPP9LUzfITMcDJLGRRjLGSAwxaD3x0tp4/9yMbgXJv7+mQ6QDMj6b5qtz0ZNMt23yeJ2YqZ9ndN9MbWmf4v6WocrCEiIiLKByMuw1XRmwKPuAlPPAfMtnXXbJyOxTcPNzcYvhVYK7Ns3OVQE5YFgzqxffk2J1BlFzvL1ZPK9ZsjM5vgLdyg3qSmvDAumYsXi1Zh6juvATI9PbiR7EaMLy7BfQlvAKZ4Em4ojJvhIZ+8AnfkNJ3dzpaQ2Q3ukqAsbzr0tPlM+9Ue5I1Z8f7gEqWp9V/DT/xLQgaOUm9w4m6y2xITcJ/+Vi6zjbHVwIv6E+0JuGNYwlwipNK9Z6bghoZHzJtaOyPEv6GseWPlZhnIjBPXluXNbsnM5PPBppxu7NmiY3ezYR7BU7CXPckgXmIb9ta7WT0qyfOxJPPzJdvjLm94c7vBcDG+IesG5300FqrnvJ7l4WbcyGwme2lIS85vboMb6Z7zu7Cpfr+dvWG29cpgd2lZZrkfu5LmGGs+qFaPifd8CJ6P6bmbzMqsFnNZjHs+pHnc9VqOehzU75s9aj153oV+P+Uy00s9fx9W/y5M/BPYPfRa1Vf2WS/TG9zzTj2WRV8z5zftv/csj4lcGpTrDYbdDbpjfteFntuJt3RdZvLtZMmZKmNrRmFLa2fwyLHLIL30o1J41ks8GWB9Ee64vXOS9veT/JtLbkMn//mQ9v+SrtdLblxjl4mIiIh6vIbGs3YpqampCZ8ercPokRfZGsp78uZDvTn5UcrX/8obNfkUtTMvq6GWkm+g2T3au9REHs/q0d59YYh6Fpk1IrPJQgOv1PFifreEfv+k/b+kbaoPHMaFFwxGQUGBrUkqKuxjlzLjzBoiIiIi6lb0J+q7V8XfDFKm8Q+cwoGavFaDz/T1ZpdIktktozlQQ0TtbTTGBbOgTLoFZlZTxv9L8gBn1hAREdF5hTNriIiIqCNxZg0RERERERERUQ/DwRoiIiIiIiIiojzCwRoiIiIiIiIiojzCwRoiIiKivCJf05v9K2CppeLOa/ZzrW9AmeXrvLNzX71skv8Vu/INMVKWbydp3VdwExFRT8TBGiIiIiKiNK6e9DPsbcXXScsgzNgKMwDz3rYyvDK4HHtLVV/j52JPNQfjiIgoMw7WEBEREXW5XXjYfa3otm22zkqsCmZkuBkewSwMaXvnNciim6Ehdd/9YFcwk+O7H3jTNfy+7HqoeQ3ftXUPJ9wMkOyzPPSMk2A9W9mqvsKzTkKzWGKOXR/fNpX8bbhjUfz9csdu6spwX+NruCXanwi2kxxEMYMt4X60HM/v1CMleLH0AXyjuAafGf0z/OSz9othi0djXOEofMaUiIiIYnGwhoiIiKiLvbftEewZZmdeDN2P+xptgwx+1IzCFqlXaUvfX+jBgc/0BfaeVM1ngDuK9mNTDfBxfQlmlpjV3jjyC6BE1rkH445sNAMQ0texKWYbkor3414ZaCi+Hj+RvoeNA45ts+vJIIPuKpYMZCzva/e3tBxja+yATCv6QmJjctaJrNt3q+krzbGLNxpG4Ufj56qYjWob5XgY+/GxrKL2a+NQEy9pYf0Tui89O0bt58OF1+NF25acLfMabrHnZcuwBJbbbRR/9gFbp44lIvb8yqBTTQIPjzf9J/sqRrE+fjco9QuMLble1RqynfvU43b1pCzniYiIziscrCEiIiLqUjXY3TAONwy379RLZuLhQrOIk/uBwZOSb+yHXwvU16C4Xwn2nKnBx/XAzKEycCN92CBl+rAF9o1/McYWJrBbxgxUX2+cfCSY+TG2+jW8ofryPYXROQ0YyHaD/VXbmDHYDB75cu2r5kwCbxwpU/tkBnyKPzvXrJfm2MV0W7+naEpoGx/X78FT1fb4VLrl5J6U/Up1PV60AzdyXqPnJE7s+VWP4143yBZLtWMutmQbvCIiIlI4WENERESUp2QgI9bAUUD9NuzGKHxGls9sw15Zts1xpK/pbvaOS5F7sdwxNJd7s4QHhtLJrS8ZnDEzWPaWfg17d8sgixm0SXvsaZlBLzezxSWZtdI5JuC+4Bi+g6l11+JH7tInTbVfk5xRQ0RElAkHa4iIiIi6VDHGF+3BK7VuRkdyhoaeTVK3TdUYNbVvAX3V23257wn2Yy9Go1gto34/UKSWbVwc3VdwyY7q64PF4fut5MzMpPH3d1MdMHagLbZU4jVz2ZMe7PgZXhxoZsOkPfa0zH7dV+3uRSOXHWW/9077ke1txUw3UBQdmNH3s2nh/lQuQ8mEu7H+oC0TEdF5g4M1RERERF3s6kly7xO5FEhmZfwCe9xlUHIPmOL9mGov65la/zV7o9pijG14DXv04IW/nIH0NRrBDXaDmR/2psBTj3iXEGX5qmqZDbOw3u1vGfYW20t7WtxXDX5+Zn8wG0XSLbjHzIZJe+zpyX69CHepl3wDk7tcScigWJobDMdwNxiWYzGXaYW/cjtVsd5W0L8k78bHRi6XZSXV7FMbvP02zBphK4iI6LzRq1mxy0REREQ9XkPjWbuU1NTUhE+P1mH0yItsDVELyUBV9Wj8xLu0TL61a/fo1t+jprJ8Kiqu24KFk20FERF1C9UHDuPCCwajoKDA1iQVFfaxS5lxZg0RERERUZuNxrgG7wbOKt2Cr7XhZsK1qNo9B6UcqCEiOi9xZg0RERGdVzizhoiIiDoSZ9YQEREREREREfUwHKwhIiIiIiIiIsojHKwhIiIiIiIiIsojHKwhIiIiIiIiIsojHKwhIiIiymu1WD9/GSptqW1a0VflMixYV2sLYTXr7kbJ/A2oseW8sPMIhq4+hLlvnbIVTh3KVf3QtUdx0NZkZPsJUq7rERERtQMO1hARERFRqxTf/CgSK25Cq7+dur3JAMu2Jjx1WfSbNmSg5jS2XVaEB2xNLh6YdDGOzbFp9gUYYeuJiIg6GgdriIiIiLqczHiZipIJNpVv17WV5VK+EXdtXo3ZkTaZ8RKNF2YdlWTGi4tR7Rn7inNwAxZIzK2rsXHRjSZ+wt1YL9NL0mxbz8IpV0nVL6+0xxTMvAkf4/LQ9J7tWK7q0s3gyU0dymWg5rpifH2IrbLeflUGagZh1bWpX6GazsHjTXaJiIio83GwhoiIiKirVT6Pl2e+hMSuLTq9M3aTHhSZXCbll/DYtDlYa9sSZRPVCtuxfEUJ3tF1qn33M2YQRTHrrEQZElizb0awTvq+0hhxE56QmOfmYOYSt2+PYpZML5l8pymrtqiNu0uweNP9wIrngYfU9tR+VKn6yvIlqmy3q/ZjzIrUy7E27q22S60xGGVzivH1kbbo+eJXLsaqawfYUq4KgE9qgsugynfaaiIiok7AwRoiIiKiLlazL2Fnr5iZK8U332kGRdKaiIXB5UfDMWZ8Bao+0YWkzQmMKc0wGNNBZs78kt6vHeNneMdQi6rdFbhrhptZIzN8EqgKbgKjjifb4FEn21d3FtsGD7SXQfUHth3B27aNiIioo3GwhoiIiKiL6Xu/6Bknt6FKD2jYy43SCl9SNPtpW+2bNh2leXOTlWpUbfZm9OhkZ+nkqfBsnMH48kVN2HfAFomIiDoYB2uIiIiIulrlBjs4Y2aYrL09ZqaMr/J53DV+pR30eEnFl9qGfDURpbevxpPBPWnkHjX+ZVDtcc+a1jv4llzu5M+cOYUX1vqXPtXhzcMFuNS/xErftyfboBoREVHrcLCGiIiIqEvVYv2+hJ1RY2fKYCUWTrbN+jKnyE2BJ38Lj+2eZ+OXoOq66dhxqxn8MDcSnofyzUtxjW73BxRi+srmkhIg3Q2Gb10NPG32I9tAy+Syl/DVja6fecBzdyI4RKtt96xxgy6HMHTbWWz46IRe1l/hfeAo5up7z5zG4jMNuEKWU76K2585MwBfny2XPpn71ch6mDQMX7StQi5dw+235fXsICIi6r56NSt2mYiIiKjHa2g8a5eSmpqa8OnROoweeZGtIcpMBsUqrtviDaoREREZ1QcO48ILBqOgIPVbCIsK+9ilzDizhoiIiOh85n8Nd5BSv6mJfHLD5Dko5UANERF1EM6sISIiovMKZ9YQERFRR+LMGiIiIiIiIiKiHoaDNUREREREREREeYSDNUREREREREREeYSDNUREREREREREeYSDNURERETdXeUyLFhXawuZ1GL9/HTf9LQdyydMxfK8+hqoOpSvPoSha4/ioK0J6kKpBi8csM2xTuGFteF1ynfaJiIiojzEwRoiIiIiUiZi4a4tWJg3X0ctgzKnse2yIjxgawL9ivDhnItxTKf+qr0Al460bekM8te5GGVX2noiIqI8xMEaIiIiojxQWT4VJRNMSs6S2Y7l8zegct3dpk0t19iWGlc34W6s32crMzD934i7Nq/GbLudkvLtqkVm29iy9BVMYZFtL1PJxJntJdvj99cwselm8OTm7VdloGYQVl0b/drTwSibfQFG2BJ2Nqq4fviiLcZrwr4TdpGIiKgb4GANERERUReTwY2K67Ygscuk7+1dkhw02bwUT2KRrl87finWyAjIwQ14YFEJ1ur4RcDG1SY2g8llEvsSHps2x66nUtlE1TIcs1a4NhMb2JzAmIdUPZ7BGrUP7ywBqj7Jsr+BBKpS6nL3xa9cjFXXDrCldE7hhd804abLssUpg85hlbsMKnRZFRERUf7hYA0RERFRF6vaW4HyW5MzVWY/XaEHRbRp92PxzcP14pixpdixrxb4JIGNt8+AuWJpOGbNn6OX2t206SiVKSy7S1Bq90Fk3F+l+OZHkdj1KGYF0186yIEGbBjUD1/PdgnUgSZsOwx82V4C9eGoRpS9dco2EhER5R8O1hARERF1qVpU7S7FY5uSM1Uk5c+9Y6LyZ3/f/lUDJl0y2JYyGHkBVs0ZFlwqNeKyQqCuyZaIiIjyDwdriIiIiLrUcJTOBO5aJfePEXIPGf/eMTEuKcHMpzcF94Sp2ZewS50h+/62xz1rsjpwFI+fKMLclBsFm2+LmuvPnNl5JHTp08GPGoHB0XvhEBER5Q8O1hARERF1MblsaC3m2cuKbsTLMxdlvoRoxE1YvCQR3Cj4gY22PqvhGDM+3Q2G5ebDFbhrhixnHmjJbX/bds8aGYyZq+8xcxqLzzTgisi9ZmRWDUYVJW80HLHBnzlz5TB96ZPuQ6Ur9heiPOv9cIiIiLpOr2bFLhMRERH1eA2NZ+1SUlNTEz49WofRIy+yNUREREStU33gMC68YDAKClJncRYV9rFLmXFmDREREVGP4X8NdzJFv1qbiIiI8htn1hAREdF5hTNriIiIqCNxZg0RERERERERUQ/DwRoiIiIiIiIiojzCwRoiIiIiIiIiojzCwRoiIiKi9la5jDf3JSIiolbjYA0RERFRe5t8JxK7tiCx6X5cZauIiIiIcsXBGiIiIqIOUlORwJjS4bZERERElBsO1hARERF1hIMb8MDeGZg1wpaJiIiIcsTBGiIiIqKOMOImPHHdJnvvmmWotNVERERE2XCwhoiIiKgjHNyABa/PMPeu2XUnJttqIiIiomw4WENERETUEUZchqt2f4QaW8xNLdbPn4qS8u22TEREROcjDtYQERERdYiJWDg/gTUtuv6pGlWbS/HY3Im2TEREROcjDtYQERERdZRLSoB9tbaQg4MfYce06SjlTYmJiIjOaxysISIiImpvlcvMjYVnLMUOW5WTTxLAzC+h2BaJiIjo/NSrWbHLRERERD1eQ+NZu5TU1NSET4/WYfTIi2wNERERUetUHziMCy8YjIKCAluTVFTYxy5lxpk1RERERERERER5hIM1RERERERERER5hIM1RERERERERER5hIM1RERERERERER5hIM1RERERO2uFuvnTzXfCKXSgnUt+PruFqpZd3ewneWVtpKIiIi6NQ7WEBEREbWzyvIbUTV/CxK7JK3EVYueR8eNo5TgsU1mWwsn2yoiIiLq1jhYQ0RERNTOJpdFBk6mlWCMXRSV5VNRMn8Damy5LYpLS1BV0XEzd4iIiKjzcbCGiIiIqCNULrOXJ21C6YqbUGyrA5sTqLKLbTLiJpTuXYL1B22ZiIiIur1ezYpdJiIiIurxGhrP2qWkpqYmfHq0DqNHXmRr2tN2LJcBm113on2vUpJ+56FcLZU9x0ugiIiI8kX1gcO48ILBKCgosDVJRYV97FJmnFlDRERE9P9v7/5jo7juvY9/8jimacAXguMYnFrZlBD1kqAorshDXBFhlNs4QgJB01ai0Cop1PzBBQlZahOL/gGC3KorJFz/EUKaqCVBSpMYYQnFTaKAimosUNy4gJsb8JO1thjMYkLqQAjG9TNn5uzu7Nr7w7/wYr9f0ihzzsycOTOzJt6vv+fMmCpR6aKQwqOe+TJfG9w5cZpV/uFmMmsAAJhACNYAAACMKpPx4g+edCp8JKDSYlt0jOacNebNU2EtVrmvfQAAcGsjWAMAADCqTMbLswpXeK/TDsxbJ70+yBCoUZqzJrJ/u8JLBpkTBwAA3LKYswYAAEwqN3/OmrEV2V+rpvKNWk5mDQAAOYE5awAAACa9kDbZLJ66FlsFAABuaWTWAACASWWiZdYAAIDcQmYNAAAAAADABEOwBgAAAAAAIIcQrAEAAAAAAMghBGsAAAAAAAByCMEaAACAnHVCdVUNitjSyAy/rZbgQgWCJ2wpWbcOVNVq7F5EdVVv1V/Q9PrL6rI1AABMdARrAAAAkFZZdbNC1fNt6ebqOnpFDbOnaIstAwAwGRCsAQAAyAGR/ZsVmLfQXeqS0lTC0W2xzJikLJmWWq3f3+1bP6EDVV5bsfokbrZMhkwbf58S23HOb+sDwb/aujjvuNHItunR3p47tPfxga8+BQBgIiNYAwAAMN5aarWg/VmF2pqd5aBKd2/WgeiYnyM79LJq3G31c3fozSwiII01r0lbTVt79HDNGwOCJiZQ07TE2b57mYps3WCKVux0z3t8e7mt8bQE1+nk9oNef5eEtOmI3ZAgpPAIxy0de69XT3y/wJYAAJg8CNYAAACMs0hHSNVLosOMCrV8904tL7bFRS9o24pCd7V0TrlOdgyeKeNXub3GHl+i0kWJQZOm4EKt1B5tKLMVQ9at8OlyPV3u9UllP9GuRd5qlBfk8V3DcJy6pL/cO1OP2SIAAJMJwRoAAIDJ4sgOhZc0q17rBgy1yi1X9db/3tC21guavs8sX2nbtet6cN8lHbN7AAAwkRGsAQAAGGdF9wUU/DD6tiXzdiXfMKhBlahUh9Vk9zGZOVlZ9IJ+XGYmDN4jrc50jlQKVTq3Se82RTN8OhVOGgY18jlr7tQPV96jL1ZFl29qyx1T9Okqf6aNuU9mzpxUb6kCAODWRbAGAABgvJVt1PE5r9nJfJcqXJVpCFGhllcFtKnCm+R3S6Otztp8bXjdHJ8+YBOdYHhBTZMaa5a66yYjxwR7HrblwLzXdDJpGJRn5HPWpGeCROXatWZ83lIFAMBYuq3fYdcBAAAmvOu9N+xaXF9fnz6/3KOSWXfbGuS8rgat/7W0LcMkyQAA3Gyd5y/qrhkFyssb+DbDKfm327X0yKwBAACYzFpqbYaMfxmN126PsbMhqfJ7BGoAABMSmTUAAGBSIbMGAACMJTJrAAAAAAAAJhiCNQAAAAAAADmEYA0AAAAAAEAOIVgDAACQs06orqpBEVsamaG21a0DVdEJh9O/4nvEzJudgidsIWo0rz2NU5c0fd8Fb6m/rMyXeVVv1dv97RI8ZTcBADBKCNYAAABgEIVavrtZobaD2rXIVo0WE5yZt1Dr93fbivHSo2Cr9P6qe/SFs7w/7bqqj16129KYNkWf2mPMUv2QrQcAYJQQrAEAAMgBkf2bY6/Orkt6b3Y4ui2WaZKUddJSGw98uOsnYlkxqQIiLUF/e0PnHm/7Gz+HycapVUvsdeD+V4A7fbb7Byp26OHXm/XSik6vzik3vrou1p7/+gdeu8e7XyN8xfgp6YlVM/WYLT527+1q6OmzpVT61PGlXQUAYIwQrAEAABhvLbVa0P6sQm1eJkvpbt+woyM79LJq3G31c3fozSyiE401r0lbTVt79HDNGwMCGibQ0rTE2b57mYps3VCYQIl7vNvfZv2ifbtvmNQ+rfywwq0/vj2kl20gJ7L/NZ3cftA75tALOrnbBF/ma4MtVz63J9behjL3kCyuPaTwSIZnPVQQC9QYx87e0JZ7C2wpjWn/1t4hDZ0CAGBoCNYAAACMs0hHSNVL5tuSGX60U8uLbXHRC9q2otBdLZ1TrpMdmYcOVW6vsceXqHRRYkCjKbhQK7UnHhAZhnB7k4KrbZaMs6x8tUnhs3ajVqm+2ruWovsCamzvdNfNMUOW5tqLVuxUqM13n0bo2HsX9F/6ZuYhTef71HrRZOR4Q6A+nd2b3dApAACGgGANAADAZHFkh8JLmlWvdQOGWmWvW+HT5dp1KJ5Zk5ANk0JZtcnAWeoFeCoO6+mtw8vqGQvRQM0X388iq2bWDO31DZ0qvj9fyjh0CgCAoSFYAwAAMM5MBkrww+jbkMy8L5nevlSiUh1Wk93HZOZkZdEL+nGZCZzskVYP9w1PhSqvlDbtHUp/k4dOjTwjZlTmrHGYQM1f7r1n8EDN+ctak/y2J/P2KN/Qp67PeqWCPFty2MmThx8MAwCAYA0AAMD4K9uo43Nes8OKlipclSmYUajlVQFtqvCGIW1ptNVZm68Nr5vj0wVZoq/uXqpNR5rsubzgiBmCZLJzov19tzI67Cq1ohXPSr6hUwmvAy++Xw+nmGA4vRHOWXP+sn53UdrW6n8V9yUds5ujWv/lG+b00Ex36NODdv8Hz+Ur+PiddqPjbEiNNigGAMBw3dbvsOsAAAAT3vXeG3Ytrq+vT59f7lHJrLttDUaXCfy8odLdGxWLYZi3VnX8RC/ZOWkmCpPxs0U1E+66AADZ6zx/UXfNKFBeni/z0pqSf7tdS4/MGgAAgMks9ppt/zLy4UXJSueGtNJ/jtXSLyZgQCPcLj1dTqAGADAyZNYAAIBJhcwaAAAwlsisAQAAAAAAmGAI1gAAAAAAAOQQgjUAAAAAAAA5hGANAAAAAABADiFYAwAAkAu6GrQ+eMIWRmg020ol8oF+3tomhfbq559EbGUazn5zzP5DEtGfju/V32wpUbpt2RqNNkYu8sk2zTn+gdMbv9Ht299af6Y5TeN/rXBk+zOTwHwezDP0lhdDttphPj+m/LfWbfrTUJsFkLMI1gAAAADjqOg7W9S+4EkV2fLoi+j09Se1dmpIpyfKl3kTLGz62TCCHremv7VW688FQbWX/0Htc9foTCeBN2CiI1gDAAAwrk6obt5CBSp2qPHVdQqYdWepa7GbW2pjdYGqBi/7wq3brANd7h6K7N9st2Voy9ES9LWTI7ysD2+Jfvn26qr1fO8HesZuy5yZk5h9kHUmj8n6cY/xfwFOn8kQrY8FC2zwwNs3emyGTIfYeZ3F19fhXXsakVb9ecp39fz0gP7cnU1/U1/7oAZkTbXpxdi99LcVvx/RbBCP2Seb4INp17Z1eq8eKPmDfv+dopRtmfqEYI655mgGk//eZ3pO1mDPPZbNYtqzbcf74+tvyqwmb59YP/39imVbRfQte62uohI9kD9b3/JKACaqfgAAgEnk6+u9A5arX13rP3suYvcYJ+cP9Ff99u+2YCXXfbSrv6r+ordutv3iQP+F6H+9Ws9gbVkf/fb/9t/3n7v6P7Llm+azP/Z/++NTthB34R9b+3d8ZguOlo+39r8Zu5gL/W8e+2N/iy1l5JzjuX/E78SFf/zR19ZgTPs/jfXL9CV6fMp+XHi//7nYdZzq3/HXxP651/Px+xnOm2TQezPEa08jdl2m78feT/isDNbfoT8Ds0/8mMT7+FPf843fL/e8sfrsrtXfrv9aUreV+HzifUk+n7PfIJ/NBCmee/Tc5rO242Pv89bi/Nds89/HhL7HPqdJn5+EcziSPs/ODk6/nc/rX/3PB0AuMr9TmN8tBvudI1tk1gAAAOSqs6GEDJnA6n1qbO/0thUv07bKw1pQcVhPb12W9RCasupmhdo2qsyWx9s/vz6jVzqj2Qc/0zNXzqj9it04RJFrIR2+VO2042U7FH1njX6U8cY8qbcfmeeuFd0R0OGv3dwInb5+Rs+fjvbLZLnYIURFT+r3dn+noDn5A4cWvaKSLM57s0R0qEd6qtDpUNEjekpHdShtf9Nce0pFzvHRrB1zvoA2uFkg3vCryoC7k2OeKkcwFMt8VoZmntbOdH6GbJZL4/U1Wuv2JaL2aNaSmxE0T8/HnmkKKZ67+cycuRZx+iZVTpfz2TXX7O316CNbYvc1/tmKatWLTb+RStboUVujK+d0+Mpv7H13ls4Pko5x+q01ai6Ptwtg4iJYAwAAkKMiHSFVbj+oUJsJsNiler7dOhGYL7YP6MW5f/Dm4rDL87Ev90Pjzv3itvEDtbvBhuyGtwxkvsw/qbd9fWqPfUH2D20xgQz3gARrp2f44n9TmWuJBl9MfwcGwxL7m+7a0wh8Vw/0tCpih1x5AQjTlrsyKh595A/a8LUJxjnXcvqongpknuenqPBxnfmiTQp9pDMFj9j95+l5e23N33jHay/jMLMUz33qbOnrVp3WbH3LrF9rVbtZdzb5h02ZwIvf4UvnVFn+S8k394wJNi6eaeeliS4JQSSn32M6txGAXEKwBgAAIEcVlS+Wat5QdMoZMzfN+v3dXqGlVgvan1Xo0GK9++vs56DJrTlrilRRID3fGf2ibOYbGW6AxRH6wB7rfRl/e+pws3RMBsgHqovNd2K+qEfnQXlHZ2JfqIN6Md/b46ay881knEvGCH2kV6b+Mv7lv+RJvWKCFymlvvb05mltwVEtNEGUkmiAwWvLy2wx2tR4JaC5RV6mSbwf2QV1TPCjcbq9Dl8AKW1bRU9qg36jOZ2y2T6G8zn7xNvfDfDNXaPF1zvT/kykfO5m/hidU7tKVOSs6+tz0hRn3bnWVy4FYkGvZue+Oz/NMYtnVupR8zl1DnnGzk1jAku61BgP3iTPuePOZzPEn4+k+a0A3DoI1gAAAOSC4vv1cPKkwMXL9NLr0kpbt6BxsbatKPS+gK2W6k2WTXQ41LzaWFBn0Lb8joQUtqs3lX+IR2yo0ha9bb5Mu3XmjTfrfVkcRZo7JdtJdp0v4NecL82x4Ts/0zP65bCzdB59JKinemwWh2+4StF3fqAH3KFWpr5Rc4sCej7kfNm2AZSFl3zDujJla0QnkzVZF/bexL+cZ752M/wmPeeeOP1KyJwJfFdrr7yjP/2/1P1Nde2ZmGDD4vzHVeFL/TBtzYnY9pve0Zy5tq1ApV68Hn3u7+hMFkEvc+/lGzIXC1xkaOvR6U9KU6PZPo5Qq9q/thk1ZskiSyflc3eOmnP9A535hjnav+4NwYo+v19d+66ecvo4IMAWWKO3p+zVQhOwMUOtTPDGHrOw53H9TyzAFDW0AKTJztNzz2p5sa0AcMu4zUxcY9cBAAAmvOu9N+xaXF9fnz6/3KOSWXfbGgBDZTJBfqX18bcWjSqTddWouQt8gaPQXv38WmXG85m3a5mMnOEG7m5lJpOuaUmzNuTKJFXAJNF5/qLumlGgvLw8WxM3Jf92u5YemTUAAAAARsCbz2XhpejEwmNj7pR4poq7JAxtGoTNdnomNrHwZNOt8OlVKidQA9ySyKwBAACTCpk1AABgLJFZAwAAAAAAMMEQrAEAAAAAAMghBGsAAAAAAAByCMEaAAAAAACAHEKwBgAAIKd160BVrVpsaWSG0VZLrdbv77aFRJH9mxWoalDElnPCqUuavu+C1hy9ais8x9674NZ7yyUds/UAAOQigjUAAAAYlqIVOxXavUxj97LmITKBmtY+vXJ/0ps2nPr/0jf1xap73OXT+/v0X+/12I0AAOQegjUAAADjzmS8LFRgnl2CJ9zalqApL9WmI/u0MmmbyXhJ3t/wjnEWk/ES3cfZnratwXQ1aL3ZZ/U+NdYs9faft1kHupxtKc7tZuEEncWpr2ux1xTLvEm8xrqE9J4TqnPqUmXwZKdHQROoWVKkH/6HrYoq/D9aZlejlhUMfJ0qAAC54rZ+h10HAACY8K733rBrcX19ffr8co9KZt1ta24yE+To+IleWlHoFiP7a9VUvlHLi03JBDneUOnujSpztxonVFf1mX7sZrWY7dulrTvt/obZfkiqrNCGFfNtnTFYWxkk9S2BCdp8WKFQtT2HKe8O6PhW6c1fh1S69SfSr73zKbhZ4TXRPib3wwRr1in43J54WyNx6pLW/OsO7X38TlvhcLNuvGe/7P5pidsAABhFnecv6q4ZBcrLG/iHgSn5SdmfKZBZAwAAMM4iHSGbveJlrhStiAZqUpmvDbHhR4Uqnduk8Fm3EHckpNLyUQh8DFFl5ffcfp2cW+G7hm6FTzdpU0U0s8Zk+IQUNlk6Lud62ppHJ1AzGBOoOZsfGwYV1BVNZxgUACCHEawBAAAYZ+7cLyZY0faswm5Aww43SilxSNHKV22136LFKk8b8LmZOhU+skr17jVGF38m0Njq+lefttxbYEtS8f35WvZln9LeYgAAxhHBGgAAgPHW0mCDM16GSf1zg2TK+LW8oU1z99igx0Fn/3K7IVfNV/lz+/RybE4aM+zJ/1aq0ZizJrXi/8jTtrPxTJquz3rVMC1PsViRnZ8ncR4dAADGD8EaAACAcdWtAx0hm1FjM2W0Rxtik8qYYU5JkwKX/US7Tq+z+29XeMlinVztBT+8iYTXKXhkhxa42/1ZOoO0lcm9ASnVBMOr90mvev3IFGgpqz6opxuj7ayTXh84b05je6ddG56uoxHv1dytN9Tw2ZfxV3g/NFPv66vYq7sf/CxP738/nmmjsyE1LnpBP856Ih8AAMYWEwwDAIBJJScnGMa4iuzfrC2qGXwSZQAAhogJhgEAADAy0SyZhMU/RGniC7dLT5cTqAEA5A4yawAAwKRCZg0AABhLZNYAAAAAAABMMARrAAAAAAAAcgjBGgAAAAAAgBxCsAYAAAAAACCHEKwBAAC41bXUav3+bltIp1sHqlK96emE6uYtVF0OvQaq62hE0/dd8Jb3emytcVVv1dv6fRG9dd5Wp+Tf31uCp+wmAAByEMEaAAAAOOZrQ1uzNpTZ4ng7f1nV5/L16ap79MWqaXrly69iAZZj732phtnTnHpn25J8NXx4Sce8TalNm2Lb8pbqh2w9AAA5iGANAABADmgJLlRgnrfEs2ROqK6qQS37N3vbnPWI3RKJ1s3brAMdtjINr/2l2nRkn1ba8wSCJ5wtJtvGlk1bXd7+3rlrncXbzztffPvg/fV4+6bK4MlOV3eegitnqNgt3aknZt+m1n9dddZ79JeLt+u/H7/T3aJZM/Tfd/epI212jbP9S7sKAMAtgGANAADAODPBjaYlzQq1ecsv2rfHgyZHduhl1bj19XN36E0TAelq0JaagOrd/Wukxn3evmmUVZt9D2rXolX2OGepnu9sKdTy3dFt3r4xR0Iq3erU6zW96fTh+HYpfDZDf2NCCg+oy17xQwU2UGNc1V/OScvutwGaAfrVkWkU2LR/a290GFT9ZY2gawAAjDmCNQAAAOMs3N6k4Op4psrKV5vcoIhr0QvatqLQXS2dU66TJipxNqTG5yrkjVgq1PKqVe7aqFu0WOUmYnI6oHLbByNtfx1FK3Yq1LZTy+PRlhEw882YYU9T9cNZtsrVo2C2c8+c71PrRekJOwTq09m9qj5qsnQAAMhNBGsAAADGVbfCp8u161A8U8UsOTN3zAA3s7/RQM007Y0Oe4opUHVs7pnbdF88ljTQrBnau2qmHrPF4vvzpZ4+WwIAIPcQrAEAABhXhSqvlDbtNfPHGGYOGf/cMYO4N6DKVw/F5oSJdITs2s2Qub+jMWeNF6i5IpXfkxSoKdATd9/Q76KZMecv63cX83RfLOvGy7hZ48+cOXUpYehT12e9TjN5tgQAQO4hWAMAADDOzLCheq2zw4qW6t3KmvRDiIqXadv2UGyi4C2Ntj6jQpXOTTXBsJl8uEmbKsx6+kBLdv0d2Zw1OnVNa6/1a+2Hvldu24DLY9+fpmXnvvTqPuzVsiXxrJmoBn/mzEMz3aFPD9p2HjyXr+CATB0AAHLHbf0Ouw4AADDhXe+9Ydfi+vr69PnlHpXMutvWAAAADE/n+Yu6a0aB8vIGZnFOyb/drqVHZg0AAMCE4X8Nd3xJfrU2AADIbWTWAACASYXMGgAAMJbIrAEAAAAAAJhgCNYAAAAAAADkEII1AAAAAAAAOYRgDQAAwGhrqWVyXwAAMGwEawAAAEZb2UaF2poVOvSCHrZVAAAA2SJYAwAAMEYiTSGVlhfaEgAAQHYI1gAAAIyFrgZtaa/Q8mJbBgAAyBLBGgAAgLFQvEwvLTlk566pVYutBgAAyIRgDQAAwFjoatD6Dyu8uWvaNqrMVgMAAGRCsAYAAGAsFN+vh09/pogtZqdbB6oWKhA8YcsAAGAyIlgDAAAwJuZrQ1VIbw5p/FOnwkfKtWvNfFsGAACTEcEaAACAsXJvQOrotoUsdH2mk4sWq5xJiQEAmNQI1gAAAIy2llpvYuGKHTppq7JyNiRVfk9FtggAACan2/oddh0AAGDCu957w67F9fX16fPLPSqZdbetAQAAGJ7O8xd114wC5eXl2Zq4Kfm327X0yKwBAAAAAADIIQRrAAAAAAAAcgjBGgAAAAAAgBxCsAYAAAAAACCHEKwBAAAYK10NWj9vodbvH8Lru4cosn+z9+YpZ6lrsZUAAOCWRrAGAABgTHTrwK8P6+ntq2x5rAS061CzQm3N2lBmqwAAwC2NYA0AAMBYaHlD4aqdWn6fLfu0BBcqUNWgiC2PRFF5QOGmscvcAQAANx/BGgAAgFF3QnUfVqTPdDkSUtiujkjxMpW3b9eBLlsGAAC3PII1AAAAo6wleEjl1fNtaaCyajNsaaNGNmrphOrsXDVNS3ZqebGtBgAAt7zb+h12HQAAYMK73nvDrsX19fXp88s9Kpl1t60ZATOpcMUONdpizHN7FEoTwBmJluBmhdcQsAEAIBd0nr+ou2YUKC8vz9bETcm/3a6lR2YNAADAaCpeppfavAl/3eX1VarcfjAhUDOac9aYiYzDWqxyAjUAAEwYBGsAAADGwyjNWRPZv13hJctUZMsAAODWxzAoAAAwqYz5MKibLLK/Vk3lGxkCBQBAjmAYFAAAwKQX0qYKb6LhuhZbBQAAbmlk1gAAgEllomXWAACA3EJmDQAAAAAAwARDsAYAAAAAACCHEKwBAAAAAADIIQRrAAAAAAAAcgjBGgAAgJx1QnVVDYrY0sgMv62W4EIFgidsKVm3DlTVavRfRHVVb9Vf0PR98SV4ym4CAGCCI1gDAACAtMqqmxWqnm9LN9G0Kfp01T36wi7VD9l6AAAmOII1AAAAOSCyf7MC8xa6S11Smko4ui2WGZOUJdNSq/X7u33rJ3SgymsrVp/EzZbJkGnj71NiO875bX0g+FdbF+cdN9Jsmz51fGlXAQCYZAjWAAAAjLeWWi1of1ahtmZnOajS3Zt1oMtuO7JDL6vG3VY/d4fezCIC0ljzmrTVtLVHD9e8MSBoYgI1TUuc7buXqcjWDaZoxU73vMe3l9saT0twnU5uP+j1d0lIm47YDQlCCkevYbim/Vt7o8Og6i9rpM0BAHCrIFgDAAAwziIdIVUviQ4zKtTy3Tu1vNgWF72gbSsK3dXSOeU62TF4poxf5fYae3yJShclBk2aggu1Unu0ocxWDFm3wqfL9XS51yeV/US7FnmrUV6Qx3cNw3G+T60XpSfsEKhPZ/eq+uhVuxEAgImNYA0AAMBkcWSHwkuaVa91A4Za5ZxZM7R31Uw9ZovF9+dLPX22BADAxEawBgAAYJwV3RdQ8MPo25bM25V8w6AGVaJSHVaT3cdk5mRl0Qv6cZmZMHiPtDrTOVIpVOncJr3bFM3w6VQ4aRjUqMxZc+pSwtCnrs96pYI8WzLMfTJz5qR6SxUAALcugjUAAADjrWyjjs95zU7mu1ThqkxDiAq1vCqgTRXeJL9bGm111uZrw+vm+PQBm+gEwwtqmtRYs9RdNxk5JtjzsC0H5r2mk0nDoDwjnLPmoZnu0KcH7Zw1D57LV/DxO+1GwwSJyrVrzTi8pQoAgDF2W7/DrgMAAEx413tv2LW4vr4+fX65RyWz7rY1yHldDVr/a2lbhkmSAQC42TrPX9RdMwqUl+fPCPVMyb/drqVHZg0AAMBk1lJrM2T8y0hfu30TnA1Jld8jUAMAmJDIrAEAAJMKmTUAAGAskVkDAAAAAAAwwRCsAQAAAAAAyCEEawAAAAAAAHIIwRoAAICcdUJ1VQ2K2NLIDLWtbh2oik44nP4V3yNm3uwUPGELUaN57akde897NXh0WXP0qt2SylW9VZ94TPCU3QQAwCghWAMAAIBBFGr57maF2g5q1yJbNVpMcGbeQq3f320rxtPten/VPfrCLnsfv9PWpzFtij71HVP9kK0HAGCUEKwBAADIAZH9m2Ovzq5Lem92OLotlmmSlHXSUhsPfLjrJ2JZMakCIi1Bf3tD5x5v+xs/h8nGqVVL7HXg/leAO322+wcqdujh15v10opOr84pN766Ltae//oHXrvHu18jfcX4VXV8aVez1jeMYwAAGBqCNQAAAOOtpVYL2p9VqM3LZCnd7Rt2dGSHXlaNu61+7g69mUV0orHmNWmraWuPHq55Y0BAwwRampY423cvU5GtGwoTKHGPd/vbrF+0b/cNk9qnlR9WuPXHt4f0sg3kRPa/ppPbD3rHHHpBJ3eb4Mt8bbDlyuf2xNrbUOYeksW1hxQe6fCsadJfYsOaLumYrU5r2r+1NzoMqv6yxnKEGABgciJYAwAAMM4iHSFVL5lvS2b40U4tL7bFRS9o24pCd7V0TrlOdmQeOlS5vcYeX6LSRYkBjabgQq3UnnhAZBjC7U0KrrZZMs6y8tUmhc/ajVql+mrvWoruC6ixvdNdN8cMWZprL1qxU6E2330alj51XOzTfeV2SNMj0n+912O3pXC+T60XpSfsEKhPZ/eqOuM8NwAADA3BGgAAgMniyA6FlzSrXusGDLXKXrfCp8u161A8syYhGyaFsmqTgbPUC/BUHNbTW4eX1TO6ClS9qkg/nGWLD+Vry5d96TNlZs3Q3lUz9ZgtFt+fL/X02RIAAKODYA0AAMA4MxkowQ+jb0My875kevtSiUp1WE12H5OZk5VFL+jHZSZwskdaPdw3PBWqvFLatHco/U0eOjXSjBivvRHPWXP+stb4hz6d6tW2aXmKdc3dnvS2p1OXEoY+dX3WKxXk2ZLDTp48/GAYAAAEawAAAMZf2UYdn/OaHVa0VOGqTMGMQi2vCmhThTcMaUujrc7afG143RyfLsgSfXX3Um060mTP5QVHzBAkk50T7e+7ldFhV6kVrXhW8g2dSngdePH9ejjFBMPpjXDOGpMlY4Y+ReefaZXe/36B3RjX+i/fMKeHZrpDnx60xzx4Ll9B/xukzobUaINiAAAM1239DrsOAAAw4V3vvWHX4vr6+vT55R6VzLrb1mB0mcDPGyrdvVGxGIZ5a1XHT/SSnZNmojAZP1tUM+GuCwCQvc7zF3XXjALl5fkyL60p+bfbtfTIrAEAAJjMYq/Z9i8jfSX2QKVzQ1rpP8dq6RcTMKARbpeeLidQAwAYGTJrAADApEJmDQAAGEtk1gAAAAAAAEwwBGsAAAAAAAByCMEaAAAAAACAHEKwBgAAAAAAIIcQrAEAAMgFXQ1aHzxhCyM0mm2lEvlAP29tk0J79fNPIrYyA3NM088S9v9b6880x6kzy4shW5kl91jTh4za9OLxD5Sql39r3aY/ZXkJg4voT8cTr2vwupEz1zzU++T1Za/+Zkt+I7/29IbX38GNZlsTxlB+/pDehLmXqX/eBxP5ZNv4/lwN5/8lkwTBGgAAANwcV85JU5+Uvo7/Qv7oI39Qe/kf9PZUWzEE7rGPzLOlZG160QSBsgrmjFSRfrTgl3rgUmP8C1KoUc9P+aV+/50iWwEAUTfz3yfcqgjWAAAAjKsTqpu3UIGKHWp8dZ0CZt1Z6lrs5pbaWF2gqsHLDnHrNutAl7uHIvs3220Z2nK0BH3t3GR/+yKkp0oq9dT1jzL/1Te012bcmMwP+8WmyftrsflLcDQbZ7BsFm/bb3RmZjAhmPPP6HE2yybazjNXzuj50/a4NBk46c3T2pkh1bn9cfrh/Oft2Ln9/YpnsiT+RXsIfw2/5mUomfb81+/PUorWe3XVer73Az1jt5kviOmv3d9fXzZLmmeS1hD6m9FQ27LZXO42/xfj2LUk1idmGiVmZPk/dwnX7T9HpvsRzSKw99i7t77z+PuV9Wcx/rz81z7oz4lp39+u6U+m555OivuYWuI5YsfE7ovH/7PhZlR9Er/HGZ97us+pv7/Rn8Xo8+v8QIcvVSduM5sHu4++Z/5iKHpN/s/OYPzX7vv3Kc21Jx7jfyaD38dUP++ZRe9T0nMf7POY9tpT9RfD0g8AADCJfH29d8By9atr/WfPRewe4+T8gf6q3/7dFqzkuo929VfVX/TWzbZfHOi/EP2vV+sZrC3ro9/+3/77/nNX/0e2fPOc6t/x1z/2tzhrLR//tH/HZ15t1GB1RsvHW/t3fPy+e1yyC//Y2v/cP3xX/tkf+7/98SlbiJ/PW/9pbN/kc5lzvJlwA4frQv+bx5xzOv3w9yvxfPF+mf7H6+2xtpSKaevbx963zztVW8nXlLrtwa4907Hpnkmy4fV3cENvK76PEf+8OPWxdsz1xc+d2A//fv51x4X3+3cMaMvh1D8X+wwOJrq/89+P/+gszr7RtpKPTfocDcp85v86yPUmtOWrT7pe/73L9NwH8l97YrspJV3ThX/80Tsm6doT+zW8z5ApJ35Ok6/JPIMM9zvlffS4fXDOkfG6DfOsBmsr7bWneCap7qMrm2cXZ873bX9fovc6qV8Dzznw2of+GZq4zO8U5neLwX7nyBaZNQAAALnqbCghQyawep8a2zu9bcXLtK3ysBZUHNbTW5cp28E2ZdXNCrVtVJkt3zShj/TK1O/qUWf10elP6pUvsvlrr3FGZ77xiHtcJpFraf6Mm79G/2OHJH3rGw/ozLW0fwIfpiL9yDnFM84j2hAb/hTR6etPqjJgi5qnyqkhnR7B6dcWPWmft2nrAzU6l/3Pr8/olc74X7RNxkz7FXenITL99WXbuH+lT+5v9s/EGM3+DqmtSKfO2M+cUfSdLXZY2jw9vyDaTpHmTsni3Kat3r1a6LTvZlc4/XjetOWrd89/eq8OX+/0MhAGVaQ5Oqd/OsfpG9911p19r5xz7qjD+e/hK7+JXYeb6eEbMpjK4pnr3c+d23a+fVZO/34fy+zy1TvrFQWy1xvRoZ6A/Wxm89yTDf0+mp9RL3vFy8Qo+s4a2/f0hvcZSv6cRtQezThxs02c/qccRmmlvI9xr6gkq2tI++/ToFI/k+Hex1TWlqzx7lNRiR7odT6fZj2Lz2PitQ/nM4R0CNYAAADkqEhHSJXbDyrUZgIsdqmeb7feWtwvKtFf/J1f+pX2C63fA3qqMLtvIebLePM33rFfFH4jRb+A3ExTZ2tx/mx9yxbNF5j2Xrs6ZsyXpAf04lxv/p/o8nwsQDQUpr9P6m1fO+3lW5K+CGb/TAY3uv0deluJQzWeyRSoMcyXdtv2hq+9oTJu0MZ8oZ36y4Rzt8cCGIMxQQ3nC2z3OemOeZqrczrk/Gw8cEeR+zOy2AyN8beVKZiQUnxYi/el2VY7igof1xk3WOo86ynRYFY2zz3Z0O+j+Rn12v6B2t0v9ZmGDqWSzXNP/pzO0/N2v9i/ExmHCKW+j1Frp2f3jIb+71PqZzJ69zG1bD6Pidc+nM8Q0iFYAwAAkKOKyhdLNW8oOuWMmZtm/f5ur9BSqwXtzyp0aLHe/XX2c9CMz5w15i/48n2xCupFHdWh0e5EaK9+pfWxLwrD+/LvY+dmGNm8C/FMAE+bGq8ENNd84boj4MswMl907GoG8awg05bJ2vGyJZ7vjLf1p+PD/fLm9debe8cwX1aznEsnhdHs75DaMlkCV+LzI5m5QNwAi538OfpZfHvqA3YPk3Ul/bnbnsNkzXhrjjb9yd4Td2Lrkie9LIPAd7X2yjvxvps5PjIEAL71jYDav5bmTPXO1/51wF03QRT5JqmO9XcYIp+8482JEv15y7cbjKJHvHmjQh9JsS/bw3juae5jSqEP7L3yAidvT7XZMEnPymTN+I3OZ8jZ5xNvfzfYMXeNFmcIGqe9j0OV6t+nlNee5pmkuo+jaOifx0yfIS/wNbTPdLcOVDn/zxrrtxvmqNvMWCi7DgAAMOFd771h1+L6+vr0+eUelcy629aMBzM58DoFban69WZtMGOVzGTCq/d5lYte0PHdy1Tk1kn1djiTCeIsqAnEyinbcphgzcpXV/n2vQnMF9jIbDX7Mg7ML/4Lv/6B3tZvkv4ib/5avkU/uuIcYzJwfMxfec0wFvfYS4lf5taWmC8/5gtb4l+/vXrnS8LxTq215zfHmy9N0Tc1JbSXvybeTxOsOb1XsufNijkmJP1PQnaFv1/2+rwTJNQvzg9ow4L0f203E4jWXX9Ah3u9/kbviWG2Re+lv97wb5PJBLF/IR/82hPvo3cPnRXzHFM8k1SG29/BDKst+wwPm/XYdSc9j5LH9efOc9pQbu69+UL5G71iNuU7z0SPu89Sn3ygV77eq1din1WTQWCflf8c/vpU3Psobz//emybvcf+z2Iqzv4/v1Zpr9dc10tSwHy+fNdh+lQiPeP7GfSeeyCprymee0rp7uNgnP0/aVT7Jede2ppUn8XFzr1/oGiLe/4hP/dUn9M7WvXiF0edZ2g/7wk/i46E5xjdluI+Ov36VWxfy3ctg0u8v0b0Hqe69uRjYv/OpbmPhv++ZOqXOfcrd0TPZ673I1Wm+zwm3Cdr0J+t5M+QvZcZ75Of+X/Zayo9tFPLi23VLaLz/EXdNaNAeXl5tiZuSv7tdi09gjUAAGBSyd1gDUbKvMnndEnSl6/OEt+cEwBuNSbw0Dg9U+Ao9/Hv0zB0NWj9r6Vt5o8UtupWMRrBGoZBAQAAYAKIuMNL4pNbOsvpo3qqhC9CAMYb/z4Ny9mQVPm9Wy5QM1rIrAEAAJMKmTUAAGAskVkDAAAAAAAwwRCsAQAAAAAAyCEEawAAAAAAAHIIwRoAAAAAAIAcQrAGAAAgp3XrQFWtWmxpZIbRVkut1u/vtoVEkf2bFahqUMSWx99VvVV/QdP3eUvwlK129Sho6usvq8vWpHXqUqwdd8n2OAAARgHBGgAAAAxL0YqdCu1eljOvVe06ekUNs6fpi1X36IslU9TaeknH3C0mUPOVWu+foi1uOTtbHnHaMW2ZZeUMFdt6AADGGsEaAACAcWcyXhYqMM8uwRNubUvQlJdq05F9Wpm0zWS8JO9veMc4i8l4ie7jbE/b1mC6GrTe7LN6nxprlnr7z9usAya9JMW53SycoLM49XUt9ppimTeJ11iXkN5zQnVOXaoMnuxcVcd/TNXex+/0irOmaNkdfeo4Lx17zwRqpjnbBr5CNZWuf/XZNQAAbj6CNQAAAOOt5Q29W3lQobZmdzk+55AbFCmrNuWD2rVolerttlD1fOeAE6rbHdBxt87Zfvo1L4ji8I7Zo2qF9GZHReyY1G2lULxML5l9Xl+lyu3Rvu3UcpNeUrbRKzvbkjWeDmjboRek3W9IW53zOf0IO/Utwe1O2Z7X6Ufp7oHDsRrbO+3acNypxx6ygRrj/HU1KF9PzJIe+/498SBO1vKks5EUQ6oAABhbBGsAAADGWaQjZLNXvMyVohUbvaBISvO1ITb8qFClc5sUPusW4o6EVFqeJhgzRiorv+f26+TcCt81dCt8ukmbKqKZNSbDJ6RwbBIY53oyBY+G4vxlrfmwV8vKhz90qaPnhloLptphUN+UYkOqAAAYewRrAAAAxpk794ubcfKswm5Aww43SilxSNHKV22136LFKs+ZSVY6FT7iy+hxF5ulM9qigZolRfrhLFs3DInZOAV64m5vSBUAADcDwRoAAIDx1tJggzNehkn9c4Nkyvi1vKFNc/fYoMdBZ/9yuyFXzVf5c/v0cmxOGjNHjX8Y1GjMWeMwgZomKbhqaIGarqNmuJM/c8Z7q1R86FOP/nIxT/f523Tn7ckUVAMAYHgI1gAAAIyrbh3oCNmMGpspoz3aUGY3u8OckiYFLvuJdp1eZ/ffrvCSxTq52gt+eBMJr1PwyA4tcLf7AwqDtJXJvQEp1QTDq/dJr3r9yBRoKas+qKcbo+2sk17fqNglWiObs0Y69vfrarh2XQ/6Xrm95uhVL4jjlr/Stuj2Aa/i9mfO3KkfrjRDn6LtfCU9MlOP2a2GGbqm554dm+wgAMCkd1u/w64DAABMeNd7b9i1uL6+Pn1+uUcls+62NUB6JijWtKTZF1QDAMDTef6i7ppRoLy8gW8hnJJ/u11Lj8waAACAycz/Gu7YMvBNTfAzEyavUjmBGgDAGCGzBgAATCpk1gAAgLFEZg0AAAAAAMAEQ7AGAAAAAAAghxCsAQAAAAAAyCEEawAAAG51LbUZX53t6daBqlSTB59Q3byFqsuhmYW7jkZir+Ce/l6Pre1RMFoXWyJ6K/babQAAbn0EawAAAOCYrw1tOfQq6vOXVX0uX5+uukdfrJqmV778SsFTdtsdU2y9Wb6pLcrTfbPsNgAAJgCCNQAAADmgJRh/dXY8S+aE6qoa1LJ/s7fNWY/YLZFo3bzNOtBhK9Pw2l+qTUf2aaU9TyB4wtlism1s2bTV5e3vnbvWWbz9vPPFtw/eX4+378he/93Vnafgyhkqdkt36onZt6n1X1ed9QJVx+odp3rVev8deswWAQCYCAjWAAAAjDMT3Gha0qxQm7f8on17PGhyZIdeVo1bXz93h940EZCuBm2pCaje3b9Gatzn7ZtGWbXZ96B2LVplj3OW6vnOlkIt3x3d5u0bcySk0q1OvV7Tm04fjm+Xwmcz9DcmpPCAuuwVP1QQD8joqv5yTlp2/522HHVVb/1v3yD1AADc2gjWAAAAjLNwe5OCq+OZKitfbXKDIq5FL2jbikJ3tXROuU52dEtnQ2p8rkLeiKVCLa9a5a6NukWLVW4iJqcDKrd9MNL211G0YqdCbTu1PB5tGYGreqv+SzXMnqofJg91On9dDdPuGFgPAMAtjmANAADAuOpW+HS5dh2KZ6qYJWfmjhngZvY3GqiZpr2PD8yeOfb363rk3gJbAgBg4iBYAwAAMK4KVV4pbdpr5o8xzBwy/rljBnFvQJWvHorNCRPpCNm1myFzf0djzhovUHNFKr9n0ECNmYD4d19O0ZqHbBkAgAmEYA0AAMA4M8OG6rXODitaqncra9IPISpepm3bQ7GJgrc02vqMClU6N9UEw2by4SZtqjDr6QMt2fV3ZHPW6NQ1rb3Wr7Uf+l7RXX9Z0SZNVo1mT/HNawMAwMRxW7/DrgMAAEx413tv2LW4vr4+fX65RyWz7rY1AAAAw9N5/qLumlGgvLw8WxM3Jf92u5YemTUAAAAThv813PEl+dXaAAAgt5FZAwAAJhUyawAAwFgiswYAAAAAAGCCIVgDAAAAAACQM6T/D2uJpWSBu6oBAAAAAElFTkSuQmCC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atYLzaosLVPJ"
      },
      "source": [
        "##OUTPUT IN THE FORM OF TEXT:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IStTRe5mLAW8"
      },
      "source": [
        "for reference, I am also giving the output copied as text:\n",
        "[\n",
        "  {\n",
        "    \"chunk_id\": 1,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" Congratulations to you, Mr. Raghavan, for that. Thank you so much for joining us. Over to you.\",\n",
        "    \"start_time\": 0,\n",
        "    \"end_time\": 4.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 2,\n",
        "    \"chunk_length\": 2,\n",
        "    \"text\": \" Hi, everybody. How are you?\",\n",
        "    \"start_time\": 8.5,\n",
        "    \"end_time\": 10.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 3,\n",
        "    \"chunk_length\": 6,\n",
        "    \"text\": \" Okay, I am not hearing this at all. Is this like a post-lunch energy downer or something?\",\n",
        "    \"start_time\": 11.5,\n",
        "    \"end_time\": 17.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 4,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" Let's hear it. Are you guys awake?\",\n",
        "    \"start_time\": 18,\n",
        "    \"end_time\": 20.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 5,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" Alright. You better be because we have a superstar guest here.\",\n",
        "    \"start_time\": 21.5,\n",
        "    \"end_time\": 27\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 6,\n",
        "    \"chunk_length\": 4,\n",
        "    \"text\": \" You heard the $41 million and I didn't hear honestly anything she said after that.\",\n",
        "    \"start_time\": 27.5,\n",
        "    \"end_time\": 31.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 7,\n",
        "    \"chunk_length\": 6,\n",
        "    \"text\": \" So, we're going to ask for about $40 million from him by the end of this conversation, okay?\",\n",
        "    \"start_time\": 32.5,\n",
        "    \"end_time\": 38.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 8,\n",
        "    \"chunk_length\": 6,\n",
        "    \"text\": \" But let's get started. I want to introduce Vivek and Pratyush, his co-founder who is not here.\",\n",
        "    \"start_time\": 39.5,\n",
        "    \"end_time\": 45.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 9,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" We wanted to start with playing a video of what OpenHati does.\",\n",
        "    \"start_time\": 46,\n",
        "    \"end_time\": 50.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 10,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" I encourage all of you to go to the website servom.ai and check it out.\",\n",
        "    \"start_time\": 51,\n",
        "    \"end_time\": 55.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 11,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" But let me start by introducing Vivek. Vivek is a dear friend and he is very, very modest, one of the most modest guys that I know.\",\n",
        "    \"start_time\": 56.5,\n",
        "    \"end_time\": 64\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 12,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" But his personal journey, Vivek, you got a PhD from Carnegie Mellon. You started and sold a company to Magma.\",\n",
        "    \"start_time\": 64.5,\n",
        "    \"end_time\": 72\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 13,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" And Vivek and I moved back to India. We were both in the valley on the same day, actually.\",\n",
        "    \"start_time\": 72.5,\n",
        "    \"end_time\": 77\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 14,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" And you've been in India for the last 16 years. And what most people don't know is your journey at Aadhaar.\",\n",
        "    \"start_time\": 77.5,\n",
        "    \"end_time\": 85\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 15,\n",
        "    \"chunk_length\": 12.5,\n",
        "    \"text\": \" Vivek spent 13 years selflessly at Aadhaar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhaar, which we all take for granted today.\",\n",
        "    \"start_time\": 85.5,\n",
        "    \"end_time\": 98\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 16,\n",
        "    \"chunk_length\": 8.5,\n",
        "    \"text\": \" So, please give it up. Honestly, when I think of selfless service, truly selfless service, I always think of Vivek.\",\n",
        "    \"start_time\": 98.5,\n",
        "    \"end_time\": 107\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 17,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush, his other co-founder.\",\n",
        "    \"start_time\": 108,\n",
        "    \"end_time\": 114.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 18,\n",
        "    \"chunk_length\": 10.5,\n",
        "    \"text\": \" Pratyush had a PhD from ETH at Zurich. He was at IBM Research. He was at Microsoft Research, playing a key role, and a faculty at IIT Madras, and at AI for Bharat.\",\n",
        "    \"start_time\": 115,\n",
        "    \"end_time\": 125.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 19,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" So, that's a little brief introduction about them. These guys are modest, modest engineers, so they don't toot their own horn.\",\n",
        "    \"start_time\": 126,\n",
        "    \"end_time\": 133.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 20,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" So, forgive me for tooting their horn in this case.\",\n",
        "    \"start_time\": 133.5,\n",
        "    \"end_time\": 137\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 21,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" But let's jump right in about the money. Funding. 41 million bucks, man. That's a lot of money, right?\",\n",
        "    \"start_time\": 137.5,\n",
        "    \"end_time\": 145\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 22,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" Every entrepreneur here is saying, what the hell did these guys do? What did the investors see to write such a big cheque?\",\n",
        "    \"start_time\": 145.5,\n",
        "    \"end_time\": 152\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 23,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" No, I think it's a new trend of what's going on in India. I think that for the very first time,\",\n",
        "    \"start_time\": 152.5,\n",
        "    \"end_time\": 160\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 24,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" I think the investors have looked at, you know, let's try and build something deep tech out of the country,\",\n",
        "    \"start_time\": 160,\n",
        "    \"end_time\": 165.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 25,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" and let's try to figure out how to build something as a foundational technology out of the country.\",\n",
        "    \"start_time\": 166,\n",
        "    \"end_time\": 170.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 26,\n",
        "    \"chunk_length\": 8.5,\n",
        "    \"text\": \" And that's really what's really exciting, you know? And I think that about, you know, as Balazs was mentioning,\",\n",
        "    \"start_time\": 171,\n",
        "    \"end_time\": 179.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 27,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" for the past 15 years, I've been kind of working in kind of, you know, both digital public infrastructure\",\n",
        "    \"start_time\": 180,\n",
        "    \"end_time\": 186.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 28,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" and kind of non-profit kind of things. But when this whole thing of generative AI came about,\",\n",
        "    \"start_time\": 186.5,\n",
        "    \"end_time\": 193\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 29,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" I, you know, we said, okay, how can I actually make a difference in this space?\",\n",
        "    \"start_time\": 193.5,\n",
        "    \"end_time\": 199\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 30,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And I said, maybe this is the opportunity to actually come out and really build something,\",\n",
        "    \"start_time\": 199.5,\n",
        "    \"end_time\": 205\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 31,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" you know, and the only way that we realize that you can do it is actually in the private sector.\",\n",
        "    \"start_time\": 205.5,\n",
        "    \"end_time\": 212\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 32,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And I think that's, and then we went out there and we said we want to build something which is a continuation, right?\",\n",
        "    \"start_time\": 212,\n",
        "    \"end_time\": 217.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 33,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" I mean, and fundamentally, the question is, the reason of what we want to do at ServamAI\",\n",
        "    \"start_time\": 218,\n",
        "    \"end_time\": 222.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 34,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" is we want to basically make generative AI available and accessible to the people in the country.\",\n",
        "    \"start_time\": 223,\n",
        "    \"end_time\": 229.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 35,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And that's the intent. And when we said that we want to do this, there was a resonance in the investment community.\",\n",
        "    \"start_time\": 230,\n",
        "    \"end_time\": 235.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 36,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" And I think it's a responsibility to really to show that something like this can be built out of India.\",\n",
        "    \"start_time\": 236.5,\n",
        "    \"end_time\": 243\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 37,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" So we see that as confidence and a responsibility. And I also hope it's a trend that, you know,\",\n",
        "    \"start_time\": 243.5,\n",
        "    \"end_time\": 249\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 38,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" that there are many more people like us who are backed, because if you look at it,\",\n",
        "    \"start_time\": 249.5,\n",
        "    \"end_time\": 254\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 39,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" maybe it's a large number in, you know, in the Indian context, but in the global context,\",\n",
        "    \"start_time\": 254.5,\n",
        "    \"end_time\": 259\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 40,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" I think there is just, there should be many, many more entrepreneurs who are backed to do things in India.\",\n",
        "    \"start_time\": 259.5,\n",
        "    \"end_time\": 265\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 41,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Krutim.\",\n",
        "    \"start_time\": 265.5,\n",
        "    \"end_time\": 271\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 42,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" So we're going to come back to that question. But again, 41 million dollars.\",\n",
        "    \"start_time\": 271.5,\n",
        "    \"end_time\": 276\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 43,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" I mean, all of what you said, you know, two million dollars, you know, that's a good amount of money\",\n",
        "    \"start_time\": 276.5,\n",
        "    \"end_time\": 281\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 44,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" for a startup which, you know, which has not yet built anything. What are you going to do with all this money?\",\n",
        "    \"start_time\": 281.5,\n",
        "    \"end_time\": 287\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 45,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" I can solve the problem. I can have a perfect solution for the problem.\",\n",
        "    \"start_time\": 288.5,\n",
        "    \"end_time\": 292\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 46,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" I think in the last week I've got lots of calls from lots of people telling me how I can.\",\n",
        "    \"start_time\": 292,\n",
        "    \"end_time\": 297.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 47,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" I know you first, okay? I'll be landed in the country the same day. I'm in front of the queue.\",\n",
        "    \"start_time\": 298,\n",
        "    \"end_time\": 302.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 48,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" No, but honestly, I think the key thing in this is to putting together an amazing team.\",\n",
        "    \"start_time\": 303,\n",
        "    \"end_time\": 309.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 49,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" And we actually have an amazing team, but we believe that it is talent that will drive this kind of thing,\",\n",
        "    \"start_time\": 310,\n",
        "    \"end_time\": 314.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 50,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" and so it is to get key talent. And of course the other thing is compute.\",\n",
        "    \"start_time\": 315,\n",
        "    \"end_time\": 319.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 51,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" This is extremely expensive compute-wise to actually do these kinds of things.\",\n",
        "    \"start_time\": 319.5,\n",
        "    \"end_time\": 325\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 52,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" And I think that those are the two primary things that, you know, we'd use this for.\",\n",
        "    \"start_time\": 325.5,\n",
        "    \"end_time\": 330\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 53,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" Okay. I'm computing in my own head as an entrepreneur. Talent, okay, you have like 20, 15 people.\",\n",
        "    \"start_time\": 330.5,\n",
        "    \"end_time\": 337\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 54,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" How much are you paying these guys? But okay, you won't touch on that.\",\n",
        "    \"start_time\": 337.5,\n",
        "    \"end_time\": 341\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 55,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" But let's talk about what you guys actually built. What is OpenHati?\",\n",
        "    \"start_time\": 341.5,\n",
        "    \"end_time\": 345\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 56,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" How would you explain OpenHati to many people here who might not have known about it?\",\n",
        "    \"start_time\": 345.5,\n",
        "    \"end_time\": 349\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 57,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" So, I think OpenHati is, so first of all, right, we come from, I personally come from the open source ecosystem,\",\n",
        "    \"start_time\": 349.5,\n",
        "    \"end_time\": 357\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 58,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful.\",\n",
        "    \"start_time\": 357.5,\n",
        "    \"end_time\": 365\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 59,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" And as a result of that, one of the first things we did was, hey, there are these open source large language models that exist, right?\",\n",
        "    \"start_time\": 365.5,\n",
        "    \"end_time\": 372\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 60,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" I mean, everybody knows about the Llama family from Meta. There are others like Mistral.\",\n",
        "    \"start_time\": 372,\n",
        "    \"end_time\": 378.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 61,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" There are a bunch of open source, you know, large language models.\",\n",
        "    \"start_time\": 379,\n",
        "    \"end_time\": 382.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 62,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" And then we said, is there any way that they can existing open source model and teach it language skills, right?\",\n",
        "    \"start_time\": 383,\n",
        "    \"end_time\": 390.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 63,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" I mean, and that is really the, you know, what we decide, what we said that can we do something like that?\",\n",
        "    \"start_time\": 391,\n",
        "    \"end_time\": 396.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 64,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" And is this a, you know, relatively frugal way of actually, you know, making models, you know, work in diverse languages?\",\n",
        "    \"start_time\": 397.5,\n",
        "    \"end_time\": 407\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 65,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" Because the truth is still today, I mean, if you look at the amount of data and knowledge, it is still English dominates these things.\",\n",
        "    \"start_time\": 407.5,\n",
        "    \"end_time\": 415\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 66,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And I think that how do you actually take and make it understand Indian language, understand Indian context,\",\n",
        "    \"start_time\": 415.5,\n",
        "    \"end_time\": 421\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 67,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" and all of those things in actually a, in an efficient way.\",\n",
        "    \"start_time\": 421,\n",
        "    \"end_time\": 424.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 68,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" And therefore, this was an attempt to do that.\",\n",
        "    \"start_time\": 425,\n",
        "    \"end_time\": 427.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 69,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And it is, OpenHati is, you know, is currently based on the Llama 7 billion model,\",\n",
        "    \"start_time\": 428,\n",
        "    \"end_time\": 433.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 70,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" but we will be releasing many more models in different languages, different sizes, and things like that as part of this, as part of this series.\",\n",
        "    \"start_time\": 434,\n",
        "    \"end_time\": 441.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 71,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And of course, you know, we will be building further models on those and doing other things to actually,\",\n",
        "    \"start_time\": 442,\n",
        "    \"end_time\": 447.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 72,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" and we will also have endpoints that people can use.\",\n",
        "    \"start_time\": 447.5,\n",
        "    \"end_time\": 450\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 73,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" So, therefore, it is not, it is definitely, you know, something that people can use to things.\",\n",
        "    \"start_time\": 450.5,\n",
        "    \"end_time\": 455\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 74,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" And that is the essence of what this OpenHati is.\",\n",
        "    \"start_time\": 455.5,\n",
        "    \"end_time\": 460\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 75,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" So, what does it mean to people in the audience here who are either doing their own startups or a business or developers?\",\n",
        "    \"start_time\": 460.5,\n",
        "    \"end_time\": 467\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 76,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" How should they look at OpenAI? Oh, sorry.\",\n",
        "    \"start_time\": 467.5,\n",
        "    \"end_time\": 470\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 77,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" Not OpenAI.\",\n",
        "    \"start_time\": 470.5,\n",
        "    \"end_time\": 472\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 78,\n",
        "    \"chunk_length\": 8.5,\n",
        "    \"text\": \" No, no, no. I think the way you look at it is that we, one of the important things that we are doing is we are not just building models.\",\n",
        "    \"start_time\": 472,\n",
        "    \"end_time\": 480.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 79,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of models,\",\n",
        "    \"start_time\": 481,\n",
        "    \"end_time\": 490.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 80,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" some which are from us, some which are open source, some which may not be open source,\",\n",
        "    \"start_time\": 491,\n",
        "    \"end_time\": 494.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 81,\n",
        "    \"chunk_length\": 11.5,\n",
        "    \"text\": \" and actually to actually pull together and figure out how to deploy, you know, generative AI applications at scale and understand and evaluate their performance in an efficient manner.\",\n",
        "    \"start_time\": 494.5,\n",
        "    \"end_time\": 506\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 82,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" And that is something that we are planning to do.\",\n",
        "    \"start_time\": 506.5,\n",
        "    \"end_time\": 508\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 83,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" And this platform is, you know, in the next couple of months will be coming out there.\",\n",
        "    \"start_time\": 508.5,\n",
        "    \"end_time\": 513\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 84,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" It will be available to developers.\",\n",
        "    \"start_time\": 513.5,\n",
        "    \"end_time\": 515\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 85,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" But, of course, those who want to start with the open source things and hack with that, of course, please go ahead and do that as well.\",\n",
        "    \"start_time\": 515.5,\n",
        "    \"end_time\": 522\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 86,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" That is phenomenal.\",\n",
        "    \"start_time\": 522.5,\n",
        "    \"end_time\": 524\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 87,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" But how does it compare to OpenAI itself or Google?\",\n",
        "    \"start_time\": 524.5,\n",
        "    \"end_time\": 529\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 88,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" See, at least the things that we are doing now, right?\",\n",
        "    \"start_time\": 529.5,\n",
        "    \"end_time\": 533\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 89,\n",
        "    \"chunk_length\": 8.5,\n",
        "    \"text\": \" I mean, one of the things that when we thought about building server, we said we want to build a full stack generative AI company and different people have,\",\n",
        "    \"start_time\": 533.5,\n",
        "    \"end_time\": 542\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 90,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" and our understanding of full stack is that we need to know how to train models from scratch.\",\n",
        "    \"start_time\": 542.5,\n",
        "    \"end_time\": 548\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 91,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" We need to know how to kind of figure out how to deploy models to solve real world use cases.\",\n",
        "    \"start_time\": 548.5,\n",
        "    \"end_time\": 554\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 92,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" And we need to play in the ecosystem to make sure that we can actually deploy population scale applications, right?\",\n",
        "    \"start_time\": 554.5,\n",
        "    \"end_time\": 562\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 93,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" So we were thinking about all of these things.\",\n",
        "    \"start_time\": 562.5,\n",
        "    \"end_time\": 565\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 94,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" But still the models we were talking about are, you know, fairly small models.\",\n",
        "    \"start_time\": 565.5,\n",
        "    \"end_time\": 569\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 95,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" They are fairly small models, right?\",\n",
        "    \"start_time\": 569.5,\n",
        "    \"end_time\": 571\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 96,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" The 7 to maybe up to 70 billion kind of range we are talking about.\",\n",
        "    \"start_time\": 571.5,\n",
        "    \"end_time\": 575\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 97,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" While these models like OpenAI and Google are obviously much bigger models, right?\",\n",
        "    \"start_time\": 575.5,\n",
        "    \"end_time\": 580\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 98,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" But we want to understand the techniques and be able to build that muscle to do all of these things to make it available to people.\",\n",
        "    \"start_time\": 580,\n",
        "    \"end_time\": 589.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 99,\n",
        "    \"chunk_length\": 10.5,\n",
        "    \"text\": \" Now those models are, I mean, as I said, I think that there is space for all of those things and I think as even Sridhar was talking about earlier in the day,\",\n",
        "    \"start_time\": 590,\n",
        "    \"end_time\": 600.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 100,\n",
        "    \"chunk_length\": 11.5,\n",
        "    \"text\": \" we believe that these smaller models can do many, many kind of domain specific tasks extremely well, probably even better than the larger models.\",\n",
        "    \"start_time\": 600.5,\n",
        "    \"end_time\": 612\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 101,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" And that is really one of the key areas.\",\n",
        "    \"start_time\": 612.5,\n",
        "    \"end_time\": 614\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 102,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" And so therefore the value of these kinds of things, right?\",\n",
        "    \"start_time\": 614.5,\n",
        "    \"end_time\": 617\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 103,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" We are not aiming in these set of models to build any AGI, right?\",\n",
        "    \"start_time\": 617.5,\n",
        "    \"end_time\": 622\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 104,\n",
        "    \"chunk_length\": 0.5,\n",
        "    \"text\": \" That's not our goal here.\",\n",
        "    \"start_time\": 622.5,\n",
        "    \"end_time\": 623\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 105,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things.\",\n",
        "    \"start_time\": 623,\n",
        "    \"end_time\": 632.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 106,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" And obviously all of this unique to India.\",\n",
        "    \"start_time\": 633,\n",
        "    \"end_time\": 634.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 107,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" But what is unique about India?\",\n",
        "    \"start_time\": 635,\n",
        "    \"end_time\": 636.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 108,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" I mean, is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems?\",\n",
        "    \"start_time\": 637,\n",
        "    \"end_time\": 646.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 109,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" So I think that, I mean, there are quite a few things that are unique about India, right?\",\n",
        "    \"start_time\": 647.5,\n",
        "    \"end_time\": 653\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 110,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" The first thing is I think that we are a voice first nation.\",\n",
        "    \"start_time\": 653.5,\n",
        "    \"end_time\": 657\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 111,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" So therefore I think voice has to be the core to doing things.\",\n",
        "    \"start_time\": 657.5,\n",
        "    \"end_time\": 661\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 112,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" The other thing, of course, India is extremely, it's a cost conscious country from a cost perspective.\",\n",
        "    \"start_time\": 661.5,\n",
        "    \"end_time\": 669\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 113,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" Now I would say that there are lots of interesting use cases where you can use open AI and the cost structure works depending on your application.\",\n",
        "    \"start_time\": 669,\n",
        "    \"end_time\": 678.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 114,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" But when you want to scale things to a massive level and make it work, then you have to figure out how small models work.\",\n",
        "    \"start_time\": 679,\n",
        "    \"end_time\": 684.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 115,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" So that's something that is also specific to India.\",\n",
        "    \"start_time\": 685,\n",
        "    \"end_time\": 688.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 116,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure.\",\n",
        "    \"start_time\": 689,\n",
        "    \"end_time\": 695.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 117,\n",
        "    \"chunk_length\": 11.5,\n",
        "    \"text\": \" When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that.\",\n",
        "    \"start_time\": 695.5,\n",
        "    \"end_time\": 707\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 118,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways.\",\n",
        "    \"start_time\": 707.5,\n",
        "    \"end_time\": 712\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 119,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" And as a part of Aadhaar, building Aadhaar, no better person than you.\",\n",
        "    \"start_time\": 712.5,\n",
        "    \"end_time\": 716\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 120,\n",
        "    \"chunk_length\": 11.5,\n",
        "    \"text\": \" So in summary, what I'm hearing is small models specialized with, trained with Indic specific language data suited for Indian problems at a compelling cost point will be suited for us.\",\n",
        "    \"start_time\": 717,\n",
        "    \"end_time\": 728.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 121,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" We're not solving some world autonomous vehicles or some complex problem.\",\n",
        "    \"start_time\": 729,\n",
        "    \"end_time\": 732.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 122,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" We're solving some basic problems specifically focused on voice with multiple languages.\",\n",
        "    \"start_time\": 733,\n",
        "    \"end_time\": 737.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 123,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" That is what you see as the future. Am I paraphrasing this correctly?\",\n",
        "    \"start_time\": 738,\n",
        "    \"end_time\": 740.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 124,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy.\",\n",
        "    \"start_time\": 741.5,\n",
        "    \"end_time\": 747\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 125,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" But we will be building, you know, custom models to solve various other kinds of problems as well, right?\",\n",
        "    \"start_time\": 747.5,\n",
        "    \"end_time\": 753\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 126,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" It's not just limited to, I think, in different domains, working in different domains, making, building things based on unique data that enterprises have and things like that.\",\n",
        "    \"start_time\": 753.5,\n",
        "    \"end_time\": 763\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 127,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" So that's something that we'll also look at.\",\n",
        "    \"start_time\": 763.5,\n",
        "    \"end_time\": 765\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 128,\n",
        "    \"chunk_length\": 0.5,\n",
        "    \"text\": \" Fair enough.\",\n",
        "    \"start_time\": 765.5,\n",
        "    \"end_time\": 766\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 129,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" So coming back to the elephant in the room, no fun intended with open Hati.\",\n",
        "    \"start_time\": 766,\n",
        "    \"end_time\": 770.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 130,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" What about Bhavesh Agarwal and Krutram? What is your take on that?\",\n",
        "    \"start_time\": 771,\n",
        "    \"end_time\": 774.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 131,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" I think it's great. I think it's wonderful, right?\",\n",
        "    \"start_time\": 775,\n",
        "    \"end_time\": 777.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 132,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" I mean, the fact that the technology AI is so important that we need multiple people working on it.\",\n",
        "    \"start_time\": 778,\n",
        "    \"end_time\": 785.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 133,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" The fact that there are other people thinking is actually validates that this is an important problem to be solved.\",\n",
        "    \"start_time\": 786,\n",
        "    \"end_time\": 791.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 134,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And I think that, and we need everybody to come together and do that.\",\n",
        "    \"start_time\": 791.5,\n",
        "    \"end_time\": 797\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 135,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" So I really welcome that. I think it's great.\",\n",
        "    \"start_time\": 797.5,\n",
        "    \"end_time\": 800\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 136,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And I think that there will be different people will have different takes as to how to solve this kind of problem.\",\n",
        "    \"start_time\": 800.5,\n",
        "    \"end_time\": 806\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 137,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" And hopefully as a result of that, the entire ecosystem benefits.\",\n",
        "    \"start_time\": 806.5,\n",
        "    \"end_time\": 811\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 138,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" I have one more question, and then I want to talk about some of the predictions that you've boldly made.\",\n",
        "    \"start_time\": 811.5,\n",
        "    \"end_time\": 816\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 139,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" So Vivek, I usually ask people about what do you think the future will be, and everybody usually hedges.\",\n",
        "    \"start_time\": 816.5,\n",
        "    \"end_time\": 821\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 140,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" So Vivek, what do you think is going to happen by December 2024?\",\n",
        "    \"start_time\": 821.5,\n",
        "    \"end_time\": 825\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 141,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" What do you think sitting in this room one year later we can expect?\",\n",
        "    \"start_time\": 825.5,\n",
        "    \"end_time\": 828\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 142,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" And you made three bold predictions, so I want to talk about that.\",\n",
        "    \"start_time\": 828.5,\n",
        "    \"end_time\": 832\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 143,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" Before that, I have one last question.\",\n",
        "    \"start_time\": 832.5,\n",
        "    \"end_time\": 834\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 144,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" What are the top three applications that you think are relevant for India?\",\n",
        "    \"start_time\": 834.5,\n",
        "    \"end_time\": 838\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 145,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" You heard Sridhar talk about medical.\",\n",
        "    \"start_time\": 838.5,\n",
        "    \"end_time\": 840\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 146,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" Quick summary, what do you think the top three apps are for India for AI?\",\n",
        "    \"start_time\": 840.5,\n",
        "    \"end_time\": 845\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 147,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" So, I mean, I think that, as you said, things like education and medical are clearly areas where I think that things can be leveraged.\",\n",
        "    \"start_time\": 845,\n",
        "    \"end_time\": 854.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 148,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" The whole idea of all these kind of the DPI aspect of it is another major application where things can happen.\",\n",
        "    \"start_time\": 855,\n",
        "    \"end_time\": 861.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 149,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" And here I'm talking about country specific work.\",\n",
        "    \"start_time\": 862,\n",
        "    \"end_time\": 864.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 150,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" And I think the whole idea which Sridhar also talked about was the concept of software, right?\",\n",
        "    \"start_time\": 865,\n",
        "    \"end_time\": 869.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 151,\n",
        "    \"chunk_length\": 8.5,\n",
        "    \"text\": \" And I think that, and clearly we have a very large software industry, and how to reimagine those things in this context is also something that's going to be big.\",\n",
        "    \"start_time\": 869.5,\n",
        "    \"end_time\": 878\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 152,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" Fair enough. Are you guys ready for Vivek Raghavan's bold predictions?\",\n",
        "    \"start_time\": 878.5,\n",
        "    \"end_time\": 884\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 153,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" Yes? No? I'm not getting any yes here. This is like a big deal.\",\n",
        "    \"start_time\": 884.5,\n",
        "    \"end_time\": 888\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 154,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it?\",\n",
        "    \"start_time\": 888.5,\n",
        "    \"end_time\": 892\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 155,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" All right. So I asked him, what do you think, you know, a year later, what do you think we can expect?\",\n",
        "    \"start_time\": 893,\n",
        "    \"end_time\": 899.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 156,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And he came up with three things, and usually people give very blah answers when you ask a question like this because they don't want to be caught wrong.\",\n",
        "    \"start_time\": 900,\n",
        "    \"end_time\": 905.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 157,\n",
        "    \"chunk_length\": 1.5,\n",
        "    \"text\": \" Not Vivek. Vivek is bold.\",\n",
        "    \"start_time\": 906,\n",
        "    \"end_time\": 907.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 158,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" So he basically said three things, and I'm going to list out the three things and then ask him about it.\",\n",
        "    \"start_time\": 908,\n",
        "    \"end_time\": 913.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 159,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" So number one, he says, I would prefer to talk to an automated customer service than a real person because they'll give me a better answer.\",\n",
        "    \"start_time\": 914,\n",
        "    \"end_time\": 921.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 160,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" So that is Vivek Raghavan's prediction number one.\",\n",
        "    \"start_time\": 922,\n",
        "    \"end_time\": 924.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 161,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut in India.\",\n",
        "    \"start_time\": 925,\n",
        "    \"end_time\": 932.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 162,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" He thinks there will be too much GPU, okay? So if you want a short Nvidia stock, this is a good time.\",\n",
        "    \"start_time\": 933,\n",
        "    \"end_time\": 937.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 163,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" And number three, which was extremely unexpected, he said some companies will suddenly die.\",\n",
        "    \"start_time\": 938,\n",
        "    \"end_time\": 944.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 164,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" Okay. So Vivek, these are not what I expected.\",\n",
        "    \"start_time\": 945,\n",
        "    \"end_time\": 948.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 165,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" So do you want to quickly talk about each of them, why you just came up with these, and then we'll throw the open for audience questions.\",\n",
        "    \"start_time\": 949.5,\n",
        "    \"end_time\": 956\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 166,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" So I don't think I quite said it the way that Vala and I am thinking, but it's interesting.\",\n",
        "    \"start_time\": 956.5,\n",
        "    \"end_time\": 963\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 167,\n",
        "    \"chunk_length\": 8.25,\n",
        "    \"text\": \" But I think the first thing that we said is I think that, and I don't think that this is, I think there will c\",\n",
        "    \"start_time\": 964,\n",
        "    \"end_time\": 972.25\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 168,\n",
        "    \"chunk_length\": 8.25,\n",
        "    \"text\": \"ome a time when, you know, in areas of customer service, et cetera, when you want to do something very specific.\",\n",
        "    \"start_time\": 972.25,\n",
        "    \"end_time\": 980.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 169,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" Today, you know, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot.\",\n",
        "    \"start_time\": 981,\n",
        "    \"end_time\": 990.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 170,\n",
        "    \"chunk_length\": 14.5,\n",
        "    \"text\": \" But I think that there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to, could give.\",\n",
        "    \"start_time\": 990.5,\n",
        "    \"end_time\": 1005\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 171,\n",
        "    \"chunk_length\": 11.5,\n",
        "    \"text\": \" And I think that that's just, I just said that there will come a time where, you know, it's not a human you're talking to, but it's probably more likely to solve your intent than the human person.\",\n",
        "    \"start_time\": 1005.5,\n",
        "    \"end_time\": 1017\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 172,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" That's just something that I think that could happen.\",\n",
        "    \"start_time\": 1018,\n",
        "    \"end_time\": 1022.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 173,\n",
        "    \"chunk_length\": 4.5,\n",
        "    \"text\": \" Okay, definitely controversial, but we'll let it go. What about the GPU glut?\",\n",
        "    \"start_time\": 1023,\n",
        "    \"end_time\": 1027.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 174,\n",
        "    \"chunk_length\": 11.5,\n",
        "    \"text\": \" No, no, yeah, so I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go, right?\",\n",
        "    \"start_time\": 1028,\n",
        "    \"end_time\": 1039.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 175,\n",
        "    \"chunk_length\": 13.5,\n",
        "    \"text\": \" I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of forms, and I think that that will always go in a cycle.\",\n",
        "    \"start_time\": 1040.5,\n",
        "    \"end_time\": 1054\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 176,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" But we may find out that there are many, many more interesting problems that people will be able to solve.\",\n",
        "    \"start_time\": 1054.5,\n",
        "    \"end_time\": 1060\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 177,\n",
        "    \"chunk_length\": 14.5,\n",
        "    \"text\": \" I still remember, you know, we were at a Gen AI event in Bangalore, and we were talking to people, and we said, you know, how many people have access to, you know, four A-hundreds?\",\n",
        "    \"start_time\": 1061,\n",
        "    \"end_time\": 1075.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 178,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" This was the question that I'd asked, and nobody in the room, and these are all extremely enthusiastic Gen AI people, and nobody had access.\",\n",
        "    \"start_time\": 1076,\n",
        "    \"end_time\": 1081.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 179,\n",
        "    \"chunk_length\": 13.5,\n",
        "    \"text\": \" And I think that thing is going to change. You will be able to get these kinds of things, and people who want to hack and do things will have access to these things without, you know, having to write a, you know, a major check to do.\",\n",
        "    \"start_time\": 1081.5,\n",
        "    \"end_time\": 1095\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 180,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" Vivek is also a semiconductor guy, before he went into Aadhaar, so I would take his predictions very seriously, so I don't know what I, I'm going to sell my media stock.\",\n",
        "    \"start_time\": 1095.5,\n",
        "    \"end_time\": 1103\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 181,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" I would not do that, but that's not what I said.\",\n",
        "    \"start_time\": 1103.5,\n",
        "    \"end_time\": 1107\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 182,\n",
        "    \"chunk_length\": 2.5,\n",
        "    \"text\": \" I want to blame you for this, if it goes up.\",\n",
        "    \"start_time\": 1107.5,\n",
        "    \"end_time\": 1110\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 183,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" But the third one is pretty strange. You know, companies are born, companies die, but you said some companies will suddenly die. What does that mean?\",\n",
        "    \"start_time\": 1111,\n",
        "    \"end_time\": 1118.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 184,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI.\",\n",
        "    \"start_time\": 1119,\n",
        "    \"end_time\": 1126.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 185,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" AI is a tool, right? And you have to use that, and you have to use that within your business process, right?\",\n",
        "    \"start_time\": 1126.5,\n",
        "    \"end_time\": 1134\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 186,\n",
        "    \"chunk_length\": 8.25,\n",
        "    \"text\": \" And how AI is being used, and so, and what's going to happen is that, I mean, I think this is true with, with, you know, when someone said in\",\n",
        "    \"start_time\": 1134.5,\n",
        "    \"end_time\": 1142.75\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 187,\n",
        "    \"chunk_length\": 8.25,\n",
        "    \"text\": \" terms of, you know, people, they said that the people who leverage AI will be, will, will be more effective than those who don't leverage AI.\",\n",
        "    \"start_time\": 1142.75,\n",
        "    \"end_time\": 1151\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 188,\n",
        "    \"chunk_length\": 11.5,\n",
        "    \"text\": \" And that's true for organizations also. Organizations that leverage AI in, fundamentally in their core business processes, will be more effective than those who don't, right?\",\n",
        "    \"start_time\": 1151,\n",
        "    \"end_time\": 1162.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 189,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" And I think that's the thing, and you won't know the difference until one day it becomes too obvious, and it will be too late.\",\n",
        "    \"start_time\": 1163,\n",
        "    \"end_time\": 1169.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 190,\n",
        "    \"chunk_length\": 6.5,\n",
        "    \"text\": \" And I think that's the reason why everybody needs to think about what it means for your business.\",\n",
        "    \"start_time\": 1170,\n",
        "    \"end_time\": 1176.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 191,\n",
        "    \"chunk_length\": 13.5,\n",
        "    \"text\": \" Because you will, everything will be fine. Everything will be fine, and one day somebody in your, either, either, either your competitor in your space or somebody brand new coming into your space will be re-imagining your business process completely.\",\n",
        "    \"start_time\": 1176.5,\n",
        "    \"end_time\": 1190\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 192,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" And at that stage you will find that it's, you know, it's a, it's a very big, very tall, you know, mountain to climb.\",\n",
        "    \"start_time\": 1191,\n",
        "    \"end_time\": 1198.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 193,\n",
        "    \"chunk_length\": 11.5,\n",
        "    \"text\": \" And that's why I think it's important for both people and entities to think about how they will, you know, they, they will upgrade themselves or they will modify their business processes to, you know, to accomplish.\",\n",
        "    \"start_time\": 1199,\n",
        "    \"end_time\": 1210.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 194,\n",
        "    \"chunk_length\": 10.5,\n",
        "    \"text\": \" That's a very nuanced answer, and everybody here who's running a business should really think about it, because life will be the same, and then suddenly, suddenly something will, you know, then there will be a step change.\",\n",
        "    \"start_time\": 1210.5,\n",
        "    \"end_time\": 1221\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 195,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" Vivek, I have a few more questions, but I'm sure the audience has a lot of questions for you. So, how are we doing on time?\",\n",
        "    \"start_time\": 1221.5,\n",
        "    \"end_time\": 1227\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 196,\n",
        "    \"chunk_length\": 7.5,\n",
        "    \"text\": \" Okay. So, does, okay, a lot of questions, so I'd love to, is there a mic that we can pass around?\",\n",
        "    \"start_time\": 1227.5,\n",
        "    \"end_time\": 1235\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 197,\n",
        "    \"chunk_length\": 13.5,\n",
        "    \"text\": \" Thank you. My name is Karthik. I work for IT service industry. So, you're saying that you're working on LLM, sorry, it's a fine-tuned LLM on top of LLama.\",\n",
        "    \"start_time\": 1240.5,\n",
        "    \"end_time\": 1254\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 198,\n",
        "    \"chunk_length\": 9.5,\n",
        "    \"text\": \" My basic question, fundamental question is we don't have a foundational model for India. Most of the models are basically using English or those kind of things.\",\n",
        "    \"start_time\": 1254.5,\n",
        "    \"end_time\": 1264\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 199,\n",
        "    \"chunk_length\": 11.5,\n",
        "    \"text\": \" So, for example, even Andrew was talking about the tokenizers and things like that. So, are you working on anything like that, or do you want to use mostly the existing models and run on top of it?\",\n",
        "    \"start_time\": 1265,\n",
        "    \"end_time\": 1276.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 200,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" You asked a good question. You asked a cherry question for himself.\",\n",
        "    \"start_time\": 1277,\n",
        "    \"end_time\": 1280.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 201,\n",
        "    \"chunk_length\": 8.25,\n",
        "    \"text\": \" No, I think the interesting thing is that if you look at, and we have actually a blog on this, on our website, I think one of the things th\",\n",
        "    \"start_time\": 1281.5,\n",
        "    \"end_time\": 1289.75\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 202,\n",
        "    \"chunk_length\": 8.25,\n",
        "    \"text\": \"at we actually built a customized tokenizer, which actually fundamentally changes the cost of some of these generations in Indian languages.\",\n",
        "    \"start_time\": 1289.75,\n",
        "    \"end_time\": 1298\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 203,\n",
        "    \"chunk_length\": 11.25,\n",
        "    \"text\": \" And I think that we're not just fine-tuning, we're actually, we are leveraging the existing pre-training, but we are doing what's known as continual free training, which actually, but having\",\n",
        "    \"start_time\": 1298,\n",
        "    \"end_time\": 1309.25\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 204,\n",
        "    \"chunk_length\": 11.25,\n",
        "    \"text\": \" said that, you know, I think that when we have to figure out where is the data to train an extremely large model from scratch, and some of those things are things which will happen over time.\",\n",
        "    \"start_time\": 1309.25,\n",
        "    \"end_time\": 1320.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 205,\n",
        "    \"chunk_length\": 13.5,\n",
        "    \"text\": \" But I think that, I think that, yes, I think that we will be doing various kinds of things, but the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that?\",\n",
        "    \"start_time\": 1320.5,\n",
        "    \"end_time\": 1334\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 206,\n",
        "    \"chunk_length\": 5.5,\n",
        "    \"text\": \" And that's the problem that we have, that we think we have solved, and it's going to be the heart of this OpenRT series.\",\n",
        "    \"start_time\": 1334.5,\n",
        "    \"end_time\": 1340\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 207,\n",
        "    \"chunk_length\": 3.5,\n",
        "    \"text\": \" It's extremely well explained in the blog, even I could understand it, so.\",\n",
        "    \"start_time\": 1340.5,\n",
        "    \"end_time\": 1344\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 208,\n",
        "    \"chunk_length\": 9.75,\n",
        "    \"text\": \" Hi, I'm Prashant, I work for a fintech company. My question is like, unlike China, we never had a consumer-facing applicatio\",\n",
        "    \"start_time\": 1345,\n",
        "    \"end_time\": 1354.75\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 209,\n",
        "    \"chunk_length\": 9.75,\n",
        "    \"text\": \"n coming out from India, and in web one, web two, crypto and all, why do you think it will be different this time in like AI?\",\n",
        "    \"start_time\": 1354.75,\n",
        "    \"end_time\": 1364.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 210,\n",
        "    \"chunk_length\": 12.75,\n",
        "    \"text\": \" Because will the DPI and other things will serve the same purpose what the Great Firewall did in China, or do you think, like in, because AI is a strategi\",\n",
        "    \"start_time\": 1364.5,\n",
        "    \"end_time\": 1377.25\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 211,\n",
        "    \"chunk_length\": 12.75,\n",
        "    \"text\": \"c sector, no outside country can work in NASA projects, maybe, or government contract will go to them, what exactly is the moat here for an Indian company?\",\n",
        "    \"start_time\": 1377.25,\n",
        "    \"end_time\": 1390\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 212,\n",
        "    \"chunk_length\": 12.75,\n",
        "    \"text\": \" So, I think the question is, I don't know the answer to these questions, right, and I think that it's difficult to predict, but I do believe, and as I'm repeating, that th\",\n",
        "    \"start_time\": 1391,\n",
        "    \"end_time\": 1403.75\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 213,\n",
        "    \"chunk_length\": 12.75,\n",
        "    \"text\": \"e combinatorial effect of being using Gen AI at a large scale, in addition, along with the DPI work that we've done in India, will have people, and I think that in the end,\",\n",
        "    \"start_time\": 1403.75,\n",
        "    \"end_time\": 1416.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 214,\n",
        "    \"chunk_length\": 10.25,\n",
        "    \"text\": \" it is, the intent is that people need to be able to use it, and they will vote by things that are useful for them, and if that doesn't happen, you're rig\",\n",
        "    \"start_time\": 1416.5,\n",
        "    \"end_time\": 1426.75\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 215,\n",
        "    \"chunk_length\": 10.25,\n",
        "    \"text\": \"ht, and I think that we have to figure out what is the mechanism of delivery of apps, right, I mean, where do Indians consume content, that's the question.\",\n",
        "    \"start_time\": 1426.75,\n",
        "    \"end_time\": 1437\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 216,\n",
        "    \"chunk_length\": 14.75,\n",
        "    \"text\": \" I'm so sorry, but we are out of time, Vivek will be outside, so he would be able to answer the question, do we have time for one last question? Can I, can I just take one last, yeah, thank you, thank you, I'm Manish Kothari, I'm from ISBR Business School, good that I got a \",\n",
        "    \"start_time\": 1437,\n",
        "    \"end_time\": 1451.75\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 217,\n",
        "    \"chunk_length\": 14.75,\n",
        "    \"text\": \"chance to ask you this question, during lunchtime, there were a few of our educationists whom we were talking about, and there was one from school, and we are from the MBA institutions, we were thinking of these present generations, how do we get them into what you are doing?\",\n",
        "    \"start_time\": 1451.75,\n",
        "    \"end_time\": 1466.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 218,\n",
        "    \"chunk_length\": 11,\n",
        "    \"text\": \" There is one thing that they have been regularly that the concentrations that they're working on, but artificial intelligence and getting into this, getting them into their academics and making them a part of it \",\n",
        "    \"start_time\": 1467.5,\n",
        "    \"end_time\": 1478.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 219,\n",
        "    \"chunk_length\": 11,\n",
        "    \"text\": \"is very important, including the trainers who train them, making them future ready into what you are doing is amazing, and the speed that which is growing, it is calling for a lot of training that needs to be done.\",\n",
        "    \"start_time\": 1478.5,\n",
        "    \"end_time\": 1489.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 220,\n",
        "    \"chunk_length\": 14,\n",
        "    \"text\": \" Can you from your angle throw some light on how we could make them future ready? How these people who are, who are management graduates and from schools who are coming out, how do we get into this part of technology that you spoke about?\",\n",
        "    \"start_time\": 1490,\n",
        "    \"end_time\": 1504\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 221,\n",
        "    \"chunk_length\": 8.5,\n",
        "    \"text\": \" So this is really a challenge, because I think everyone will need to understand at some level what this technology does, and I t\",\n",
        "    \"start_time\": 1505,\n",
        "    \"end_time\": 1513.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 222,\n",
        "    \"chunk_length\": 8.5,\n",
        "    \"text\": \"hink that we have to rethink how we get everyone into these, and this kind of education has to be at many different levels, right?\",\n",
        "    \"start_time\": 1513.5,\n",
        "    \"end_time\": 1522\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 223,\n",
        "    \"chunk_length\": 12,\n",
        "    \"text\": \" There are, from a core set of having people who are extremely good at some, and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools.\",\n",
        "    \"start_time\": 1522,\n",
        "    \"end_time\": 1534\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 224,\n",
        "    \"chunk_length\": 14.5,\n",
        "    \"text\": \" By the way, the most important thing about, and maybe that's part of what makes an LLM interesting, is that how you use it, your mileage varies by that, and to understand how to actually leverage this in an interesting way is\",\n",
        "    \"start_time\": 1534,\n",
        "    \"end_time\": 1548.5\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 225,\n",
        "    \"chunk_length\": 14.5,\n",
        "    \"text\": \" something that we have to widely teach many, many people, and because asking the, you know, things in the right way and having the right kind of applications will make a huge difference to how people can leverage these tools.\",\n",
        "    \"start_time\": 1548.5,\n",
        "    \"end_time\": 1563\n",
        "  },\n",
        "  {\n",
        "    \"chunk_id\": 226,\n",
        "    \"chunk_length\": 7,\n",
        "    \"text\": \" Thank you very much Vivek, very good luck to Sarvam, and good luck to India, I think it's going to be a lot on your shoulders.\",\n",
        "    \"start_time\": 1564,\n",
        "    \"end_time\": 1571\n",
        "  }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD1LtPuP6tVj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
